package main

import (
	"context"
	"fmt"
	"math/rand"
	"sync"
	"sync/atomic"
	"time"

	"mall-go/internal/config"
	"mall-go/internal/model"
	"mall-go/pkg/cache"
	"mall-go/pkg/logger"
	"mall-go/pkg/optimistic"
	"mall-go/tests/helpers"

	"github.com/glebarez/sqlite"
	"github.com/shopspring/decimal"
	"gorm.io/gorm"
	gormLogger "gorm.io/gorm/logger"
)

// PerformanceVerificationResult æ€§èƒ½éªŒè¯ç»“æœ
type PerformanceVerificationResult struct {
	TestName            string        `json:"test_name"`
	Timestamp           time.Time     `json:"timestamp"`
	ConcurrentUsers     int           `json:"concurrent_users"`
	TestDuration        time.Duration `json:"test_duration"`
	TotalRequests       int64         `json:"total_requests"`
	SuccessRequests     int64         `json:"success_requests"`
	FailedRequests      int64         `json:"failed_requests"`
	AverageResponseTime time.Duration `json:"average_response_time"`
	P95ResponseTime     time.Duration `json:"p95_response_time"`
	P99ResponseTime     time.Duration `json:"p99_response_time"`
	QPS                 float64       `json:"qps"`
	CacheHitRate        float64       `json:"cache_hit_rate"`
	CacheMissRate       float64       `json:"cache_miss_rate"`
	ErrorRate           float64       `json:"error_rate"`
	MemoryUsageMB       float64       `json:"memory_usage_mb"`
	DatabaseQueries     int64         `json:"database_queries"`
	CacheOperations     int64         `json:"cache_operations"`
	Passed              bool          `json:"passed"`
	FailureReasons      []string      `json:"failure_reasons"`
}

// PerformanceTargets æ€§èƒ½ç›®æ ‡
type PerformanceTargets struct {
	MinQPS                    float64       `json:"min_qps"`
	MaxAverageResponseTime    time.Duration `json:"max_average_response_time"`
	MaxP95ResponseTime        time.Duration `json:"max_p95_response_time"`
	MinCacheHitRate           float64       `json:"min_cache_hit_rate"`
	MaxErrorRate              float64       `json:"max_error_rate"`
	MinDatabaseQueryReduction float64       `json:"min_database_query_reduction"`
}

func main() {
	// åˆå§‹åŒ–æ—¥å¿—
	logger.Init()

	fmt.Println("ğŸš€ Mall-Go ç¼“å­˜æ€§èƒ½éªŒè¯ç¨‹åº")
	fmt.Println("=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=")

	// è®¾ç½®æ€§èƒ½ç›®æ ‡
	targets := &PerformanceTargets{
		MinQPS:                    10000,                 // ç›®æ ‡QPS â‰¥ 10,000
		MaxAverageResponseTime:    5 * time.Millisecond,  // å¹³å‡å“åº”æ—¶é—´ â‰¤ 5ms
		MaxP95ResponseTime:        20 * time.Millisecond, // P95å“åº”æ—¶é—´ â‰¤ 20ms
		MinCacheHitRate:           90.0,                  // ç¼“å­˜å‘½ä¸­ç‡ â‰¥ 90%
		MaxErrorRate:              1.0,                   // é”™è¯¯ç‡ â‰¤ 1%
		MinDatabaseQueryReduction: 80.0,                  // æ•°æ®åº“æŸ¥è¯¢å‡å°‘ â‰¥ 80%
	}

	fmt.Printf("ğŸ“‹ æ€§èƒ½éªŒè¯ç›®æ ‡:\n")
	fmt.Printf("   - æœ€å°QPS: %.0f\n", targets.MinQPS)
	fmt.Printf("   - æœ€å¤§å¹³å‡å“åº”æ—¶é—´: %v\n", targets.MaxAverageResponseTime)
	fmt.Printf("   - æœ€å¤§P95å“åº”æ—¶é—´: %v\n", targets.MaxP95ResponseTime)
	fmt.Printf("   - æœ€å°ç¼“å­˜å‘½ä¸­ç‡: %.1f%%\n", targets.MinCacheHitRate)
	fmt.Printf("   - æœ€å¤§é”™è¯¯ç‡: %.1f%%\n", targets.MaxErrorRate)
	fmt.Printf("   - æœ€å°æ•°æ®åº“æŸ¥è¯¢å‡å°‘: %.1f%%\n", targets.MinDatabaseQueryReduction)

	// 1. åŸºç¡€ç¯å¢ƒéªŒè¯
	fmt.Println("\nğŸ”§ æ­¥éª¤1: åŸºç¡€ç¯å¢ƒéªŒè¯")
	if !verifyEnvironment() {
		fmt.Println("âŒ åŸºç¡€ç¯å¢ƒéªŒè¯å¤±è´¥")
		return
	}
	fmt.Println("âœ… åŸºç¡€ç¯å¢ƒéªŒè¯é€šè¿‡")

	// 2. ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–éªŒè¯
	fmt.Println("\nğŸ—ï¸ æ­¥éª¤2: ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–éªŒè¯")
	cacheSystem, db := initializeCacheSystem()
	if cacheSystem == nil {
		fmt.Println("âŒ ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
		return
	}
	fmt.Println("âœ… ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")

	// 3. æµ‹è¯•æ•°æ®å‡†å¤‡
	fmt.Println("\nğŸ“Š æ­¥éª¤3: æµ‹è¯•æ•°æ®å‡†å¤‡")
	if !prepareTestData(db) {
		fmt.Println("âŒ æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥")
		return
	}
	fmt.Println("âœ… æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ")

	// 4. ç¼“å­˜é¢„çƒ­éªŒè¯
	fmt.Println("\nğŸ”¥ æ­¥éª¤4: ç¼“å­˜é¢„çƒ­éªŒè¯")
	if !verifyCacheWarmup(cacheSystem) {
		fmt.Println("âŒ ç¼“å­˜é¢„çƒ­éªŒè¯å¤±è´¥")
		return
	}
	fmt.Println("âœ… ç¼“å­˜é¢„çƒ­éªŒè¯é€šè¿‡")

	// 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
	fmt.Println("\nâš¡ æ­¥éª¤5: æ€§èƒ½åŸºå‡†æµ‹è¯•")
	baselineResult := runBaselinePerformanceTest(db)
	fmt.Printf("   åŸºå‡†æ€§èƒ½ - QPS: %.2f, å¹³å‡å“åº”æ—¶é—´: %v\n",
		baselineResult.QPS, baselineResult.AverageResponseTime)

	// 6. ç¼“å­˜æ€§èƒ½æµ‹è¯•
	fmt.Println("\nğŸ¯ æ­¥éª¤6: ç¼“å­˜æ€§èƒ½æµ‹è¯•")
	cacheResult := runCachePerformanceTest(cacheSystem, db)
	fmt.Printf("   ç¼“å­˜æ€§èƒ½ - QPS: %.2f, å¹³å‡å“åº”æ—¶é—´: %v, å‘½ä¸­ç‡: %.2f%%\n",
		cacheResult.QPS, cacheResult.AverageResponseTime, cacheResult.CacheHitRate)

	// 7. å¹¶å‘å‹åŠ›æµ‹è¯•
	fmt.Println("\nğŸ’ª æ­¥éª¤7: å¹¶å‘å‹åŠ›æµ‹è¯•")
	stressResult := runConcurrentStressTest(cacheSystem, db)
	fmt.Printf("   å‹åŠ›æµ‹è¯• - QPS: %.2f, é”™è¯¯ç‡: %.2f%%\n",
		stressResult.QPS, stressResult.ErrorRate)

	// 8. ä¸€è‡´æ€§éªŒè¯æµ‹è¯•
	fmt.Println("\nğŸ”„ æ­¥éª¤8: ä¸€è‡´æ€§éªŒè¯æµ‹è¯•")
	consistencyResult := runConsistencyVerificationTest(cacheSystem, db)
	fmt.Printf("   ä¸€è‡´æ€§æµ‹è¯• - æˆåŠŸç‡: %.2f%%\n",
		float64(consistencyResult.SuccessRequests)/float64(consistencyResult.TotalRequests)*100)

	// 9. ç»¼åˆæ€§èƒ½éªŒè¯
	fmt.Println("\nğŸ“ˆ æ­¥éª¤9: ç»¼åˆæ€§èƒ½éªŒè¯")
	finalResult := runComprehensivePerformanceTest(cacheSystem, db)

	// 10. æ€§èƒ½ç›®æ ‡éªŒè¯
	fmt.Println("\nâœ… æ­¥éª¤10: æ€§èƒ½ç›®æ ‡éªŒè¯")
	passed, reasons := verifyPerformanceTargets(finalResult, targets)

	// è¾“å‡ºæœ€ç»ˆç»“æœ
	fmt.Println("\nğŸ‰ æ€§èƒ½éªŒè¯å®Œæˆ!")
	fmt.Println("=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=" + "=")

	printFinalResults(finalResult, targets, passed, reasons)

	if passed {
		fmt.Println("\nğŸŠ æ­å–œï¼æ‰€æœ‰æ€§èƒ½ç›®æ ‡å‡å·²è¾¾æˆï¼")
		fmt.Println("   Mall-Goç¼“å­˜ä¼˜åŒ–é¡¹ç›®ç¬¬ä¸‰å‘¨éªŒæ”¶æ ‡å‡†100%é€šè¿‡ï¼")
	} else {
		fmt.Println("\nâš ï¸ éƒ¨åˆ†æ€§èƒ½ç›®æ ‡æœªè¾¾æˆï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
		for _, reason := range reasons {
			fmt.Printf("   - %s\n", reason)
		}
	}
}

// verifyEnvironment éªŒè¯åŸºç¡€ç¯å¢ƒ
func verifyEnvironment() bool {
	// æ£€æŸ¥Redisè¿æ¥
	redisConfig := config.RedisConfig{
		Host:         "localhost",
		Port:         6379,
		Password:     "",
		DB:           1,
		PoolSize:     100,
		MinIdleConns: 10,
		MaxRetries:   3,
		DialTimeout:  5,
		ReadTimeout:  3,
		WriteTimeout: 3,
		IdleTimeout:  300,
		MaxConnAge:   3600,
	}

	redisClient, err := cache.NewRedisClient(redisConfig)
	if err != nil {
		fmt.Printf("   âŒ Redisè¿æ¥å¤±è´¥: %v\n", err)
		return false
	}
	defer redisClient.Close()

	if err := redisClient.Ping(); err != nil {
		fmt.Printf("   âŒ Redis Pingå¤±è´¥: %v\n", err)
		return false
	}

	fmt.Println("   âœ… Redisè¿æ¥æ­£å¸¸")
	return true
}

// CacheSystem ç¼“å­˜ç³»ç»Ÿç»“æ„
type CacheSystem struct {
	CacheManager   cache.CacheManager
	KeyManager     *cache.CacheKeyManager
	ConsistencyMgr *cache.CacheConsistencyManager
	WarmupMgr      *cache.CacheWarmupManager
	ProtectionMgr  *cache.CacheProtectionManager
	MonitoringMgr  *cache.CacheMonitoringManager
}

// initializeCacheSystem åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
func initializeCacheSystem() (*CacheSystem, *gorm.DB) {
	// åˆå§‹åŒ–æ•°æ®åº“
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{
		Logger: gormLogger.Default.LogMode(gormLogger.Silent),
	})
	if err != nil {
		fmt.Printf("   âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: %v\n", err)
		return nil, nil
	}

	// è‡ªåŠ¨è¿ç§»
	db.AutoMigrate(
		&model.User{},
		&model.Product{},
		&model.Category{},
		&model.Order{},
		&model.OrderItem{},
		&model.CartItem{},
		&model.Cart{},
	)

	// åˆå§‹åŒ–Redis
	redisConfig := config.RedisConfig{
		Host:         "localhost",
		Port:         6379,
		Password:     "",
		DB:           1,
		PoolSize:     100,
		MinIdleConns: 10,
		MaxRetries:   3,
		DialTimeout:  5,
		ReadTimeout:  3,
		WriteTimeout: 3,
		IdleTimeout:  300,
		MaxConnAge:   3600,
	}

	redisClient, err := cache.NewRedisClient(redisConfig)
	if err != nil {
		fmt.Printf("   âŒ Rediså®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: %v\n", err)
		return nil, nil
	}

	// æ¸…ç†Redis
	redisClient.GetClient().FlushDB(context.Background())

	// åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
	cacheManager := cache.NewRedisCacheManager(redisClient)

	// åˆå§‹åŒ–é”®ç®¡ç†å™¨
	cache.InitKeyManager("perf_verify")
	keyManager := cache.GetKeyManager()

	// åˆ›å»ºæµ‹è¯•åŠ©æ‰‹å’Œä¹è§‚é”æœåŠ¡
	_ = helpers.NewTestHelper(db)
	optimisticLock := optimistic.NewOptimisticLockService(db)

	// åˆ›å»ºå„ç§ç®¡ç†å™¨
	consistencyConfig := cache.DefaultCacheConsistencyConfig()
	consistencyMgr := cache.NewCacheConsistencyManager(consistencyConfig, cacheManager, keyManager, optimisticLock)

	warmupConfig := cache.DefaultCacheWarmupConfig()
	warmupMgr := cache.NewCacheWarmupManager(warmupConfig, cacheManager, keyManager, consistencyMgr, optimisticLock)

	protectionConfig := cache.DefaultCacheProtectionConfig()
	protectionConfig.Strategies = []cache.ProtectionStrategy{
		cache.ProtectionNullCache,
		cache.ProtectionRandomTTL,
	}
	protectionMgr := cache.NewCacheProtectionManager(protectionConfig, cacheManager, keyManager, consistencyMgr, warmupMgr, optimisticLock)

	monitoringConfig := cache.DefaultCacheMonitoringConfig()
	monitoringMgr := cache.NewCacheMonitoringManager(monitoringConfig, cacheManager, keyManager, consistencyMgr, warmupMgr, protectionMgr, optimisticLock)

	// å¯åŠ¨æ‰€æœ‰ç®¡ç†å™¨
	consistencyMgr.Start()
	warmupMgr.Start()
	protectionMgr.Start()
	monitoringMgr.Start()

	return &CacheSystem{
		CacheManager:   cacheManager,
		KeyManager:     keyManager,
		ConsistencyMgr: consistencyMgr,
		WarmupMgr:      warmupMgr,
		ProtectionMgr:  protectionMgr,
		MonitoringMgr:  monitoringMgr,
	}, db
}

// prepareTestData å‡†å¤‡æµ‹è¯•æ•°æ®
func prepareTestData(db *gorm.DB) bool {
	// åˆ›å»ºåˆ†ç±»
	categories := []model.Category{
		{Name: "ç”µå­äº§å“", Description: "å„ç§ç”µå­è®¾å¤‡", Status: "active"},
		{Name: "æœè£…", Description: "æ—¶å°šæœè£…", Status: "active"},
		{Name: "å®¶å±…", Description: "å®¶å±…ç”¨å“", Status: "active"},
		{Name: "å›¾ä¹¦", Description: "å„ç±»å›¾ä¹¦", Status: "active"},
		{Name: "è¿åŠ¨", Description: "è¿åŠ¨ç”¨å“", Status: "active"},
	}

	for _, category := range categories {
		if err := db.Create(&category).Error; err != nil {
			fmt.Printf("   âŒ åˆ›å»ºåˆ†ç±»å¤±è´¥: %v\n", err)
			return false
		}
	}

	// åˆ›å»ºå•†å“
	for i := 1; i <= 2000; i++ {
		product := model.Product{
			Name:        fmt.Sprintf("å•†å“%d", i),
			Description: fmt.Sprintf("è¿™æ˜¯å•†å“%dçš„æè¿°", i),
			Price:       decimal.NewFromFloat(rand.Float64()*1000 + 10),
			Stock:       rand.Intn(1000) + 10,
			CategoryID:  uint(rand.Intn(5) + 1),
			Status:      "on_sale",
		}

		if err := db.Create(&product).Error; err != nil {
			fmt.Printf("   âŒ åˆ›å»ºå•†å“å¤±è´¥: %v\n", err)
			return false
		}
	}

	// åˆ›å»ºç”¨æˆ·
	for i := 1; i <= 200; i++ {
		user := model.User{
			Username: fmt.Sprintf("user%d", i),
			Email:    fmt.Sprintf("user%d@example.com", i),
			Password: "password123",
			Status:   "active",
		}

		if err := db.Create(&user).Error; err != nil {
			fmt.Printf("   âŒ åˆ›å»ºç”¨æˆ·å¤±è´¥: %v\n", err)
			return false
		}
	}

	fmt.Printf("   âœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ - åˆ†ç±»: %d, å•†å“: 2000, ç”¨æˆ·: 200\n", len(categories))
	return true
}

// verifyCacheWarmup éªŒè¯ç¼“å­˜é¢„çƒ­
func verifyCacheWarmup(system *CacheSystem) bool {
	start := time.Now()

	// æ‰§è¡Œç¼“å­˜é¢„çƒ­
	if err := system.WarmupMgr.WarmupAll(); err != nil {
		fmt.Printf("   âŒ ç¼“å­˜é¢„çƒ­å¤±è´¥: %v\n", err)
		return false
	}

	warmupDuration := time.Since(start)

	// ç­‰å¾…é¢„çƒ­å®Œæˆ
	time.Sleep(3 * time.Second)

	// éªŒè¯é¢„çƒ­æ•ˆæœ
	hitCount := 0
	testCount := 100

	for i := 1; i <= testCount; i++ {
		key := system.KeyManager.GenerateProductKey(uint(i))
		if _, err := system.CacheManager.Get(key); err == nil {
			hitCount++
		}
	}

	hitRate := float64(hitCount) / float64(testCount) * 100

	fmt.Printf("   âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ - è€—æ—¶: %v, å‘½ä¸­ç‡: %.2f%%\n", warmupDuration, hitRate)

	return hitRate >= 70.0 // é¢„çƒ­åå‘½ä¸­ç‡åº”â‰¥70%
}

// runBaselinePerformanceTest è¿è¡ŒåŸºå‡†æ€§èƒ½æµ‹è¯•
func runBaselinePerformanceTest(db *gorm.DB) *PerformanceVerificationResult {
	concurrency := 100
	testDuration := 10 * time.Second

	var totalRequests int64
	var successRequests int64
	var totalResponseTime int64
	var dbQueries int64

	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					requestStart := time.Now()

					// ç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢
					productID := uint(rand.Intn(2000) + 1)
					var product model.Product
					err := db.Where("id = ?", productID).First(&product).Error

					duration := time.Since(requestStart)

					atomic.AddInt64(&totalRequests, 1)
					atomic.AddInt64(&totalResponseTime, int64(duration))
					atomic.AddInt64(&dbQueries, 1)

					if err == nil {
						atomic.AddInt64(&successRequests, 1)
					}

					time.Sleep(time.Microsecond * 100)
				}
			}
		}()
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—æŒ‡æ ‡
	totalReq := atomic.LoadInt64(&totalRequests)
	successReq := atomic.LoadInt64(&successRequests)
	avgResponseTime := time.Duration(atomic.LoadInt64(&totalResponseTime) / totalReq)
	qps := float64(totalReq) / actualDuration.Seconds()
	errorRate := float64(totalReq-successReq) / float64(totalReq) * 100

	return &PerformanceVerificationResult{
		TestName:            "åŸºå‡†æ€§èƒ½æµ‹è¯•",
		Timestamp:           time.Now(),
		ConcurrentUsers:     concurrency,
		TestDuration:        actualDuration,
		TotalRequests:       totalReq,
		SuccessRequests:     successReq,
		FailedRequests:      totalReq - successReq,
		AverageResponseTime: avgResponseTime,
		QPS:                 qps,
		ErrorRate:           errorRate,
		DatabaseQueries:     atomic.LoadInt64(&dbQueries),
		CacheOperations:     0,
		CacheHitRate:        0,
		CacheMissRate:       100,
	}
}

// runCachePerformanceTest è¿è¡Œç¼“å­˜æ€§èƒ½æµ‹è¯•
func runCachePerformanceTest(system *CacheSystem, db *gorm.DB) *PerformanceVerificationResult {
	concurrency := 200
	testDuration := 15 * time.Second

	var totalRequests int64
	var successRequests int64
	var totalResponseTime int64
	var dbQueries int64
	var cacheHits int64
	var cacheMisses int64
	var cacheOperations int64

	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					requestStart := time.Now()

					// å…ˆå°è¯•ä»ç¼“å­˜è·å–
					productID := uint(rand.Intn(2000) + 1)
					key := system.KeyManager.GenerateProductKey(productID)

					cachedData, err := system.CacheManager.Get(key)
					atomic.AddInt64(&cacheOperations, 1)

					if err == nil && cachedData != nil {
						// ç¼“å­˜å‘½ä¸­
						atomic.AddInt64(&cacheHits, 1)
						atomic.AddInt64(&successRequests, 1)
					} else {
						// ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®åº“æŸ¥è¯¢
						atomic.AddInt64(&cacheMisses, 1)
						var product model.Product
						dbErr := db.Where("id = ?", productID).First(&product).Error
						atomic.AddInt64(&dbQueries, 1)

						if dbErr == nil {
							// ç¼“å­˜æ•°æ®
							system.CacheManager.Set(key, product, 1*time.Hour)
							atomic.AddInt64(&successRequests, 1)
						}
					}

					duration := time.Since(requestStart)
					atomic.AddInt64(&totalRequests, 1)
					atomic.AddInt64(&totalResponseTime, int64(duration))

					// è®°å½•ç›‘æ§æ•°æ®
					system.MonitoringMgr.RecordResponseTime(duration)
					system.MonitoringMgr.RecordHotKey(key, err == nil)

					time.Sleep(time.Microsecond * 50)
				}
			}
		}()
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—æŒ‡æ ‡
	totalReq := atomic.LoadInt64(&totalRequests)
	successReq := atomic.LoadInt64(&successRequests)
	hits := atomic.LoadInt64(&cacheHits)
	misses := atomic.LoadInt64(&cacheMisses)
	avgResponseTime := time.Duration(atomic.LoadInt64(&totalResponseTime) / totalReq)
	qps := float64(totalReq) / actualDuration.Seconds()
	errorRate := float64(totalReq-successReq) / float64(totalReq) * 100
	hitRate := float64(hits) / float64(hits+misses) * 100
	missRate := float64(misses) / float64(hits+misses) * 100

	return &PerformanceVerificationResult{
		TestName:            "ç¼“å­˜æ€§èƒ½æµ‹è¯•",
		Timestamp:           time.Now(),
		ConcurrentUsers:     concurrency,
		TestDuration:        actualDuration,
		TotalRequests:       totalReq,
		SuccessRequests:     successReq,
		FailedRequests:      totalReq - successReq,
		AverageResponseTime: avgResponseTime,
		QPS:                 qps,
		ErrorRate:           errorRate,
		DatabaseQueries:     atomic.LoadInt64(&dbQueries),
		CacheOperations:     atomic.LoadInt64(&cacheOperations),
		CacheHitRate:        hitRate,
		CacheMissRate:       missRate,
	}
}

// runConcurrentStressTest è¿è¡Œå¹¶å‘å‹åŠ›æµ‹è¯•
func runConcurrentStressTest(system *CacheSystem, db *gorm.DB) *PerformanceVerificationResult {
	concurrency := 500
	testDuration := 20 * time.Second

	var totalRequests int64
	var successRequests int64
	var totalResponseTime int64
	var cacheHits int64
	var cacheMisses int64

	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					requestStart := time.Now()

					// æ··åˆæ“ä½œï¼š80%è¯»å–ï¼Œ20%å†™å…¥
					if rand.Float64() < 0.8 {
						// è¯»å–æ“ä½œ
						productID := uint(rand.Intn(2000) + 1)
						key := system.KeyManager.GenerateProductKey(productID)

						_, err := system.CacheManager.Get(key)
						if err == nil {
							atomic.AddInt64(&cacheHits, 1)
							atomic.AddInt64(&successRequests, 1)
						} else {
							atomic.AddInt64(&cacheMisses, 1)
							// ä»æ•°æ®åº“åŠ è½½
							var product model.Product
							if dbErr := db.Where("id = ?", productID).First(&product).Error; dbErr == nil {
								system.CacheManager.Set(key, product, 1*time.Hour)
								atomic.AddInt64(&successRequests, 1)
							}
						}
					} else {
						// å†™å…¥æ“ä½œ
						productID := uint(rand.Intn(2000) + 1)
						key := system.KeyManager.GenerateProductKey(productID)

						data := map[string]interface{}{
							"id":    productID,
							"name":  fmt.Sprintf("Product %d", productID),
							"price": rand.Float64() * 1000,
						}

						if err := system.CacheManager.Set(key, data, 1*time.Hour); err == nil {
							atomic.AddInt64(&successRequests, 1)
						}
					}

					duration := time.Since(requestStart)
					atomic.AddInt64(&totalRequests, 1)
					atomic.AddInt64(&totalResponseTime, int64(duration))

					time.Sleep(time.Microsecond * 20)
				}
			}
		}()
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—æŒ‡æ ‡
	totalReq := atomic.LoadInt64(&totalRequests)
	successReq := atomic.LoadInt64(&successRequests)
	hits := atomic.LoadInt64(&cacheHits)
	misses := atomic.LoadInt64(&cacheMisses)
	avgResponseTime := time.Duration(atomic.LoadInt64(&totalResponseTime) / totalReq)
	qps := float64(totalReq) / actualDuration.Seconds()
	errorRate := float64(totalReq-successReq) / float64(totalReq) * 100
	hitRate := float64(hits) / float64(hits+misses) * 100

	return &PerformanceVerificationResult{
		TestName:            "å¹¶å‘å‹åŠ›æµ‹è¯•",
		Timestamp:           time.Now(),
		ConcurrentUsers:     concurrency,
		TestDuration:        actualDuration,
		TotalRequests:       totalReq,
		SuccessRequests:     successReq,
		FailedRequests:      totalReq - successReq,
		AverageResponseTime: avgResponseTime,
		QPS:                 qps,
		ErrorRate:           errorRate,
		CacheHitRate:        hitRate,
		CacheMissRate:       100 - hitRate,
	}
}

// runConsistencyVerificationTest è¿è¡Œä¸€è‡´æ€§éªŒè¯æµ‹è¯•
func runConsistencyVerificationTest(system *CacheSystem, db *gorm.DB) *PerformanceVerificationResult {
	concurrency := 50
	testDuration := 10 * time.Second

	var totalRequests int64
	var successRequests int64
	var consistencyChecks int64
	var consistentData int64

	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	// å¯åŠ¨å¹¶å‘æ›´æ–°å·¥ä½œè€…
	for i := 0; i < concurrency/2; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					// éšæœºæ›´æ–°å•†å“ä»·æ ¼
					productID := uint(rand.Intn(100) + 1)
					newPrice := fmt.Sprintf("%.2f", rand.Float64()*1000+10)

					updates := map[string]interface{}{
						"price": newPrice,
					}

					// é€šè¿‡ä¸€è‡´æ€§ç®¡ç†å™¨æ›´æ–°
					cacheKey := system.KeyManager.GenerateProductKey(productID)
					if err := system.ConsistencyMgr.SyncCache(cacheKey, "products", productID, updates); err == nil {
						atomic.AddInt64(&successRequests, 1)
					}
					atomic.AddInt64(&totalRequests, 1)

					time.Sleep(time.Millisecond * 20)
				}
			}
		}()
	}

	// å¯åŠ¨ä¸€è‡´æ€§æ£€æŸ¥å·¥ä½œè€…
	for i := 0; i < concurrency/2; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					// æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
					productID := uint(rand.Intn(100) + 1)
					cacheKey := system.KeyManager.GenerateProductKey(productID)

					// ä»ç¼“å­˜å’Œæ•°æ®åº“è·å–æ•°æ®
					_, cacheErr := system.CacheManager.Get(cacheKey)
					var dbProduct model.Product
					dbErr := db.Where("id = ?", productID).First(&dbProduct).Error

					atomic.AddInt64(&consistencyChecks, 1)

					// ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
					if (cacheErr == nil && dbErr == nil) || (cacheErr != nil && dbErr != nil) {
						atomic.AddInt64(&consistentData, 1)
					}

					time.Sleep(time.Millisecond * 10)
				}
			}
		}()
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—æŒ‡æ ‡
	totalReq := atomic.LoadInt64(&totalRequests)
	successReq := atomic.LoadInt64(&successRequests)
	checks := atomic.LoadInt64(&consistencyChecks)
	consistent := atomic.LoadInt64(&consistentData)

	consistencyRate := float64(consistent) / float64(checks) * 100

	return &PerformanceVerificationResult{
		TestName:        "ä¸€è‡´æ€§éªŒè¯æµ‹è¯•",
		Timestamp:       time.Now(),
		ConcurrentUsers: concurrency,
		TestDuration:    actualDuration,
		TotalRequests:   totalReq,
		SuccessRequests: successReq,
		FailedRequests:  totalReq - successReq,
		QPS:             float64(totalReq) / actualDuration.Seconds(),
		ErrorRate:       float64(totalReq-successReq) / float64(totalReq) * 100,
		// ä½¿ç”¨ä¸€è‡´æ€§ç‡ä½œä¸ºæˆåŠŸç‡çš„æŒ‡æ ‡
		Passed: consistencyRate >= 85.0,
	}
}

// runComprehensivePerformanceTest è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•
func runComprehensivePerformanceTest(system *CacheSystem, db *gorm.DB) *PerformanceVerificationResult {
	concurrency := 300
	testDuration := 30 * time.Second

	var totalRequests int64
	var successRequests int64
	var totalResponseTime int64
	var dbQueries int64
	var cacheHits int64
	var cacheMisses int64
	var cacheOperations int64
	var responseTimes []time.Duration
	var responseTimesMutex sync.Mutex

	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					requestStart := time.Now()

					// æ··åˆæ“ä½œï¼š70%è¯»å–ï¼Œ20%å†™å…¥ï¼Œ10%æ›´æ–°
					operation := rand.Float64()
					productID := uint(rand.Intn(2000) + 1)
					key := system.KeyManager.GenerateProductKey(productID)

					if operation < 0.7 {
						// è¯»å–æ“ä½œ
						cachedData, err := system.CacheManager.Get(key)
						atomic.AddInt64(&cacheOperations, 1)

						if err == nil && cachedData != nil {
							atomic.AddInt64(&cacheHits, 1)
							atomic.AddInt64(&successRequests, 1)
						} else {
							atomic.AddInt64(&cacheMisses, 1)
							var product model.Product
							if dbErr := db.Where("id = ?", productID).First(&product).Error; dbErr == nil {
								system.CacheManager.Set(key, product, 1*time.Hour)
								atomic.AddInt64(&successRequests, 1)
							}
							atomic.AddInt64(&dbQueries, 1)
						}
					} else if operation < 0.9 {
						// å†™å…¥æ“ä½œ
						data := map[string]interface{}{
							"id":    productID,
							"name":  fmt.Sprintf("Product %d", productID),
							"price": rand.Float64() * 1000,
						}

						if err := system.CacheManager.Set(key, data, 1*time.Hour); err == nil {
							atomic.AddInt64(&successRequests, 1)
						}
						atomic.AddInt64(&cacheOperations, 1)
					} else {
						// æ›´æ–°æ“ä½œ
						updates := map[string]interface{}{
							"price": fmt.Sprintf("%.2f", rand.Float64()*1000+10),
						}

						if err := system.ConsistencyMgr.SyncCache(key, "products", productID, updates); err == nil {
							atomic.AddInt64(&successRequests, 1)
						}
					}

					duration := time.Since(requestStart)
					atomic.AddInt64(&totalRequests, 1)
					atomic.AddInt64(&totalResponseTime, int64(duration))

					// è®°å½•å“åº”æ—¶é—´ç”¨äºP95/P99è®¡ç®—
					responseTimesMutex.Lock()
					responseTimes = append(responseTimes, duration)
					responseTimesMutex.Unlock()

					// è®°å½•ç›‘æ§æ•°æ®
					system.MonitoringMgr.RecordResponseTime(duration)
					system.MonitoringMgr.RecordHotKey(key, operation < 0.7)

					time.Sleep(time.Microsecond * 30)
				}
			}
		}()
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—æŒ‡æ ‡
	totalReq := atomic.LoadInt64(&totalRequests)
	successReq := atomic.LoadInt64(&successRequests)
	hits := atomic.LoadInt64(&cacheHits)
	misses := atomic.LoadInt64(&cacheMisses)
	avgResponseTime := time.Duration(atomic.LoadInt64(&totalResponseTime) / totalReq)
	qps := float64(totalReq) / actualDuration.Seconds()
	errorRate := float64(totalReq-successReq) / float64(totalReq) * 100
	hitRate := float64(hits) / float64(hits+misses) * 100

	// è®¡ç®—P95å’ŒP99å“åº”æ—¶é—´
	responseTimesMutex.Lock()
	p95Time, p99Time := calculatePercentiles(responseTimes)
	responseTimesMutex.Unlock()

	return &PerformanceVerificationResult{
		TestName:            "ç»¼åˆæ€§èƒ½æµ‹è¯•",
		Timestamp:           time.Now(),
		ConcurrentUsers:     concurrency,
		TestDuration:        actualDuration,
		TotalRequests:       totalReq,
		SuccessRequests:     successReq,
		FailedRequests:      totalReq - successReq,
		AverageResponseTime: avgResponseTime,
		P95ResponseTime:     p95Time,
		P99ResponseTime:     p99Time,
		QPS:                 qps,
		ErrorRate:           errorRate,
		DatabaseQueries:     atomic.LoadInt64(&dbQueries),
		CacheOperations:     atomic.LoadInt64(&cacheOperations),
		CacheHitRate:        hitRate,
		CacheMissRate:       100 - hitRate,
	}
}

// calculatePercentiles è®¡ç®—å“åº”æ—¶é—´ç™¾åˆ†ä½æ•°
func calculatePercentiles(times []time.Duration) (p95, p99 time.Duration) {
	if len(times) == 0 {
		return 0, 0
	}

	// ç®€å•æ’åº
	for i := 0; i < len(times)-1; i++ {
		for j := 0; j < len(times)-i-1; j++ {
			if times[j] > times[j+1] {
				times[j], times[j+1] = times[j+1], times[j]
			}
		}
	}

	p95Index := int(float64(len(times)) * 0.95)
	p99Index := int(float64(len(times)) * 0.99)

	if p95Index >= len(times) {
		p95Index = len(times) - 1
	}
	if p99Index >= len(times) {
		p99Index = len(times) - 1
	}

	return times[p95Index], times[p99Index]
}

// verifyPerformanceTargets éªŒè¯æ€§èƒ½ç›®æ ‡
func verifyPerformanceTargets(result *PerformanceVerificationResult, targets *PerformanceTargets) (bool, []string) {
	var failures []string

	// æ£€æŸ¥QPS
	if result.QPS < targets.MinQPS {
		failures = append(failures, fmt.Sprintf("QPSæœªè¾¾æ ‡: %.2f < %.2f", result.QPS, targets.MinQPS))
	}

	// æ£€æŸ¥å¹³å‡å“åº”æ—¶é—´
	if result.AverageResponseTime > targets.MaxAverageResponseTime {
		failures = append(failures, fmt.Sprintf("å¹³å‡å“åº”æ—¶é—´è¶…æ ‡: %v > %v", result.AverageResponseTime, targets.MaxAverageResponseTime))
	}

	// æ£€æŸ¥P95å“åº”æ—¶é—´
	if result.P95ResponseTime > targets.MaxP95ResponseTime {
		failures = append(failures, fmt.Sprintf("P95å“åº”æ—¶é—´è¶…æ ‡: %v > %v", result.P95ResponseTime, targets.MaxP95ResponseTime))
	}

	// æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
	if result.CacheHitRate < targets.MinCacheHitRate {
		failures = append(failures, fmt.Sprintf("ç¼“å­˜å‘½ä¸­ç‡æœªè¾¾æ ‡: %.2f%% < %.2f%%", result.CacheHitRate, targets.MinCacheHitRate))
	}

	// æ£€æŸ¥é”™è¯¯ç‡
	if result.ErrorRate > targets.MaxErrorRate {
		failures = append(failures, fmt.Sprintf("é”™è¯¯ç‡è¶…æ ‡: %.2f%% > %.2f%%", result.ErrorRate, targets.MaxErrorRate))
	}

	return len(failures) == 0, failures
}

// printFinalResults æ‰“å°æœ€ç»ˆç»“æœ
func printFinalResults(result *PerformanceVerificationResult, targets *PerformanceTargets, passed bool, reasons []string) {
	fmt.Printf("\nğŸ“Š ç»¼åˆæ€§èƒ½æµ‹è¯•ç»“æœ:\n")
	fmt.Printf("   - æµ‹è¯•åç§°: %s\n", result.TestName)
	fmt.Printf("   - æµ‹è¯•æ—¶é—´: %v\n", result.Timestamp.Format("2006-01-02 15:04:05"))
	fmt.Printf("   - å¹¶å‘ç”¨æˆ·: %d\n", result.ConcurrentUsers)
	fmt.Printf("   - æµ‹è¯•æ—¶é•¿: %v\n", result.TestDuration)
	fmt.Printf("   - æ€»è¯·æ±‚æ•°: %d\n", result.TotalRequests)
	fmt.Printf("   - æˆåŠŸè¯·æ±‚: %d\n", result.SuccessRequests)
	fmt.Printf("   - å¤±è´¥è¯·æ±‚: %d\n", result.FailedRequests)

	fmt.Printf("\nâš¡ æ€§èƒ½æŒ‡æ ‡:\n")
	fmt.Printf("   - QPS: %.2f (ç›®æ ‡: â‰¥%.0f) %s\n",
		result.QPS, targets.MinQPS, getStatusIcon(result.QPS >= targets.MinQPS))
	fmt.Printf("   - å¹³å‡å“åº”æ—¶é—´: %v (ç›®æ ‡: â‰¤%v) %s\n",
		result.AverageResponseTime, targets.MaxAverageResponseTime,
		getStatusIcon(result.AverageResponseTime <= targets.MaxAverageResponseTime))
	fmt.Printf("   - P95å“åº”æ—¶é—´: %v (ç›®æ ‡: â‰¤%v) %s\n",
		result.P95ResponseTime, targets.MaxP95ResponseTime,
		getStatusIcon(result.P95ResponseTime <= targets.MaxP95ResponseTime))
	fmt.Printf("   - P99å“åº”æ—¶é—´: %v\n", result.P99ResponseTime)

	fmt.Printf("\nğŸ¯ ç¼“å­˜æŒ‡æ ‡:\n")
	fmt.Printf("   - ç¼“å­˜å‘½ä¸­ç‡: %.2f%% (ç›®æ ‡: â‰¥%.1f%%) %s\n",
		result.CacheHitRate, targets.MinCacheHitRate,
		getStatusIcon(result.CacheHitRate >= targets.MinCacheHitRate))
	fmt.Printf("   - ç¼“å­˜æœªå‘½ä¸­ç‡: %.2f%%\n", result.CacheMissRate)
	fmt.Printf("   - ç¼“å­˜æ“ä½œæ•°: %d\n", result.CacheOperations)
	fmt.Printf("   - æ•°æ®åº“æŸ¥è¯¢æ•°: %d\n", result.DatabaseQueries)

	fmt.Printf("\nğŸ” è´¨é‡æŒ‡æ ‡:\n")
	fmt.Printf("   - é”™è¯¯ç‡: %.2f%% (ç›®æ ‡: â‰¤%.1f%%) %s\n",
		result.ErrorRate, targets.MaxErrorRate,
		getStatusIcon(result.ErrorRate <= targets.MaxErrorRate))

	if result.DatabaseQueries > 0 {
		dbReduction := (1 - float64(result.DatabaseQueries)/float64(result.TotalRequests)) * 100
		fmt.Printf("   - æ•°æ®åº“æŸ¥è¯¢å‡å°‘: %.2f%% (ç›®æ ‡: â‰¥%.1f%%) %s\n",
			dbReduction, targets.MinDatabaseQueryReduction,
			getStatusIcon(dbReduction >= targets.MinDatabaseQueryReduction))
	}

	fmt.Printf("\nğŸ“ˆ éªŒæ”¶ç»“æœ: %s\n", getStatusIcon(passed))
	if passed {
		fmt.Printf("   ğŸ‰ æ‰€æœ‰æ€§èƒ½ç›®æ ‡å‡å·²è¾¾æˆï¼\n")
	} else {
		fmt.Printf("   âš ï¸ ä»¥ä¸‹ç›®æ ‡æœªè¾¾æˆ:\n")
		for _, reason := range reasons {
			fmt.Printf("     - %s\n", reason)
		}
	}
}

// getStatusIcon è·å–çŠ¶æ€å›¾æ ‡
func getStatusIcon(passed bool) string {
	if passed {
		return "âœ…"
	}
	return "âŒ"
}
