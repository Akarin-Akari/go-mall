package performance

import (
	"context"
	"fmt"
	"math/rand"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"mall-go/internal/model"
	"mall-go/pkg/cache"
	"mall-go/pkg/logger"

	"github.com/stretchr/testify/assert"
)

// ConcurrentStressTestSuite å¹¶å‘å‹åŠ›æµ‹è¯•å¥—ä»¶
type ConcurrentStressTestSuite struct {
	*CachePerformanceTestSuite
}

// StressTestResult å‹åŠ›æµ‹è¯•ç»“æœ
type StressTestResult struct {
	*PerformanceResult
	ConcurrentUsers    int           `json:"concurrent_users"`
	TestDuration       time.Duration `json:"test_duration"`
	PeakQPS           float64       `json:"peak_qps"`
	MemoryUsageMB     float64       `json:"memory_usage_mb"`
	CacheHitRate      float64       `json:"cache_hit_rate"`
	DataConsistency   float64       `json:"data_consistency"`
	SystemStability   float64       `json:"system_stability"`
}

// SetupConcurrentStressTest è®¾ç½®å¹¶å‘å‹åŠ›æµ‹è¯•ç¯å¢ƒ
func SetupConcurrentStressTest(t *testing.T) *ConcurrentStressTestSuite {
	cacheTestSuite := SetupCachePerformanceTest(t)
	if cacheTestSuite == nil {
		return nil
	}
	
	return &ConcurrentStressTestSuite{
		CachePerformanceTestSuite: cacheTestSuite,
	}
}

// CleanupConcurrentStressTest æ¸…ç†å¹¶å‘å‹åŠ›æµ‹è¯•ç¯å¢ƒ
func (suite *ConcurrentStressTestSuite) CleanupConcurrentStressTest() {
	suite.CleanupCachePerformanceTest()
}

// TestHighConcurrencyCache æµ‹è¯•é«˜å¹¶å‘ç¼“å­˜æ€§èƒ½
func TestHighConcurrencyCache(t *testing.T) {
	suite := SetupConcurrentStressTest(t)
	if suite == nil {
		return
	}
	defer suite.CleanupConcurrentStressTest()
	
	// åˆ›å»ºæµ‹è¯•æ•°æ®
	suite.CreateCacheTestData(t)
	
	t.Run("é«˜å¹¶å‘ç¼“å­˜è¯»å†™å‹åŠ›æµ‹è¯•", func(t *testing.T) {
		concurrency := 500
		testDuration := 30 * time.Second
		
		var totalRequests int64
		var successRequests int64
		var cacheHits int64
		var cacheMisses int64
		var errors int64
		
		ctx, cancel := context.WithTimeout(context.Background(), testDuration)
		defer cancel()
		
		var wg sync.WaitGroup
		startTime := time.Now()
		
		// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
		for i := 0; i < concurrency; i++ {
			wg.Add(1)
			go func(workerID int) {
				defer wg.Done()
				
				for {
					select {
					case <-ctx.Done():
						return
					default:
						// æ‰§è¡Œç¼“å­˜æ“ä½œ
						atomic.AddInt64(&totalRequests, 1)
						
						// 80%è¯»æ“ä½œï¼Œ20%å†™æ“ä½œ
						if rand.Float64() < 0.8 {
							// è¯»æ“ä½œ
							productID := uint(rand.Intn(1000) + 1)
							key := suite.keyManager.GenerateProductKey(productID)
							
							// å°è¯•ä»ç¼“å­˜è·å–
							_, err := suite.cacheManager.Get(key)
							if err == nil {
								atomic.AddInt64(&cacheHits, 1)
								atomic.AddInt64(&successRequests, 1)
							} else {
								atomic.AddInt64(&cacheMisses, 1)
								
								// ä»æ•°æ®åº“åŠ è½½å¹¶ç¼“å­˜
								var product model.Product
								if dbErr := suite.db.Where("id = ?", productID).First(&product).Error; dbErr == nil {
									suite.cacheManager.Set(key, product, 1*time.Hour)
									atomic.AddInt64(&successRequests, 1)
								} else {
									atomic.AddInt64(&errors, 1)
								}
							}
						} else {
							// å†™æ“ä½œ
							productID := uint(rand.Intn(1000) + 1)
							key := suite.keyManager.GenerateProductKey(productID)
							
							data := map[string]interface{}{
								"id":    productID,
								"name":  fmt.Sprintf("Product %d", productID),
								"price": rand.Float64() * 1000,
							}
							
							if err := suite.cacheManager.Set(key, data, 1*time.Hour); err == nil {
								atomic.AddInt64(&successRequests, 1)
							} else {
								atomic.AddInt64(&errors, 1)
							}
						}
						
						// çŸ­æš‚ä¼‘æ¯é¿å…è¿‡åº¦æ¶ˆè€—CPU
						time.Sleep(time.Microsecond * 100)
					}
				}
			}(i)
		}
		
		// ç­‰å¾…æ‰€æœ‰å·¥ä½œè€…å®Œæˆ
		wg.Wait()
		actualDuration := time.Since(startTime)
		
		// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
		totalReq := atomic.LoadInt64(&totalRequests)
		successReq := atomic.LoadInt64(&successRequests)
		hits := atomic.LoadInt64(&cacheHits)
		misses := atomic.LoadInt64(&cacheMisses)
		errs := atomic.LoadInt64(&errors)
		
		qps := float64(totalReq) / actualDuration.Seconds()
		hitRate := float64(hits) / float64(hits+misses) * 100
		successRate := float64(successReq) / float64(totalReq) * 100
		errorRate := float64(errs) / float64(totalReq) * 100
		
		// éªŒè¯æ€§èƒ½æŒ‡æ ‡
		assert.Greater(t, qps, 5000.0, "QPSåº”>5000")
		assert.GreaterOrEqual(t, hitRate, 60.0, "ç¼“å­˜å‘½ä¸­ç‡åº”â‰¥60%")
		assert.GreaterOrEqual(t, successRate, 95.0, "æˆåŠŸç‡åº”â‰¥95%")
		assert.Less(t, errorRate, 5.0, "é”™è¯¯ç‡åº”<5%")
		
		t.Logf("âœ… é«˜å¹¶å‘ç¼“å­˜å‹åŠ›æµ‹è¯•é€šè¿‡")
		t.Logf("   - å¹¶å‘ç”¨æˆ·æ•°: %d", concurrency)
		t.Logf("   - æµ‹è¯•æ—¶é•¿: %v", actualDuration)
		t.Logf("   - æ€»è¯·æ±‚æ•°: %d", totalReq)
		t.Logf("   - QPS: %.2f (ç›®æ ‡: >5000)", qps)
		t.Logf("   - ç¼“å­˜å‘½ä¸­ç‡: %.2f%% (ç›®æ ‡: â‰¥60%%)", hitRate)
		t.Logf("   - æˆåŠŸç‡: %.2f%% (ç›®æ ‡: â‰¥95%%)", successRate)
		t.Logf("   - é”™è¯¯ç‡: %.2f%% (ç›®æ ‡: <5%%)", errorRate)
	})
}

// TestConcurrentConsistency æµ‹è¯•å¹¶å‘ä¸€è‡´æ€§
func TestConcurrentConsistency(t *testing.T) {
	suite := SetupConcurrentStressTest(t)
	if suite == nil {
		return
	}
	defer suite.CleanupConcurrentStressTest()
	
	// åˆ›å»ºæµ‹è¯•æ•°æ®
	suite.CreateCacheTestData(t)
	
	t.Run("å¹¶å‘ä¸€è‡´æ€§å‹åŠ›æµ‹è¯•", func(t *testing.T) {
		concurrency := 100
		testDuration := 20 * time.Second
		
		var totalUpdates int64
		var successUpdates int64
		var consistencyChecks int64
		var consistentData int64
		
		ctx, cancel := context.WithTimeout(context.Background(), testDuration)
		defer cancel()
		
		var wg sync.WaitGroup
		startTime := time.Now()
		
		// å¯åŠ¨å¹¶å‘æ›´æ–°å·¥ä½œè€…
		for i := 0; i < concurrency/2; i++ {
			wg.Add(1)
			go func(workerID int) {
				defer wg.Done()
				
				for {
					select {
					case <-ctx.Done():
						return
					default:
						// éšæœºé€‰æ‹©å•†å“è¿›è¡Œæ›´æ–°
						productID := uint(rand.Intn(100) + 1)
						newPrice := fmt.Sprintf("%.2f", rand.Float64()*1000+10)
						
						updates := map[string]interface{}{
							"price": newPrice,
						}
						
						// é€šè¿‡ä¸€è‡´æ€§ç®¡ç†å™¨æ›´æ–°
						cacheKey := suite.keyManager.GenerateProductKey(productID)
						if err := suite.consistencyMgr.SyncCache(cacheKey, "products", productID, updates); err == nil {
							atomic.AddInt64(&successUpdates, 1)
						}
						atomic.AddInt64(&totalUpdates, 1)
						
						time.Sleep(time.Millisecond * 10)
					}
				}
			}(i)
		}
		
		// å¯åŠ¨å¹¶å‘ä¸€è‡´æ€§æ£€æŸ¥å·¥ä½œè€…
		for i := 0; i < concurrency/2; i++ {
			wg.Add(1)
			go func(workerID int) {
				defer wg.Done()
				
				for {
					select {
					case <-ctx.Done():
						return
					default:
						// éšæœºæ£€æŸ¥å•†å“æ•°æ®ä¸€è‡´æ€§
						productID := uint(rand.Intn(100) + 1)
						cacheKey := suite.keyManager.GenerateProductKey(productID)
						
						// ä»ç¼“å­˜è·å–æ•°æ®
						cachedData, cacheErr := suite.cacheManager.Get(cacheKey)
						
						// ä»æ•°æ®åº“è·å–æ•°æ®
						var dbProduct model.Product
						dbErr := suite.db.Where("id = ?", productID).First(&dbProduct).Error
						
						atomic.AddInt64(&consistencyChecks, 1)
						
						// ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
						if cacheErr == nil && dbErr == nil && cachedData != nil {
							atomic.AddInt64(&consistentData, 1)
						} else if cacheErr != nil && dbErr != nil {
							// éƒ½ä¸å­˜åœ¨ä¹Ÿç®—ä¸€è‡´
							atomic.AddInt64(&consistentData, 1)
						}
						
						time.Sleep(time.Millisecond * 5)
					}
				}
			}(i)
		}
		
		// ç­‰å¾…æ‰€æœ‰å·¥ä½œè€…å®Œæˆ
		wg.Wait()
		actualDuration := time.Since(startTime)
		
		// è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡
		totalUpd := atomic.LoadInt64(&totalUpdates)
		successUpd := atomic.LoadInt64(&successUpdates)
		totalChecks := atomic.LoadInt64(&consistencyChecks)
		consistent := atomic.LoadInt64(&consistentData)
		
		updateSuccessRate := float64(successUpd) / float64(totalUpd) * 100
		consistencyRate := float64(consistent) / float64(totalChecks) * 100
		updateQPS := float64(totalUpd) / actualDuration.Seconds()
		
		// éªŒè¯ä¸€è‡´æ€§æŒ‡æ ‡
		assert.GreaterOrEqual(t, updateSuccessRate, 90.0, "æ›´æ–°æˆåŠŸç‡åº”â‰¥90%")
		assert.GreaterOrEqual(t, consistencyRate, 85.0, "æ•°æ®ä¸€è‡´æ€§åº”â‰¥85%")
		assert.Greater(t, updateQPS, 100.0, "æ›´æ–°QPSåº”>100")
		
		t.Logf("âœ… å¹¶å‘ä¸€è‡´æ€§å‹åŠ›æµ‹è¯•é€šè¿‡")
		t.Logf("   - å¹¶å‘ç”¨æˆ·æ•°: %d", concurrency)
		t.Logf("   - æµ‹è¯•æ—¶é•¿: %v", actualDuration)
		t.Logf("   - æ€»æ›´æ–°æ•°: %d", totalUpd)
		t.Logf("   - æ›´æ–°æˆåŠŸç‡: %.2f%% (ç›®æ ‡: â‰¥90%%)", updateSuccessRate)
		t.Logf("   - æ•°æ®ä¸€è‡´æ€§: %.2f%% (ç›®æ ‡: â‰¥85%%)", consistencyRate)
		t.Logf("   - æ›´æ–°QPS: %.2f (ç›®æ ‡: >100)", updateQPS)
		t.Logf("   - ä¸€è‡´æ€§æ£€æŸ¥æ¬¡æ•°: %d", totalChecks)
	})
}

// TestSystemStabilityUnderLoad æµ‹è¯•ç³»ç»Ÿè´Ÿè½½ç¨³å®šæ€§
func TestSystemStabilityUnderLoad(t *testing.T) {
	suite := SetupConcurrentStressTest(t)
	if suite == nil {
		return
	}
	defer suite.CleanupConcurrentStressTest()
	
	// åˆ›å»ºæµ‹è¯•æ•°æ®
	suite.CreateCacheTestData(t)
	
	t.Run("ç³»ç»Ÿè´Ÿè½½ç¨³å®šæ€§æµ‹è¯•", func(t *testing.T) {
		// æ¸è¿›å¼å¢åŠ è´Ÿè½½
		loadLevels := []int{50, 100, 200, 300, 500}
		testDurationPerLevel := 10 * time.Second
		
		for _, concurrency := range loadLevels {
			t.Logf("ğŸ”„ æµ‹è¯•è´Ÿè½½çº§åˆ«: %d å¹¶å‘ç”¨æˆ·", concurrency)
			
			var totalRequests int64
			var successRequests int64
			var errors int64
			
			ctx, cancel := context.WithTimeout(context.Background(), testDurationPerLevel)
			
			var wg sync.WaitGroup
			startTime := time.Now()
			
			// å¯åŠ¨å¹¶å‘å·¥ä½œè€…
			for i := 0; i < concurrency; i++ {
				wg.Add(1)
				go func() {
					defer wg.Done()
					
					for {
						select {
						case <-ctx.Done():
							return
						default:
							atomic.AddInt64(&totalRequests, 1)
							
							// æ··åˆæ“ä½œï¼šè¯»å–ã€å†™å…¥ã€æ›´æ–°
							operation := rand.Intn(3)
							productID := uint(rand.Intn(500) + 1)
							key := suite.keyManager.GenerateProductKey(productID)
							
							switch operation {
							case 0: // è¯»å–
								if _, err := suite.cacheManager.Get(key); err == nil {
									atomic.AddInt64(&successRequests, 1)
								} else {
									atomic.AddInt64(&errors, 1)
								}
							case 1: // å†™å…¥
								data := map[string]interface{}{
									"id":   productID,
									"name": fmt.Sprintf("Product %d", productID),
								}
								if err := suite.cacheManager.Set(key, data, 1*time.Hour); err == nil {
									atomic.AddInt64(&successRequests, 1)
								} else {
									atomic.AddInt64(&errors, 1)
								}
							case 2: // åˆ é™¤
								if err := suite.cacheManager.Delete(key); err == nil {
									atomic.AddInt64(&successRequests, 1)
								} else {
									atomic.AddInt64(&errors, 1)
								}
							}
							
							time.Sleep(time.Microsecond * 200)
						}
					}
				}()
			}
			
			wg.Wait()
			cancel()
			actualDuration := time.Since(startTime)
			
			// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
			totalReq := atomic.LoadInt64(&totalRequests)
			successReq := atomic.LoadInt64(&successRequests)
			errs := atomic.LoadInt64(&errors)
			
			qps := float64(totalReq) / actualDuration.Seconds()
			successRate := float64(successReq) / float64(totalReq) * 100
			errorRate := float64(errs) / float64(totalReq) * 100
			
			// éªŒè¯ç³»ç»Ÿç¨³å®šæ€§
			assert.GreaterOrEqual(t, successRate, 90.0, fmt.Sprintf("è´Ÿè½½%dä¸‹æˆåŠŸç‡åº”â‰¥90%%", concurrency))
			assert.Less(t, errorRate, 10.0, fmt.Sprintf("è´Ÿè½½%dä¸‹é”™è¯¯ç‡åº”<10%%", concurrency))
			
			t.Logf("   âœ… è´Ÿè½½çº§åˆ« %d: QPS=%.2f, æˆåŠŸç‡=%.2f%%, é”™è¯¯ç‡=%.2f%%", 
				concurrency, qps, successRate, errorRate)
			
			// çŸ­æš‚ä¼‘æ¯è®©ç³»ç»Ÿæ¢å¤
			time.Sleep(2 * time.Second)
		}
		
		t.Logf("âœ… ç³»ç»Ÿè´Ÿè½½ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
	})
}
