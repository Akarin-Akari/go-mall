# å®æˆ˜ç¯‡ç¬¬å››ç« ï¼šæ¶ˆæ¯é˜Ÿåˆ—é›†æˆä¸å®è·µ ğŸš€

> *"åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ¶ˆæ¯é˜Ÿåˆ—æ˜¯è§£è€¦æœåŠ¡ã€æé«˜ç³»ç»Ÿå¯é æ€§çš„æ ¸å¿ƒç»„ä»¶ã€‚æŒæ¡æ¶ˆæ¯é˜Ÿåˆ—ï¼Œå°±æŒæ¡äº†æ„å»ºé«˜å¯ç”¨ç³»ç»Ÿçš„å…³é”®æŠ€èƒ½ï¼"* ğŸ’ª

## ğŸ“š æœ¬ç« å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡ï¼š

- ğŸ¯ **æ¶ˆæ¯é˜Ÿåˆ—æ ¸å¿ƒæ¦‚å¿µ**ï¼šç†è§£æ¶ˆæ¯é˜Ÿåˆ—çš„ä½œç”¨ã€ä¼˜åŠ¿å’Œåº”ç”¨åœºæ™¯
- ğŸ› ï¸ **ä¸»æµMQæ¡†æ¶å¯¹æ¯”**ï¼šRabbitMQ vs Kafka vs NSQ vs Redis Stream
- ğŸ—ï¸ **Goè¯­è¨€é›†æˆå®è·µ**ï¼šåœ¨Goé¡¹ç›®ä¸­é›†æˆå’Œä½¿ç”¨å„ç§æ¶ˆæ¯é˜Ÿåˆ—
- ğŸ“¨ **æ¶ˆæ¯æ¨¡å¼è®¾è®¡**ï¼šå‘å¸ƒè®¢é˜…ã€ç‚¹å¯¹ç‚¹ã€è¯·æ±‚å“åº”ç­‰æ¶ˆæ¯æ¨¡å¼
- âš¡ **é«˜çº§ç‰¹æ€§åº”ç”¨**ï¼šæ¶ˆæ¯æŒä¹…åŒ–ã€äº‹åŠ¡ã€æ­»ä¿¡é˜Ÿåˆ—ã€å»¶è¿Ÿæ¶ˆæ¯
- ğŸª **äº‹ä»¶é©±åŠ¨æ¶æ„**ï¼šåŸºäºæ¶ˆæ¯é˜Ÿåˆ—æ„å»ºäº‹ä»¶é©±åŠ¨çš„å¾®æœåŠ¡æ¶æ„
- ğŸ”§ **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**ï¼šæ¶ˆæ¯é˜Ÿåˆ—çš„æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§
- ğŸ¢ **ä¼ä¸šçº§å®è·µ**ï¼šç»“åˆmall-goé¡¹ç›®çš„çœŸå®ä¸šåŠ¡åœºæ™¯

---

## ğŸŒŸ æ¶ˆæ¯é˜Ÿåˆ—æ¦‚è¿°

### ä»€ä¹ˆæ˜¯æ¶ˆæ¯é˜Ÿåˆ—ï¼Ÿ

æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆMessage Queueï¼Œç®€ç§°MQï¼‰æ˜¯ä¸€ç§åº”ç”¨ç¨‹åºé—´çš„é€šä¿¡æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¶ˆæ¯çš„ä¼ è¾“è¿‡ç¨‹ä¸­ä¿å­˜æ¶ˆæ¯æ¥å®ç°åº”ç”¨ç¨‹åºé—´çš„å¼‚æ­¥é€šä¿¡ã€‚

```go
// æ¶ˆæ¯é˜Ÿåˆ—çš„åŸºæœ¬æ¦‚å¿µç¤ºä¾‹
type Message struct {
    ID        string                 `json:"id"`
    Topic     string                 `json:"topic"`
    Payload   map[string]interface{} `json:"payload"`
    Timestamp int64                  `json:"timestamp"`
    Headers   map[string]string      `json:"headers"`
}

// ç”Ÿäº§è€…æ¥å£
type Producer interface {
    Send(ctx context.Context, topic string, message *Message) error
    SendBatch(ctx context.Context, topic string, messages []*Message) error
    Close() error
}

// æ¶ˆè´¹è€…æ¥å£
type Consumer interface {
    Subscribe(ctx context.Context, topic string, handler MessageHandler) error
    Unsubscribe(topic string) error
    Close() error
}

// æ¶ˆæ¯å¤„ç†å™¨
type MessageHandler func(ctx context.Context, message *Message) error
```

### æ¶ˆæ¯é˜Ÿåˆ—çš„æ ¸å¿ƒä¼˜åŠ¿

#### 1. ç³»ç»Ÿè§£è€¦ ğŸ”—
```go
// âŒ ç´§è€¦åˆçš„åŒæ­¥è°ƒç”¨
func ProcessOrder(order *Order) error {
    // ç›´æ¥è°ƒç”¨å„ä¸ªæœåŠ¡
    if err := inventoryService.UpdateStock(order.Items); err != nil {
        return err
    }
    if err := paymentService.ProcessPayment(order.Payment); err != nil {
        return err
    }
    if err := notificationService.SendNotification(order.UserID); err != nil {
        return err
    }
    return nil
}

// âœ… é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—è§£è€¦
func ProcessOrderWithMQ(order *Order, producer Producer) error {
    // å‘å¸ƒè®¢å•åˆ›å»ºäº‹ä»¶
    event := &Message{
        ID:      generateID(),
        Topic:   "order.created",
        Payload: map[string]interface{}{
            "order_id": order.ID,
            "user_id":  order.UserID,
            "items":    order.Items,
            "amount":   order.Amount,
        },
        Timestamp: time.Now().Unix(),
    }
    
    return producer.Send(context.Background(), "order.created", event)
}
```

#### 2. å¼‚æ­¥å¤„ç† âš¡
```go
// å¼‚æ­¥å¤„ç†è®¢å•ç›¸å…³ä¸šåŠ¡
func SetupOrderEventHandlers(consumer Consumer) {
    // åº“å­˜æœåŠ¡ç›‘å¬è®¢å•äº‹ä»¶
    consumer.Subscribe(context.Background(), "order.created", func(ctx context.Context, msg *Message) error {
        orderID := msg.Payload["order_id"].(string)
        items := msg.Payload["items"].([]interface{})
        
        // å¼‚æ­¥æ›´æ–°åº“å­˜
        return inventoryService.UpdateStockAsync(orderID, items)
    })
    
    // æ”¯ä»˜æœåŠ¡ç›‘å¬è®¢å•äº‹ä»¶
    consumer.Subscribe(context.Background(), "order.created", func(ctx context.Context, msg *Message) error {
        orderID := msg.Payload["order_id"].(string)
        amount := msg.Payload["amount"].(float64)
        
        // å¼‚æ­¥å¤„ç†æ”¯ä»˜
        return paymentService.ProcessPaymentAsync(orderID, amount)
    })
    
    // é€šçŸ¥æœåŠ¡ç›‘å¬è®¢å•äº‹ä»¶
    consumer.Subscribe(context.Background(), "order.created", func(ctx context.Context, msg *Message) error {
        userID := msg.Payload["user_id"].(string)
        orderID := msg.Payload["order_id"].(string)
        
        // å¼‚æ­¥å‘é€é€šçŸ¥
        return notificationService.SendNotificationAsync(userID, orderID)
    })
}
```

#### 3. æµé‡å‰Šå³° ğŸ“ˆ
```go
// ç§’æ€åœºæ™¯çš„æµé‡å‰Šå³°
type SeckillService struct {
    producer Producer
    redis    *redis.Client
}

func (s *SeckillService) HandleSeckillRequest(ctx context.Context, userID, productID string) error {
    // å¿«é€Ÿå“åº”ç”¨æˆ·è¯·æ±‚
    requestID := generateRequestID()
    
    // å°†ç§’æ€è¯·æ±‚æ”¾å…¥é˜Ÿåˆ—
    message := &Message{
        ID:    requestID,
        Topic: "seckill.request",
        Payload: map[string]interface{}{
            "request_id": requestID,
            "user_id":    userID,
            "product_id": productID,
            "timestamp":  time.Now().Unix(),
        },
    }
    
    if err := s.producer.Send(ctx, "seckill.request", message); err != nil {
        return err
    }
    
    // ç«‹å³è¿”å›ï¼Œå‘ŠçŸ¥ç”¨æˆ·è¯·æ±‚å·²æäº¤
    return nil
}

// å¼‚æ­¥å¤„ç†ç§’æ€è¯·æ±‚
func (s *SeckillService) ProcessSeckillRequests(consumer Consumer) {
    consumer.Subscribe(context.Background(), "seckill.request", func(ctx context.Context, msg *Message) error {
        userID := msg.Payload["user_id"].(string)
        productID := msg.Payload["product_id"].(string)
        
        // æ£€æŸ¥åº“å­˜å¹¶å¤„ç†ç§’æ€
        success, err := s.processSeckillLogic(ctx, userID, productID)
        if err != nil {
            return err
        }
        
        // å‘å¸ƒå¤„ç†ç»“æœ
        resultMsg := &Message{
            ID:    generateID(),
            Topic: "seckill.result",
            Payload: map[string]interface{}{
                "user_id":    userID,
                "product_id": productID,
                "success":    success,
                "timestamp":  time.Now().Unix(),
            },
        }
        
        return s.producer.Send(ctx, "seckill.result", resultMsg)
    })
}
```

### æ¶ˆæ¯é˜Ÿåˆ—åº”ç”¨åœºæ™¯

#### 1. è®¢å•å¤„ç†æµç¨‹ ğŸ“¦
```go
// è®¢å•å¤„ç†çš„å®Œæ•´æ¶ˆæ¯æµ
type OrderEventType string

const (
    OrderCreated   OrderEventType = "order.created"
    OrderPaid      OrderEventType = "order.paid"
    OrderShipped   OrderEventType = "order.shipped"
    OrderDelivered OrderEventType = "order.delivered"
    OrderCancelled OrderEventType = "order.cancelled"
)

// è®¢å•çŠ¶æ€æœºé€šè¿‡æ¶ˆæ¯é©±åŠ¨
func (s *OrderService) CreateOrder(ctx context.Context, order *Order) error {
    // 1. ä¿å­˜è®¢å•åˆ°æ•°æ®åº“
    if err := s.db.Create(order).Error; err != nil {
        return err
    }
    
    // 2. å‘å¸ƒè®¢å•åˆ›å»ºäº‹ä»¶
    return s.publishOrderEvent(ctx, OrderCreated, order)
}

func (s *OrderService) publishOrderEvent(ctx context.Context, eventType OrderEventType, order *Order) error {
    message := &Message{
        ID:    generateID(),
        Topic: string(eventType),
        Payload: map[string]interface{}{
            "order_id":   order.ID,
            "user_id":    order.UserID,
            "status":     order.Status,
            "amount":     order.Amount,
            "items":      order.Items,
            "created_at": order.CreatedAt,
        },
        Headers: map[string]string{
            "event_type": string(eventType),
            "source":     "order-service",
        },
    }
    
    return s.producer.Send(ctx, string(eventType), message)
}
```

#### 2. æ•°æ®åŒæ­¥ ğŸ”„
```go
// ç”¨æˆ·ä¿¡æ¯å˜æ›´åŒæ­¥åˆ°å„ä¸ªæœåŠ¡
type UserSyncService struct {
    producer Producer
}

func (s *UserSyncService) UpdateUserProfile(ctx context.Context, userID string, updates map[string]interface{}) error {
    // 1. æ›´æ–°ä¸»æ•°æ®åº“
    if err := s.updateUserInDB(ctx, userID, updates); err != nil {
        return err
    }
    
    // 2. å‘å¸ƒç”¨æˆ·æ›´æ–°äº‹ä»¶
    message := &Message{
        ID:    generateID(),
        Topic: "user.profile.updated",
        Payload: map[string]interface{}{
            "user_id": userID,
            "updates": updates,
            "version": time.Now().Unix(),
        },
    }
    
    return s.producer.Send(ctx, "user.profile.updated", message)
}

// å„ä¸ªæœåŠ¡ç›‘å¬ç”¨æˆ·æ›´æ–°äº‹ä»¶
func SetupUserSyncHandlers(consumer Consumer) {
    // è®¢å•æœåŠ¡æ›´æ–°ç”¨æˆ·ç¼“å­˜
    consumer.Subscribe(context.Background(), "user.profile.updated", func(ctx context.Context, msg *Message) error {
        userID := msg.Payload["user_id"].(string)
        updates := msg.Payload["updates"].(map[string]interface{})
        
        return orderService.UpdateUserCache(ctx, userID, updates)
    })
    
    // æ¨èæœåŠ¡æ›´æ–°ç”¨æˆ·ç”»åƒ
    consumer.Subscribe(context.Background(), "user.profile.updated", func(ctx context.Context, msg *Message) error {
        userID := msg.Payload["user_id"].(string)
        updates := msg.Payload["updates"].(map[string]interface{})
        
        return recommendService.UpdateUserProfile(ctx, userID, updates)
    })
}
```

#### 3. æ—¥å¿—æ”¶é›†ä¸åˆ†æ ğŸ“Š
```go
// ä¸šåŠ¡æ—¥å¿—æ”¶é›†
type LogCollector struct {
    producer Producer
}

func (lc *LogCollector) LogUserAction(ctx context.Context, action *UserAction) error {
    message := &Message{
        ID:    generateID(),
        Topic: "user.action.log",
        Payload: map[string]interface{}{
            "user_id":    action.UserID,
            "action":     action.Action,
            "resource":   action.Resource,
            "ip":         action.IP,
            "user_agent": action.UserAgent,
            "timestamp":  action.Timestamp,
        },
    }
    
    return lc.producer.Send(ctx, "user.action.log", message)
}

// æ—¥å¿—åˆ†ææœåŠ¡
func SetupLogAnalysis(consumer Consumer) {
    consumer.Subscribe(context.Background(), "user.action.log", func(ctx context.Context, msg *Message) error {
        // å®æ—¶åˆ†æç”¨æˆ·è¡Œä¸º
        return analyticsService.ProcessUserAction(ctx, msg.Payload)
    })
}
```

---

## ğŸ†š ä¸»æµæ¶ˆæ¯é˜Ÿåˆ—å¯¹æ¯”

### æŠ€æœ¯é€‰å‹å¯¹æ¯”è¡¨

| ç‰¹æ€§ | RabbitMQ | Apache Kafka | NSQ | Redis Stream |
|------|----------|--------------|-----|--------------|
| **è¯­è¨€** | Erlang | Scala/Java | Go | C |
| **åè®®** | AMQP | è‡ªå®šä¹‰ | HTTP/TCP | Redisåè®® |
| **æ€§èƒ½** | ä¸­ç­‰ | æé«˜ | é«˜ | é«˜ |
| **å¯é æ€§** | æé«˜ | é«˜ | é«˜ | ä¸­ç­‰ |
| **å¤æ‚åº¦** | é«˜ | é«˜ | ä½ | ä½ |
| **è¿ç»´æˆæœ¬** | é«˜ | é«˜ | ä½ | ä½ |
| **ç”Ÿæ€æˆç†Ÿåº¦** | éå¸¸æˆç†Ÿ | éå¸¸æˆç†Ÿ | è¾ƒæˆç†Ÿ | è¾ƒæ–° |
| **é€‚ç”¨åœºæ™¯** | ä¼ä¸šçº§åº”ç”¨ | å¤§æ•°æ®æµå¤„ç† | ç®€å•æ¶ˆæ¯é˜Ÿåˆ— | è½»é‡çº§é˜Ÿåˆ— |

### è¯¦ç»†å¯¹æ¯”åˆ†æ

#### 1. RabbitMQ ğŸ°
```go
// RabbitMQçš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯
/*
ä¼˜åŠ¿ï¼š
âœ… åŠŸèƒ½ä¸°å¯Œï¼šæ”¯æŒå¤šç§æ¶ˆæ¯æ¨¡å¼ï¼ˆå‘å¸ƒè®¢é˜…ã€è·¯ç”±ã€RPCç­‰ï¼‰
âœ… å¯é æ€§é«˜ï¼šæ”¯æŒæ¶ˆæ¯æŒä¹…åŒ–ã€äº‹åŠ¡ã€ç¡®è®¤æœºåˆ¶
âœ… ç®¡ç†ç•Œé¢ï¼šæä¾›Webç®¡ç†ç•Œé¢ï¼Œè¿ç»´å‹å¥½
âœ… æ’ä»¶ç”Ÿæ€ï¼šä¸°å¯Œçš„æ’ä»¶ç³»ç»Ÿ
âœ… æ ‡å‡†åè®®ï¼šæ”¯æŒAMQPæ ‡å‡†åè®®

åŠ£åŠ¿ï¼š
âŒ æ€§èƒ½ä¸€èˆ¬ï¼šç›¸æ¯”Kafkaæ€§èƒ½è¾ƒä½
âŒ å­¦ä¹ æˆæœ¬ï¼šæ¦‚å¿µè¾ƒå¤šï¼Œå­¦ä¹ æ›²çº¿é™¡å³­
âŒ èµ„æºæ¶ˆè€—ï¼šå†…å­˜å’ŒCPUæ¶ˆè€—è¾ƒé«˜
âŒ æ‰©å±•æ€§ï¼šé›†ç¾¤æ‰©å±•ç›¸å¯¹å¤æ‚

é€‚ç”¨åœºæ™¯ï¼š
ğŸ¯ ä¼ä¸šçº§åº”ç”¨ï¼Œå¯¹å¯é æ€§è¦æ±‚æé«˜
ğŸ¯ å¤æ‚çš„æ¶ˆæ¯è·¯ç”±éœ€æ±‚
ğŸ¯ éœ€è¦äº‹åŠ¡æ”¯æŒçš„åœºæ™¯
ğŸ¯ ä¼ ç»Ÿä¼ä¸šæ¶æ„å‡çº§
*/

// RabbitMQ Goå®¢æˆ·ç«¯ç¤ºä¾‹
import "github.com/streadway/amqp"

type RabbitMQClient struct {
    conn    *amqp.Connection
    channel *amqp.Channel
}

func NewRabbitMQClient(url string) (*RabbitMQClient, error) {
    conn, err := amqp.Dial(url)
    if err != nil {
        return nil, err
    }
    
    ch, err := conn.Channel()
    if err != nil {
        return nil, err
    }
    
    return &RabbitMQClient{
        conn:    conn,
        channel: ch,
    }, nil
}
```

#### 2. Apache Kafka âš¡
```go
// Kafkaçš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯
/*
ä¼˜åŠ¿ï¼š
âœ… æé«˜æ€§èƒ½ï¼šç™¾ä¸‡çº§TPSï¼Œä½å»¶è¿Ÿ
âœ… æ°´å¹³æ‰©å±•ï¼šå¤©ç„¶æ”¯æŒåˆ†å¸ƒå¼ï¼Œæ˜“äºæ‰©å±•
âœ… æŒä¹…åŒ–ï¼šæ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜ï¼Œæ”¯æŒæ•°æ®å›æ”¾
âœ… æµå¤„ç†ï¼šä¸Kafka Streamsé›†æˆï¼Œæ”¯æŒæµå¤„ç†
âœ… ç”Ÿæ€ä¸°å¯Œï¼šä¸å¤§æ•°æ®ç”Ÿæ€æ·±åº¦é›†æˆ

åŠ£åŠ¿ï¼š
âŒ å¤æ‚åº¦é«˜ï¼šé…ç½®å¤æ‚ï¼Œè¿ç»´æˆæœ¬é«˜
âŒ èµ„æºæ¶ˆè€—ï¼šéœ€è¦è¾ƒå¤šå†…å­˜å’Œç£ç›˜ç©ºé—´
âŒ å­¦ä¹ æˆæœ¬ï¼šæ¦‚å¿µè¾ƒå¤šï¼Œéœ€è¦æ·±å…¥ç†è§£
âŒ å®æ—¶æ€§ï¼šä¸é€‚åˆä½å»¶è¿Ÿåœºæ™¯

é€‚ç”¨åœºæ™¯ï¼š
ğŸ¯ å¤§æ•°æ®æµå¤„ç†
ğŸ¯ é«˜ååé‡åœºæ™¯
ğŸ¯ æ—¥å¿—æ”¶é›†å’Œåˆ†æ
ğŸ¯ äº‹ä»¶æº¯æºæ¶æ„
*/

// Kafka Goå®¢æˆ·ç«¯ç¤ºä¾‹
import "github.com/Shopify/sarama"

type KafkaClient struct {
    producer sarama.SyncProducer
    consumer sarama.Consumer
}

func NewKafkaClient(brokers []string) (*KafkaClient, error) {
    config := sarama.NewConfig()
    config.Producer.Return.Successes = true
    
    producer, err := sarama.NewSyncProducer(brokers, config)
    if err != nil {
        return nil, err
    }
    
    consumer, err := sarama.NewConsumer(brokers, config)
    if err != nil {
        return nil, err
    }
    
    return &KafkaClient{
        producer: producer,
        consumer: consumer,
    }, nil
}
```

#### 3. NSQ ğŸš€
```go
// NSQçš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯
/*
ä¼˜åŠ¿ï¼š
âœ… ç®€å•æ˜“ç”¨ï¼šGoåŸç”Ÿï¼Œé…ç½®ç®€å•
âœ… å»ä¸­å¿ƒåŒ–ï¼šæ— å•ç‚¹æ•…éšœ
âœ… é«˜æ€§èƒ½ï¼šçº¯Goå®ç°ï¼Œæ€§èƒ½ä¼˜ç§€
âœ… è¿ç»´å‹å¥½ï¼šå†…ç½®Webç®¡ç†ç•Œé¢
âœ… è‡ªåŠ¨å‘ç°ï¼šæ”¯æŒæœåŠ¡è‡ªåŠ¨å‘ç°

åŠ£åŠ¿ï¼š
âŒ åŠŸèƒ½ç›¸å¯¹ç®€å•ï¼šä¸æ”¯æŒå¤æ‚è·¯ç”±
âŒ ç”Ÿæ€è¾ƒå°ï¼šç›¸æ¯”RabbitMQå’ŒKafkaç”Ÿæ€è¾ƒå°
âŒ æŒä¹…åŒ–æœ‰é™ï¼šæŒä¹…åŒ–åŠŸèƒ½ç›¸å¯¹ç®€å•
âŒ é¡ºåºä¿è¯ï¼šä¸ä¿è¯æ¶ˆæ¯é¡ºåº

é€‚ç”¨åœºæ™¯ï¼š
ğŸ¯ Goå¾®æœåŠ¡æ¶æ„
ğŸ¯ ç®€å•çš„å‘å¸ƒè®¢é˜…éœ€æ±‚
ğŸ¯ å¯¹è¿ç»´æˆæœ¬æ•æ„Ÿçš„åœºæ™¯
ğŸ¯ ä¸­å°å‹é¡¹ç›®
*/

// NSQ Goå®¢æˆ·ç«¯ç¤ºä¾‹
import "github.com/nsqio/go-nsq"

type NSQClient struct {
    producer *nsq.Producer
    consumer *nsq.Consumer
}

func NewNSQClient(nsqdAddr string) (*NSQClient, error) {
    config := nsq.NewConfig()
    
    producer, err := nsq.NewProducer(nsqdAddr, config)
    if err != nil {
        return nil, err
    }
    
    return &NSQClient{
        producer: producer,
    }, nil
}
```

#### 4. Redis Stream ğŸ“¡
```go
// Redis Streamçš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯
/*
ä¼˜åŠ¿ï¼š
âœ… è½»é‡çº§ï¼šåŸºäºRedisï¼Œéƒ¨ç½²ç®€å•
âœ… é«˜æ€§èƒ½ï¼šå†…å­˜å­˜å‚¨ï¼Œæ€§èƒ½ä¼˜ç§€
âœ… æŒä¹…åŒ–ï¼šæ”¯æŒAOFå’ŒRDBæŒä¹…åŒ–
âœ… æ¶ˆè´¹ç»„ï¼šæ”¯æŒæ¶ˆè´¹è€…ç»„æ¨¡å¼
âœ… å­¦ä¹ æˆæœ¬ä½ï¼šåŸºäºç†Ÿæ‚‰çš„Redis

åŠ£åŠ¿ï¼š
âŒ åŠŸèƒ½æœ‰é™ï¼šç›¸æ¯”ä¸“ä¸šMQåŠŸèƒ½è¾ƒå°‘
âŒ å†…å­˜é™åˆ¶ï¼šå—Rediså†…å­˜é™åˆ¶
âŒ ç”Ÿæ€è¾ƒæ–°ï¼šç›¸å¯¹è¾ƒæ–°ï¼Œç”Ÿæ€ä¸å¤Ÿæˆç†Ÿ
âŒ é›†ç¾¤å¤æ‚ï¼šRedisé›†ç¾¤é…ç½®ç›¸å¯¹å¤æ‚

é€‚ç”¨åœºæ™¯ï¼š
ğŸ¯ å·²æœ‰RedisåŸºç¡€è®¾æ–½
ğŸ¯ è½»é‡çº§æ¶ˆæ¯é˜Ÿåˆ—éœ€æ±‚
ğŸ¯ å®æ—¶æ•°æ®æµå¤„ç†
ğŸ¯ ç®€å•çš„äº‹ä»¶é©±åŠ¨æ¶æ„
*/

// Redis Stream Goå®¢æˆ·ç«¯ç¤ºä¾‹
import "github.com/redis/go-redis/v9"

type RedisStreamClient struct {
    rdb *redis.Client
}

func NewRedisStreamClient(addr string) *RedisStreamClient {
    rdb := redis.NewClient(&redis.Options{
        Addr: addr,
    })
    
    return &RedisStreamClient{rdb: rdb}
}
```

---

## ğŸ› ï¸ RabbitMQé›†æˆå®è·µ

RabbitMQæ˜¯åŠŸèƒ½æœ€ä¸°å¯Œçš„æ¶ˆæ¯é˜Ÿåˆ—ä¹‹ä¸€ï¼Œè®©æˆ‘ä»¬æ·±å…¥å­¦ä¹ å¦‚ä½•åœ¨Goé¡¹ç›®ä¸­é›†æˆå’Œä½¿ç”¨RabbitMQã€‚

### åŸºç¡€é…ç½®ä¸è¿æ¥

```go
// æ¥è‡ª mall-go/internal/mq/rabbitmq/client.go
package rabbitmq

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "sync"
    "time"
    
    "github.com/streadway/amqp"
)

// RabbitMQé…ç½®
type Config struct {
    URL          string        `yaml:"url"`
    Exchange     string        `yaml:"exchange"`
    ExchangeType string        `yaml:"exchange_type"`
    Durable      bool          `yaml:"durable"`
    AutoDelete   bool          `yaml:"auto_delete"`
    Internal     bool          `yaml:"internal"`
    NoWait       bool          `yaml:"no_wait"`
    
    // è¿æ¥æ± é…ç½®
    MaxConnections int           `yaml:"max_connections"`
    MaxChannels    int           `yaml:"max_channels"`
    HeartBeat      time.Duration `yaml:"heartbeat"`
    
    // é‡è¿é…ç½®
    ReconnectDelay time.Duration `yaml:"reconnect_delay"`
    MaxRetries     int           `yaml:"max_retries"`
}

// RabbitMQå®¢æˆ·ç«¯
type Client struct {
    config   *Config
    conn     *amqp.Connection
    channels chan *amqp.Channel
    mutex    sync.RWMutex
    closed   bool
}

// åˆ›å»ºRabbitMQå®¢æˆ·ç«¯
func NewClient(config *Config) (*Client, error) {
    client := &Client{
        config:   config,
        channels: make(chan *amqp.Channel, config.MaxChannels),
    }
    
    if err := client.connect(); err != nil {
        return nil, err
    }
    
    // é¢„åˆ›å»ºé€šé“æ± 
    for i := 0; i < config.MaxChannels; i++ {
        ch, err := client.conn.Channel()
        if err != nil {
            return nil, err
        }
        client.channels <- ch
    }
    
    // ç›‘å¬è¿æ¥çŠ¶æ€
    go client.handleConnectionEvents()
    
    return client, nil
}

// å»ºç«‹è¿æ¥
func (c *Client) connect() error {
    var err error
    
    // é…ç½®è¿æ¥å‚æ•°
    config := amqp.Config{
        Heartbeat: c.config.HeartBeat,
        Locale:    "en_US",
    }
    
    c.conn, err = amqp.DialConfig(c.config.URL, config)
    if err != nil {
        return fmt.Errorf("failed to connect to RabbitMQ: %w", err)
    }
    
    log.Printf("Connected to RabbitMQ: %s", c.config.URL)
    return nil
}

// è·å–é€šé“
func (c *Client) getChannel() (*amqp.Channel, error) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    if c.closed {
        return nil, fmt.Errorf("client is closed")
    }
    
    select {
    case ch := <-c.channels:
        return ch, nil
    case <-time.After(5 * time.Second):
        return nil, fmt.Errorf("timeout getting channel")
    }
}

// å½’è¿˜é€šé“
func (c *Client) returnChannel(ch *amqp.Channel) {
    if ch == nil || ch.IsClosed() {
        // åˆ›å»ºæ–°é€šé“æ›¿æ¢
        newCh, err := c.conn.Channel()
        if err != nil {
            log.Printf("Failed to create new channel: %v", err)
            return
        }
        ch = newCh
    }
    
    select {
    case c.channels <- ch:
    default:
        ch.Close() // é€šé“æ± æ»¡äº†ï¼Œå…³é—­é€šé“
    }
}

// å¤„ç†è¿æ¥äº‹ä»¶
func (c *Client) handleConnectionEvents() {
    for {
        reason, ok := <-c.conn.NotifyClose(make(chan *amqp.Error))
        if !ok {
            break
        }
        
        log.Printf("Connection closed: %v", reason)
        
        // å°è¯•é‡è¿
        for i := 0; i < c.config.MaxRetries; i++ {
            time.Sleep(c.config.ReconnectDelay)
            
            if err := c.connect(); err != nil {
                log.Printf("Reconnect attempt %d failed: %v", i+1, err)
                continue
            }
            
            log.Printf("Reconnected to RabbitMQ")
            break
        }
    }
}

// å…³é—­å®¢æˆ·ç«¯
func (c *Client) Close() error {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    if c.closed {
        return nil
    }
    
    c.closed = true
    
    // å…³é—­æ‰€æœ‰é€šé“
    close(c.channels)
    for ch := range c.channels {
        ch.Close()
    }
    
    // å…³é—­è¿æ¥
    return c.conn.Close()
}
```

### RabbitMQç”Ÿäº§è€…å®ç°

```go
// æ¥è‡ª mall-go/internal/mq/rabbitmq/producer.go
package rabbitmq

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/streadway/amqp"
)

// ç”Ÿäº§è€…
type Producer struct {
    client   *Client
    exchange string
}

// åˆ›å»ºç”Ÿäº§è€…
func NewProducer(client *Client, exchange string) (*Producer, error) {
    producer := &Producer{
        client:   client,
        exchange: exchange,
    }

    // å£°æ˜äº¤æ¢æœº
    if err := producer.declareExchange(); err != nil {
        return nil, err
    }

    return producer, nil
}

// å£°æ˜äº¤æ¢æœº
func (p *Producer) declareExchange() error {
    ch, err := p.client.getChannel()
    if err != nil {
        return err
    }
    defer p.client.returnChannel(ch)

    return ch.ExchangeDeclare(
        p.exchange,                    // äº¤æ¢æœºåç§°
        p.client.config.ExchangeType,  // äº¤æ¢æœºç±»å‹
        p.client.config.Durable,       // æ˜¯å¦æŒä¹…åŒ–
        p.client.config.AutoDelete,    // æ˜¯å¦è‡ªåŠ¨åˆ é™¤
        p.client.config.Internal,      // æ˜¯å¦å†…éƒ¨ä½¿ç”¨
        p.client.config.NoWait,        // æ˜¯å¦ç­‰å¾…æœåŠ¡å™¨å“åº”
        nil,                           // é¢å¤–å‚æ•°
    )
}

// å‘é€æ¶ˆæ¯
func (p *Producer) Send(ctx context.Context, routingKey string, message interface{}) error {
    return p.SendWithOptions(ctx, routingKey, message, PublishOptions{})
}

// å‘é€é€‰é¡¹
type PublishOptions struct {
    ContentType  string
    DeliveryMode uint8  // 1=éæŒä¹…åŒ–, 2=æŒä¹…åŒ–
    Priority     uint8  // 0-255
    Expiration   string // æ¶ˆæ¯è¿‡æœŸæ—¶é—´(æ¯«ç§’)
    Headers      amqp.Table
    Mandatory    bool   // å¦‚æœæ— æ³•è·¯ç”±æ˜¯å¦è¿”å›
    Immediate    bool   // å¦‚æœæ— æ¶ˆè´¹è€…æ˜¯å¦è¿”å›
}

// å¸¦é€‰é¡¹å‘é€æ¶ˆæ¯
func (p *Producer) SendWithOptions(ctx context.Context, routingKey string, message interface{}, options PublishOptions) error {
    ch, err := p.client.getChannel()
    if err != nil {
        return err
    }
    defer p.client.returnChannel(ch)

    // åºåˆ—åŒ–æ¶ˆæ¯
    body, err := json.Marshal(message)
    if err != nil {
        return fmt.Errorf("failed to marshal message: %w", err)
    }

    // è®¾ç½®é»˜è®¤å€¼
    if options.ContentType == "" {
        options.ContentType = "application/json"
    }
    if options.DeliveryMode == 0 {
        options.DeliveryMode = 2 // é»˜è®¤æŒä¹…åŒ–
    }

    // æ„å»ºå‘å¸ƒæ¶ˆæ¯
    publishing := amqp.Publishing{
        ContentType:  options.ContentType,
        DeliveryMode: options.DeliveryMode,
        Priority:     options.Priority,
        Expiration:   options.Expiration,
        Headers:      options.Headers,
        Timestamp:    time.Now(),
        Body:         body,
    }

    // å‘å¸ƒæ¶ˆæ¯
    return ch.Publish(
        p.exchange,         // äº¤æ¢æœº
        routingKey,         // è·¯ç”±é”®
        options.Mandatory,  // mandatory
        options.Immediate,  // immediate
        publishing,         // æ¶ˆæ¯
    )
}

// æ‰¹é‡å‘é€æ¶ˆæ¯
func (p *Producer) SendBatch(ctx context.Context, routingKey string, messages []interface{}) error {
    ch, err := p.client.getChannel()
    if err != nil {
        return err
    }
    defer p.client.returnChannel(ch)

    for _, message := range messages {
        body, err := json.Marshal(message)
        if err != nil {
            return fmt.Errorf("failed to marshal message: %w", err)
        }

        publishing := amqp.Publishing{
            ContentType:  "application/json",
            DeliveryMode: 2, // æŒä¹…åŒ–
            Timestamp:    time.Now(),
            Body:         body,
        }

        if err := ch.Publish(p.exchange, routingKey, false, false, publishing); err != nil {
            return err
        }
    }

    return nil
}

// å‘é€å»¶è¿Ÿæ¶ˆæ¯
func (p *Producer) SendDelayed(ctx context.Context, routingKey string, message interface{}, delay time.Duration) error {
    options := PublishOptions{
        Expiration: fmt.Sprintf("%d", delay.Milliseconds()),
        Headers: amqp.Table{
            "x-delay": delay.Milliseconds(),
        },
    }

    return p.SendWithOptions(ctx, routingKey, message, options)
}

// å‘é€äº‹åŠ¡æ¶ˆæ¯
func (p *Producer) SendTransactional(ctx context.Context, routingKey string, messages []interface{}) error {
    ch, err := p.client.getChannel()
    if err != nil {
        return err
    }
    defer p.client.returnChannel(ch)

    // å¼€å¯äº‹åŠ¡
    if err := ch.Tx(); err != nil {
        return err
    }

    // å‘é€æ¶ˆæ¯
    for _, message := range messages {
        body, err := json.Marshal(message)
        if err != nil {
            ch.TxRollback() // å›æ»šäº‹åŠ¡
            return fmt.Errorf("failed to marshal message: %w", err)
        }

        publishing := amqp.Publishing{
            ContentType:  "application/json",
            DeliveryMode: 2,
            Timestamp:    time.Now(),
            Body:         body,
        }

        if err := ch.Publish(p.exchange, routingKey, false, false, publishing); err != nil {
            ch.TxRollback() // å›æ»šäº‹åŠ¡
            return err
        }
    }

    // æäº¤äº‹åŠ¡
    return ch.TxCommit()
}
```

### RabbitMQæ¶ˆè´¹è€…å®ç°

```go
// æ¥è‡ª mall-go/internal/mq/rabbitmq/consumer.go
package rabbitmq

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "sync"
    "time"

    "github.com/streadway/amqp"
)

// æ¶ˆæ¯å¤„ç†å™¨
type MessageHandler func(ctx context.Context, delivery amqp.Delivery) error

// æ¶ˆè´¹è€…é…ç½®
type ConsumerConfig struct {
    QueueName    string `yaml:"queue_name"`
    RoutingKey   string `yaml:"routing_key"`
    ConsumerTag  string `yaml:"consumer_tag"`
    AutoAck      bool   `yaml:"auto_ack"`
    Exclusive    bool   `yaml:"exclusive"`
    NoLocal      bool   `yaml:"no_local"`
    NoWait       bool   `yaml:"no_wait"`

    // é˜Ÿåˆ—é…ç½®
    QueueDurable    bool `yaml:"queue_durable"`
    QueueAutoDelete bool `yaml:"queue_auto_delete"`
    QueueExclusive  bool `yaml:"queue_exclusive"`

    // æ¶ˆè´¹è€…é…ç½®
    PrefetchCount int `yaml:"prefetch_count"`
    PrefetchSize  int `yaml:"prefetch_size"`

    // é‡è¯•é…ç½®
    MaxRetries    int           `yaml:"max_retries"`
    RetryDelay    time.Duration `yaml:"retry_delay"`
    DeadLetterExchange string   `yaml:"dead_letter_exchange"`
}

// æ¶ˆè´¹è€…
type Consumer struct {
    client   *Client
    config   *ConsumerConfig
    exchange string
    handlers map[string]MessageHandler
    mutex    sync.RWMutex
    ctx      context.Context
    cancel   context.CancelFunc
    wg       sync.WaitGroup
}

// åˆ›å»ºæ¶ˆè´¹è€…
func NewConsumer(client *Client, exchange string, config *ConsumerConfig) (*Consumer, error) {
    ctx, cancel := context.WithCancel(context.Background())

    consumer := &Consumer{
        client:   client,
        config:   config,
        exchange: exchange,
        handlers: make(map[string]MessageHandler),
        ctx:      ctx,
        cancel:   cancel,
    }

    // å£°æ˜é˜Ÿåˆ—
    if err := consumer.declareQueue(); err != nil {
        return nil, err
    }

    return consumer, nil
}

// å£°æ˜é˜Ÿåˆ—
func (c *Consumer) declareQueue() error {
    ch, err := c.client.getChannel()
    if err != nil {
        return err
    }
    defer c.client.returnChannel(ch)

    // å£°æ˜é˜Ÿåˆ—
    args := amqp.Table{}
    if c.config.DeadLetterExchange != "" {
        args["x-dead-letter-exchange"] = c.config.DeadLetterExchange
    }

    _, err = ch.QueueDeclare(
        c.config.QueueName,        // é˜Ÿåˆ—åç§°
        c.config.QueueDurable,     // æ˜¯å¦æŒä¹…åŒ–
        c.config.QueueAutoDelete,  // æ˜¯å¦è‡ªåŠ¨åˆ é™¤
        c.config.QueueExclusive,   // æ˜¯å¦æ’ä»–
        c.config.NoWait,           // æ˜¯å¦ç­‰å¾…
        args,                      // é¢å¤–å‚æ•°
    )
    if err != nil {
        return err
    }

    // ç»‘å®šé˜Ÿåˆ—åˆ°äº¤æ¢æœº
    return ch.QueueBind(
        c.config.QueueName, // é˜Ÿåˆ—åç§°
        c.config.RoutingKey, // è·¯ç”±é”®
        c.exchange,         // äº¤æ¢æœº
        c.config.NoWait,    // æ˜¯å¦ç­‰å¾…
        nil,                // é¢å¤–å‚æ•°
    )
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (c *Consumer) RegisterHandler(routingKey string, handler MessageHandler) {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    c.handlers[routingKey] = handler
}

// å¼€å§‹æ¶ˆè´¹
func (c *Consumer) Start() error {
    ch, err := c.client.getChannel()
    if err != nil {
        return err
    }

    // è®¾ç½®QoS
    if err := ch.Qos(c.config.PrefetchCount, c.config.PrefetchSize, false); err != nil {
        return err
    }

    // å¼€å§‹æ¶ˆè´¹
    deliveries, err := ch.Consume(
        c.config.QueueName,   // é˜Ÿåˆ—åç§°
        c.config.ConsumerTag, // æ¶ˆè´¹è€…æ ‡ç­¾
        c.config.AutoAck,     // è‡ªåŠ¨ç¡®è®¤
        c.config.Exclusive,   // æ’ä»–
        c.config.NoLocal,     // ä¸æ¥æ”¶è‡ªå·±å‘å¸ƒçš„æ¶ˆæ¯
        c.config.NoWait,      // ä¸ç­‰å¾…
        nil,                  // é¢å¤–å‚æ•°
    )
    if err != nil {
        return err
    }

    // å¯åŠ¨æ¶ˆæ¯å¤„ç†åç¨‹
    c.wg.Add(1)
    go c.handleMessages(deliveries)

    log.Printf("Consumer started for queue: %s", c.config.QueueName)
    return nil
}

// å¤„ç†æ¶ˆæ¯
func (c *Consumer) handleMessages(deliveries <-chan amqp.Delivery) {
    defer c.wg.Done()

    for {
        select {
        case <-c.ctx.Done():
            return
        case delivery, ok := <-deliveries:
            if !ok {
                return
            }

            c.processMessage(delivery)
        }
    }
}

// å¤„ç†å•ä¸ªæ¶ˆæ¯
func (c *Consumer) processMessage(delivery amqp.Delivery) {
    c.mutex.RLock()
    handler, exists := c.handlers[delivery.RoutingKey]
    c.mutex.RUnlock()

    if !exists {
        log.Printf("No handler for routing key: %s", delivery.RoutingKey)
        delivery.Nack(false, false) // æ‹’ç»æ¶ˆæ¯ï¼Œä¸é‡æ–°å…¥é˜Ÿ
        return
    }

    // å¤„ç†æ¶ˆæ¯
    err := c.processWithRetry(handler, delivery)

    if err != nil {
        log.Printf("Failed to process message after retries: %v", err)
        delivery.Nack(false, false) // æ‹’ç»æ¶ˆæ¯ï¼Œå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
    } else {
        delivery.Ack(false) // ç¡®è®¤æ¶ˆæ¯
    }
}

// å¸¦é‡è¯•çš„æ¶ˆæ¯å¤„ç†
func (c *Consumer) processWithRetry(handler MessageHandler, delivery amqp.Delivery) error {
    var err error

    for i := 0; i <= c.config.MaxRetries; i++ {
        err = handler(c.ctx, delivery)
        if err == nil {
            return nil
        }

        if i < c.config.MaxRetries {
            log.Printf("Message processing failed (attempt %d/%d): %v",
                      i+1, c.config.MaxRetries+1, err)
            time.Sleep(c.config.RetryDelay)
        }
    }

    return err
}

// åœæ­¢æ¶ˆè´¹
func (c *Consumer) Stop() error {
    c.cancel()
    c.wg.Wait()

    log.Printf("Consumer stopped for queue: %s", c.config.QueueName)
    return nil
}
```

### RabbitMQå®é™…åº”ç”¨ç¤ºä¾‹

```go
// æ¥è‡ª mall-go/internal/service/order_message_service.go
package service

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "time"

    "mall-go/internal/mq/rabbitmq"
    "mall-go/internal/model"
)

// è®¢å•æ¶ˆæ¯æœåŠ¡
type OrderMessageService struct {
    producer *rabbitmq.Producer
    consumer *rabbitmq.Consumer
}

// è®¢å•äº‹ä»¶ç±»å‹
type OrderEvent struct {
    EventType string                 `json:"event_type"`
    OrderID   uint                   `json:"order_id"`
    UserID    uint                   `json:"user_id"`
    Data      map[string]interface{} `json:"data"`
    Timestamp int64                  `json:"timestamp"`
}

// åˆ›å»ºè®¢å•æ¶ˆæ¯æœåŠ¡
func NewOrderMessageService(client *rabbitmq.Client) (*OrderMessageService, error) {
    // åˆ›å»ºç”Ÿäº§è€…
    producer, err := rabbitmq.NewProducer(client, "mall.orders")
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºæ¶ˆè´¹è€…é…ç½®
    consumerConfig := &rabbitmq.ConsumerConfig{
        QueueName:       "order.processing",
        RoutingKey:      "order.*",
        ConsumerTag:     "order-processor",
        AutoAck:         false,
        PrefetchCount:   10,
        MaxRetries:      3,
        RetryDelay:      time.Second * 5,
        DeadLetterExchange: "mall.orders.dlx",
    }

    // åˆ›å»ºæ¶ˆè´¹è€…
    consumer, err := rabbitmq.NewConsumer(client, "mall.orders", consumerConfig)
    if err != nil {
        return nil, err
    }

    service := &OrderMessageService{
        producer: producer,
        consumer: consumer,
    }

    // æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    service.registerHandlers()

    return service, nil
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (s *OrderMessageService) registerHandlers() {
    // è®¢å•åˆ›å»ºå¤„ç†å™¨
    s.consumer.RegisterHandler("order.created", s.handleOrderCreated)

    // è®¢å•æ”¯ä»˜å¤„ç†å™¨
    s.consumer.RegisterHandler("order.paid", s.handleOrderPaid)

    // è®¢å•å‘è´§å¤„ç†å™¨
    s.consumer.RegisterHandler("order.shipped", s.handleOrderShipped)

    // è®¢å•å–æ¶ˆå¤„ç†å™¨
    s.consumer.RegisterHandler("order.cancelled", s.handleOrderCancelled)
}

// å‘å¸ƒè®¢å•åˆ›å»ºäº‹ä»¶
func (s *OrderMessageService) PublishOrderCreated(ctx context.Context, order *model.Order) error {
    event := &OrderEvent{
        EventType: "order.created",
        OrderID:   order.ID,
        UserID:    order.UserID,
        Data: map[string]interface{}{
            "amount":     order.Amount,
            "items":      order.Items,
            "address":    order.Address,
            "created_at": order.CreatedAt,
        },
        Timestamp: time.Now().Unix(),
    }

    return s.producer.Send(ctx, "order.created", event)
}

// å‘å¸ƒè®¢å•æ”¯ä»˜äº‹ä»¶
func (s *OrderMessageService) PublishOrderPaid(ctx context.Context, orderID uint, paymentInfo map[string]interface{}) error {
    event := &OrderEvent{
        EventType: "order.paid",
        OrderID:   orderID,
        Data:      paymentInfo,
        Timestamp: time.Now().Unix(),
    }

    return s.producer.Send(ctx, "order.paid", event)
}

// å¤„ç†è®¢å•åˆ›å»ºäº‹ä»¶
func (s *OrderMessageService) handleOrderCreated(ctx context.Context, delivery amqp.Delivery) error {
    var event OrderEvent
    if err := json.Unmarshal(delivery.Body, &event); err != nil {
        return fmt.Errorf("failed to unmarshal order created event: %w", err)
    }

    log.Printf("Processing order created event: OrderID=%d, UserID=%d",
               event.OrderID, event.UserID)

    // 1. æ›´æ–°åº“å­˜
    if err := s.updateInventory(ctx, event); err != nil {
        return fmt.Errorf("failed to update inventory: %w", err)
    }

    // 2. å‘é€é€šçŸ¥
    if err := s.sendOrderNotification(ctx, event); err != nil {
        log.Printf("Failed to send notification: %v", err)
        // é€šçŸ¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    }

    // 3. æ›´æ–°ç”¨æˆ·ç§¯åˆ†
    if err := s.updateUserPoints(ctx, event); err != nil {
        log.Printf("Failed to update user points: %v", err)
        // ç§¯åˆ†æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    }

    log.Printf("Order created event processed successfully: OrderID=%d", event.OrderID)
    return nil
}

// å¤„ç†è®¢å•æ”¯ä»˜äº‹ä»¶
func (s *OrderMessageService) handleOrderPaid(ctx context.Context, delivery amqp.Delivery) error {
    var event OrderEvent
    if err := json.Unmarshal(delivery.Body, &event); err != nil {
        return fmt.Errorf("failed to unmarshal order paid event: %w", err)
    }

    log.Printf("Processing order paid event: OrderID=%d", event.OrderID)

    // 1. æ›´æ–°è®¢å•çŠ¶æ€
    if err := s.updateOrderStatus(ctx, event.OrderID, "paid"); err != nil {
        return fmt.Errorf("failed to update order status: %w", err)
    }

    // 2. è§¦å‘å‘è´§æµç¨‹
    if err := s.triggerShipping(ctx, event); err != nil {
        return fmt.Errorf("failed to trigger shipping: %w", err)
    }

    // 3. å‘é€æ”¯ä»˜æˆåŠŸé€šçŸ¥
    if err := s.sendPaymentNotification(ctx, event); err != nil {
        log.Printf("Failed to send payment notification: %v", err)
    }

    log.Printf("Order paid event processed successfully: OrderID=%d", event.OrderID)
    return nil
}

// å¤„ç†è®¢å•å‘è´§äº‹ä»¶
func (s *OrderMessageService) handleOrderShipped(ctx context.Context, delivery amqp.Delivery) error {
    var event OrderEvent
    if err := json.Unmarshal(delivery.Body, &event); err != nil {
        return fmt.Errorf("failed to unmarshal order shipped event: %w", err)
    }

    log.Printf("Processing order shipped event: OrderID=%d", event.OrderID)

    // 1. æ›´æ–°è®¢å•çŠ¶æ€
    if err := s.updateOrderStatus(ctx, event.OrderID, "shipped"); err != nil {
        return fmt.Errorf("failed to update order status: %w", err)
    }

    // 2. å‘é€å‘è´§é€šçŸ¥
    if err := s.sendShippingNotification(ctx, event); err != nil {
        log.Printf("Failed to send shipping notification: %v", err)
    }

    // 3. å¯åŠ¨ç‰©æµè·Ÿè¸ª
    if err := s.startLogisticsTracking(ctx, event); err != nil {
        log.Printf("Failed to start logistics tracking: %v", err)
    }

    log.Printf("Order shipped event processed successfully: OrderID=%d", event.OrderID)
    return nil
}

// å¤„ç†è®¢å•å–æ¶ˆäº‹ä»¶
func (s *OrderMessageService) handleOrderCancelled(ctx context.Context, delivery amqp.Delivery) error {
    var event OrderEvent
    if err := json.Unmarshal(delivery.Body, &event); err != nil {
        return fmt.Errorf("failed to unmarshal order cancelled event: %w", err)
    }

    log.Printf("Processing order cancelled event: OrderID=%d", event.OrderID)

    // 1. æ¢å¤åº“å­˜
    if err := s.restoreInventory(ctx, event); err != nil {
        return fmt.Errorf("failed to restore inventory: %w", err)
    }

    // 2. å¤„ç†é€€æ¬¾
    if err := s.processRefund(ctx, event); err != nil {
        return fmt.Errorf("failed to process refund: %w", err)
    }

    // 3. å‘é€å–æ¶ˆé€šçŸ¥
    if err := s.sendCancellationNotification(ctx, event); err != nil {
        log.Printf("Failed to send cancellation notification: %v", err)
    }

    log.Printf("Order cancelled event processed successfully: OrderID=%d", event.OrderID)
    return nil
}

// è¾…åŠ©æ–¹æ³•å®ç°
func (s *OrderMessageService) updateInventory(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿåº“å­˜æ›´æ–°
    log.Printf("Updating inventory for order: %d", event.OrderID)
    time.Sleep(100 * time.Millisecond) // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    return nil
}

func (s *OrderMessageService) sendOrderNotification(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå‘é€é€šçŸ¥
    log.Printf("Sending order notification for user: %d", event.UserID)
    return nil
}

func (s *OrderMessageService) updateUserPoints(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿç§¯åˆ†æ›´æ–°
    log.Printf("Updating user points for user: %d", event.UserID)
    return nil
}

func (s *OrderMessageService) updateOrderStatus(ctx context.Context, orderID uint, status string) error {
    // æ¨¡æ‹Ÿè®¢å•çŠ¶æ€æ›´æ–°
    log.Printf("Updating order %d status to: %s", orderID, status)
    return nil
}

func (s *OrderMessageService) triggerShipping(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿè§¦å‘å‘è´§
    log.Printf("Triggering shipping for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) sendPaymentNotification(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå‘é€æ”¯ä»˜é€šçŸ¥
    log.Printf("Sending payment notification for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) sendShippingNotification(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå‘é€å‘è´§é€šçŸ¥
    log.Printf("Sending shipping notification for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) startLogisticsTracking(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå¯åŠ¨ç‰©æµè·Ÿè¸ª
    log.Printf("Starting logistics tracking for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) restoreInventory(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿæ¢å¤åº“å­˜
    log.Printf("Restoring inventory for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) processRefund(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå¤„ç†é€€æ¬¾
    log.Printf("Processing refund for order: %d", event.OrderID)
    return nil
}

func (s *OrderMessageService) sendCancellationNotification(ctx context.Context, event OrderEvent) error {
    // æ¨¡æ‹Ÿå‘é€å–æ¶ˆé€šçŸ¥
    log.Printf("Sending cancellation notification for order: %d", event.OrderID)
    return nil
}

// å¯åŠ¨æ¶ˆè´¹è€…
func (s *OrderMessageService) Start() error {
    return s.consumer.Start()
}

// åœæ­¢æ¶ˆè´¹è€…
func (s *OrderMessageService) Stop() error {
    return s.consumer.Stop()
}
```

---

## âš¡ Apache Kafkaé›†æˆå®è·µ

Kafkaæ˜¯é«˜æ€§èƒ½çš„åˆ†å¸ƒå¼æµå¤„ç†å¹³å°ï¼Œç‰¹åˆ«é€‚åˆå¤§æ•°æ®åœºæ™¯å’Œé«˜ååé‡çš„æ¶ˆæ¯å¤„ç†ã€‚

### KafkaåŸºç¡€é…ç½®ä¸è¿æ¥

```go
// æ¥è‡ª mall-go/internal/mq/kafka/client.go
package kafka

import (
    "context"
    "fmt"
    "log"
    "strings"
    "time"

    "github.com/Shopify/sarama"
)

// Kafkaé…ç½®
type Config struct {
    Brokers       []string      `yaml:"brokers"`
    ClientID      string        `yaml:"client_id"`
    Version       string        `yaml:"version"`

    // ç”Ÿäº§è€…é…ç½®
    Producer ProducerConfig `yaml:"producer"`

    // æ¶ˆè´¹è€…é…ç½®
    Consumer ConsumerConfig `yaml:"consumer"`

    // å®‰å…¨é…ç½®
    Security SecurityConfig `yaml:"security"`
}

// ç”Ÿäº§è€…é…ç½®
type ProducerConfig struct {
    RequiredAcks      int           `yaml:"required_acks"`      // 0=ä¸ç­‰å¾…, 1=ç­‰å¾…leader, -1=ç­‰å¾…æ‰€æœ‰å‰¯æœ¬
    Timeout           time.Duration `yaml:"timeout"`
    Compression       string        `yaml:"compression"`        // none, gzip, snappy, lz4, zstd
    MaxMessageBytes   int           `yaml:"max_message_bytes"`
    RetryMax          int           `yaml:"retry_max"`
    RetryBackoff      time.Duration `yaml:"retry_backoff"`
    FlushFrequency    time.Duration `yaml:"flush_frequency"`
    FlushMessages     int           `yaml:"flush_messages"`
    FlushBytes        int           `yaml:"flush_bytes"`

    // å¹‚ç­‰æ€§é…ç½®
    Idempotent        bool          `yaml:"idempotent"`
    MaxInFlight       int           `yaml:"max_in_flight"`
}

// æ¶ˆè´¹è€…é…ç½®
type ConsumerConfig struct {
    GroupID          string        `yaml:"group_id"`
    AutoOffsetReset  string        `yaml:"auto_offset_reset"`  // earliest, latest
    EnableAutoCommit bool          `yaml:"enable_auto_commit"`
    AutoCommitInterval time.Duration `yaml:"auto_commit_interval"`
    SessionTimeout   time.Duration `yaml:"session_timeout"`
    HeartbeatInterval time.Duration `yaml:"heartbeat_interval"`
    MaxProcessingTime time.Duration `yaml:"max_processing_time"`
    FetchMin         int32         `yaml:"fetch_min"`
    FetchMax         int32         `yaml:"fetch_max"`
    FetchDefault     int32         `yaml:"fetch_default"`
}

// å®‰å…¨é…ç½®
type SecurityConfig struct {
    EnableSASL bool   `yaml:"enable_sasl"`
    SASLMechanism string `yaml:"sasl_mechanism"`
    Username   string `yaml:"username"`
    Password   string `yaml:"password"`
    EnableTLS  bool   `yaml:"enable_tls"`
    TLSConfig  TLSConfig `yaml:"tls_config"`
}

type TLSConfig struct {
    CertFile string `yaml:"cert_file"`
    KeyFile  string `yaml:"key_file"`
    CAFile   string `yaml:"ca_file"`
}

// Kafkaå®¢æˆ·ç«¯
type Client struct {
    config   *Config
    producer sarama.SyncProducer
    consumer sarama.Consumer
}

// åˆ›å»ºKafkaå®¢æˆ·ç«¯
func NewClient(config *Config) (*Client, error) {
    // è§£æKafkaç‰ˆæœ¬
    version, err := sarama.ParseKafkaVersion(config.Version)
    if err != nil {
        return nil, fmt.Errorf("failed to parse Kafka version: %w", err)
    }

    // åˆ›å»ºSaramaé…ç½®
    saramaConfig := sarama.NewConfig()
    saramaConfig.Version = version
    saramaConfig.ClientID = config.ClientID

    // é…ç½®ç”Ÿäº§è€…
    saramaConfig.Producer.RequiredAcks = sarama.RequiredAcks(config.Producer.RequiredAcks)
    saramaConfig.Producer.Timeout = config.Producer.Timeout
    saramaConfig.Producer.Compression = parseCompression(config.Producer.Compression)
    saramaConfig.Producer.MaxMessageBytes = config.Producer.MaxMessageBytes
    saramaConfig.Producer.Retry.Max = config.Producer.RetryMax
    saramaConfig.Producer.Retry.Backoff = config.Producer.RetryBackoff
    saramaConfig.Producer.Flush.Frequency = config.Producer.FlushFrequency
    saramaConfig.Producer.Flush.Messages = config.Producer.FlushMessages
    saramaConfig.Producer.Flush.Bytes = config.Producer.FlushBytes
    saramaConfig.Producer.Idempotent = config.Producer.Idempotent
    saramaConfig.Net.MaxOpenRequests = config.Producer.MaxInFlight
    saramaConfig.Producer.Return.Successes = true
    saramaConfig.Producer.Return.Errors = true

    // é…ç½®æ¶ˆè´¹è€…
    saramaConfig.Consumer.Group.Session.Timeout = config.Consumer.SessionTimeout
    saramaConfig.Consumer.Group.Heartbeat.Interval = config.Consumer.HeartbeatInterval
    saramaConfig.Consumer.MaxProcessingTime = config.Consumer.MaxProcessingTime
    saramaConfig.Consumer.Fetch.Min = config.Consumer.FetchMin
    saramaConfig.Consumer.Fetch.Max = config.Consumer.FetchMax
    saramaConfig.Consumer.Fetch.Default = config.Consumer.FetchDefault
    saramaConfig.Consumer.Return.Errors = true

    // è®¾ç½®åç§»é‡é‡ç½®ç­–ç•¥
    switch config.Consumer.AutoOffsetReset {
    case "earliest":
        saramaConfig.Consumer.Offsets.Initial = sarama.OffsetOldest
    case "latest":
        saramaConfig.Consumer.Offsets.Initial = sarama.OffsetNewest
    }

    // é…ç½®å®‰å…¨è®¾ç½®
    if err := configureSecurity(saramaConfig, &config.Security); err != nil {
        return nil, err
    }

    // åˆ›å»ºç”Ÿäº§è€…
    producer, err := sarama.NewSyncProducer(config.Brokers, saramaConfig)
    if err != nil {
        return nil, fmt.Errorf("failed to create producer: %w", err)
    }

    // åˆ›å»ºæ¶ˆè´¹è€…
    consumer, err := sarama.NewConsumer(config.Brokers, saramaConfig)
    if err != nil {
        producer.Close()
        return nil, fmt.Errorf("failed to create consumer: %w", err)
    }

    client := &Client{
        config:   config,
        producer: producer,
        consumer: consumer,
    }

    log.Printf("Kafka client created successfully, brokers: %s",
               strings.Join(config.Brokers, ","))

    return client, nil
}

// è§£æå‹ç¼©ç®—æ³•
func parseCompression(compression string) sarama.CompressionCodec {
    switch strings.ToLower(compression) {
    case "gzip":
        return sarama.CompressionGZIP
    case "snappy":
        return sarama.CompressionSnappy
    case "lz4":
        return sarama.CompressionLZ4
    case "zstd":
        return sarama.CompressionZSTD
    default:
        return sarama.CompressionNone
    }
}

// é…ç½®å®‰å…¨è®¾ç½®
func configureSecurity(config *sarama.Config, security *SecurityConfig) error {
    if security.EnableSASL {
        config.Net.SASL.Enable = true
        config.Net.SASL.Mechanism = sarama.SASLMechanism(security.SASLMechanism)
        config.Net.SASL.User = security.Username
        config.Net.SASL.Password = security.Password
    }

    if security.EnableTLS {
        config.Net.TLS.Enable = true
        // è¿™é‡Œå¯ä»¥é…ç½®TLSè¯ä¹¦ç­‰
    }

    return nil
}

// å…³é—­å®¢æˆ·ç«¯
func (c *Client) Close() error {
    var errs []error

    if err := c.producer.Close(); err != nil {
        errs = append(errs, err)
    }

    if err := c.consumer.Close(); err != nil {
        errs = append(errs, err)
    }

    if len(errs) > 0 {
        return fmt.Errorf("errors closing client: %v", errs)
    }

    return nil
}
```

### Kafkaç”Ÿäº§è€…å®ç°

```go
// æ¥è‡ª mall-go/internal/mq/kafka/producer.go
package kafka

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/Shopify/sarama"
)

// Kafkaç”Ÿäº§è€…
type Producer struct {
    client   *Client
    producer sarama.SyncProducer
}

// åˆ›å»ºç”Ÿäº§è€…
func NewProducer(client *Client) *Producer {
    return &Producer{
        client:   client,
        producer: client.producer,
    }
}

// æ¶ˆæ¯ç»“æ„
type KafkaMessage struct {
    Key       string                 `json:"key"`
    Value     interface{}            `json:"value"`
    Headers   map[string]string      `json:"headers"`
    Timestamp time.Time              `json:"timestamp"`
}

// å‘é€æ¶ˆæ¯
func (p *Producer) Send(ctx context.Context, topic string, message *KafkaMessage) error {
    // åºåˆ—åŒ–æ¶ˆæ¯å€¼
    valueBytes, err := json.Marshal(message.Value)
    if err != nil {
        return fmt.Errorf("failed to marshal message value: %w", err)
    }

    // æ„å»ºKafkaæ¶ˆæ¯
    kafkaMsg := &sarama.ProducerMessage{
        Topic:     topic,
        Key:       sarama.StringEncoder(message.Key),
        Value:     sarama.ByteEncoder(valueBytes),
        Timestamp: message.Timestamp,
    }

    // æ·»åŠ æ¶ˆæ¯å¤´
    if message.Headers != nil {
        kafkaMsg.Headers = make([]sarama.RecordHeader, 0, len(message.Headers))
        for k, v := range message.Headers {
            kafkaMsg.Headers = append(kafkaMsg.Headers, sarama.RecordHeader{
                Key:   []byte(k),
                Value: []byte(v),
            })
        }
    }

    // å‘é€æ¶ˆæ¯
    partition, offset, err := p.producer.SendMessage(kafkaMsg)
    if err != nil {
        return fmt.Errorf("failed to send message: %w", err)
    }

    fmt.Printf("Message sent successfully: topic=%s, partition=%d, offset=%d\n",
               topic, partition, offset)
    return nil
}

// æ‰¹é‡å‘é€æ¶ˆæ¯
func (p *Producer) SendBatch(ctx context.Context, topic string, messages []*KafkaMessage) error {
    kafkaMessages := make([]*sarama.ProducerMessage, len(messages))

    for i, msg := range messages {
        valueBytes, err := json.Marshal(msg.Value)
        if err != nil {
            return fmt.Errorf("failed to marshal message %d: %w", i, err)
        }

        kafkaMsg := &sarama.ProducerMessage{
            Topic:     topic,
            Key:       sarama.StringEncoder(msg.Key),
            Value:     sarama.ByteEncoder(valueBytes),
            Timestamp: msg.Timestamp,
        }

        if msg.Headers != nil {
            kafkaMsg.Headers = make([]sarama.RecordHeader, 0, len(msg.Headers))
            for k, v := range msg.Headers {
                kafkaMsg.Headers = append(kafkaMsg.Headers, sarama.RecordHeader{
                    Key:   []byte(k),
                    Value: []byte(v),
                })
            }
        }

        kafkaMessages[i] = kafkaMsg
    }

    // æ‰¹é‡å‘é€
    return p.producer.SendMessages(kafkaMessages)
}

// å‘é€å¸¦åˆ†åŒºé”®çš„æ¶ˆæ¯
func (p *Producer) SendWithPartition(ctx context.Context, topic string, partition int32, message *KafkaMessage) error {
    valueBytes, err := json.Marshal(message.Value)
    if err != nil {
        return fmt.Errorf("failed to marshal message value: %w", err)
    }

    kafkaMsg := &sarama.ProducerMessage{
        Topic:     topic,
        Partition: partition,
        Key:       sarama.StringEncoder(message.Key),
        Value:     sarama.ByteEncoder(valueBytes),
        Timestamp: message.Timestamp,
    }

    if message.Headers != nil {
        kafkaMsg.Headers = make([]sarama.RecordHeader, 0, len(message.Headers))
        for k, v := range message.Headers {
            kafkaMsg.Headers = append(kafkaMsg.Headers, sarama.RecordHeader{
                Key:   []byte(k),
                Value: []byte(v),
            })
        }
    }

    partition, offset, err := p.producer.SendMessage(kafkaMsg)
    if err != nil {
        return fmt.Errorf("failed to send message: %w", err)
    }

    fmt.Printf("Message sent to specific partition: topic=%s, partition=%d, offset=%d\n",
               topic, partition, offset)
    return nil
}
```

### Kafkaæ¶ˆè´¹è€…å®ç°

```go
// æ¥è‡ª mall-go/internal/mq/kafka/consumer.go
package kafka

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "sync"

    "github.com/Shopify/sarama"
)

// æ¶ˆæ¯å¤„ç†å™¨
type KafkaMessageHandler func(ctx context.Context, message *sarama.ConsumerMessage) error

// æ¶ˆè´¹è€…ç»„å¤„ç†å™¨
type ConsumerGroupHandler struct {
    handlers map[string]KafkaMessageHandler
    mutex    sync.RWMutex
}

// åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤„ç†å™¨
func NewConsumerGroupHandler() *ConsumerGroupHandler {
    return &ConsumerGroupHandler{
        handlers: make(map[string]KafkaMessageHandler),
    }
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (h *ConsumerGroupHandler) RegisterHandler(topic string, handler KafkaMessageHandler) {
    h.mutex.Lock()
    defer h.mutex.Unlock()

    h.handlers[topic] = handler
}

// å®ç°sarama.ConsumerGroupHandleræ¥å£
func (h *ConsumerGroupHandler) Setup(sarama.ConsumerGroupSession) error {
    return nil
}

func (h *ConsumerGroupHandler) Cleanup(sarama.ConsumerGroupSession) error {
    return nil
}

func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for {
        select {
        case message := <-claim.Messages():
            if message == nil {
                return nil
            }

            if err := h.processMessage(session.Context(), message); err != nil {
                log.Printf("Failed to process message: %v", err)
                // æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ˜¯å¦ç»§ç»­å¤„ç†
                continue
            }

            // æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
            session.MarkMessage(message, "")

        case <-session.Context().Done():
            return nil
        }
    }
}

// å¤„ç†æ¶ˆæ¯
func (h *ConsumerGroupHandler) processMessage(ctx context.Context, message *sarama.ConsumerMessage) error {
    h.mutex.RLock()
    handler, exists := h.handlers[message.Topic]
    h.mutex.RUnlock()

    if !exists {
        return fmt.Errorf("no handler registered for topic: %s", message.Topic)
    }

    return handler(ctx, message)
}

// Kafkaæ¶ˆè´¹è€…
type Consumer struct {
    client        *Client
    consumerGroup sarama.ConsumerGroup
    handler       *ConsumerGroupHandler
    topics        []string
    ctx           context.Context
    cancel        context.CancelFunc
    wg            sync.WaitGroup
}

// åˆ›å»ºæ¶ˆè´¹è€…
func NewConsumer(client *Client, groupID string, topics []string) (*Consumer, error) {
    consumerGroup, err := sarama.NewConsumerGroupFromClient(groupID, client.consumer.(*sarama.consumer).client)
    if err != nil {
        return nil, fmt.Errorf("failed to create consumer group: %w", err)
    }

    ctx, cancel := context.WithCancel(context.Background())

    consumer := &Consumer{
        client:        client,
        consumerGroup: consumerGroup,
        handler:       NewConsumerGroupHandler(),
        topics:        topics,
        ctx:           ctx,
        cancel:        cancel,
    }

    return consumer, nil
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (c *Consumer) RegisterHandler(topic string, handler KafkaMessageHandler) {
    c.handler.RegisterHandler(topic, handler)
}

// å¼€å§‹æ¶ˆè´¹
func (c *Consumer) Start() error {
    c.wg.Add(1)
    go func() {
        defer c.wg.Done()

        for {
            select {
            case <-c.ctx.Done():
                return
            default:
                if err := c.consumerGroup.Consume(c.ctx, c.topics, c.handler); err != nil {
                    log.Printf("Consumer group error: %v", err)
                    return
                }
            }
        }
    }()

    // ç›‘å¬é”™è¯¯
    c.wg.Add(1)
    go func() {
        defer c.wg.Done()

        for {
            select {
            case <-c.ctx.Done():
                return
            case err := <-c.consumerGroup.Errors():
                if err != nil {
                    log.Printf("Consumer group error: %v", err)
                }
            }
        }
    }()

    log.Printf("Kafka consumer started for topics: %v", c.topics)
    return nil
}

// åœæ­¢æ¶ˆè´¹
func (c *Consumer) Stop() error {
    c.cancel()
    c.wg.Wait()

    if err := c.consumerGroup.Close(); err != nil {
        return fmt.Errorf("failed to close consumer group: %w", err)
    }

    log.Printf("Kafka consumer stopped for topics: %v", c.topics)
    return nil
}
```

### Kafkaå®é™…åº”ç”¨ç¤ºä¾‹

```go
// æ¥è‡ª mall-go/internal/service/analytics_service.go
package service

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "time"

    "github.com/Shopify/sarama"
    "mall-go/internal/mq/kafka"
)

// ç”¨æˆ·è¡Œä¸ºåˆ†ææœåŠ¡
type AnalyticsService struct {
    producer *kafka.Producer
    consumer *kafka.Consumer
}

// ç”¨æˆ·è¡Œä¸ºäº‹ä»¶
type UserBehaviorEvent struct {
    UserID    uint                   `json:"user_id"`
    EventType string                 `json:"event_type"`
    Page      string                 `json:"page"`
    Action    string                 `json:"action"`
    Properties map[string]interface{} `json:"properties"`
    Timestamp  int64                  `json:"timestamp"`
    SessionID  string                 `json:"session_id"`
    IP         string                 `json:"ip"`
    UserAgent  string                 `json:"user_agent"`
}

// åˆ›å»ºåˆ†ææœåŠ¡
func NewAnalyticsService(client *kafka.Client) (*AnalyticsService, error) {
    producer := kafka.NewProducer(client)

    consumer, err := kafka.NewConsumer(client, "analytics-group", []string{
        "user.behavior",
        "order.events",
        "product.events",
    })
    if err != nil {
        return nil, err
    }

    service := &AnalyticsService{
        producer: producer,
        consumer: consumer,
    }

    // æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    service.registerHandlers()

    return service, nil
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (s *AnalyticsService) registerHandlers() {
    // ç”¨æˆ·è¡Œä¸ºåˆ†æ
    s.consumer.RegisterHandler("user.behavior", s.handleUserBehavior)

    // è®¢å•äº‹ä»¶åˆ†æ
    s.consumer.RegisterHandler("order.events", s.handleOrderEvents)

    // å•†å“äº‹ä»¶åˆ†æ
    s.consumer.RegisterHandler("product.events", s.handleProductEvents)
}

// è®°å½•ç”¨æˆ·è¡Œä¸º
func (s *AnalyticsService) TrackUserBehavior(ctx context.Context, event *UserBehaviorEvent) error {
    message := &kafka.KafkaMessage{
        Key:   fmt.Sprintf("user_%d", event.UserID),
        Value: event,
        Headers: map[string]string{
            "event_type": event.EventType,
            "source":     "web",
        },
        Timestamp: time.Now(),
    }

    return s.producer.Send(ctx, "user.behavior", message)
}

// å¤„ç†ç”¨æˆ·è¡Œä¸ºäº‹ä»¶
func (s *AnalyticsService) handleUserBehavior(ctx context.Context, message *sarama.ConsumerMessage) error {
    var event UserBehaviorEvent
    if err := json.Unmarshal(message.Value, &event); err != nil {
        return fmt.Errorf("failed to unmarshal user behavior event: %w", err)
    }

    log.Printf("Processing user behavior: UserID=%d, EventType=%s, Action=%s",
               event.UserID, event.EventType, event.Action)

    // 1. å®æ—¶ç”¨æˆ·ç”»åƒæ›´æ–°
    if err := s.updateUserProfile(ctx, &event); err != nil {
        log.Printf("Failed to update user profile: %v", err)
    }

    // 2. å®æ—¶æ¨èè®¡ç®—
    if err := s.updateRecommendations(ctx, &event); err != nil {
        log.Printf("Failed to update recommendations: %v", err)
    }

    // 3. å¼‚å¸¸è¡Œä¸ºæ£€æµ‹
    if err := s.detectAnomalies(ctx, &event); err != nil {
        log.Printf("Failed to detect anomalies: %v", err)
    }

    // 4. å­˜å‚¨åˆ°æ•°æ®ä»“åº“
    if err := s.storeToWarehouse(ctx, &event); err != nil {
        log.Printf("Failed to store to warehouse: %v", err)
    }

    return nil
}

// å¤„ç†è®¢å•äº‹ä»¶
func (s *AnalyticsService) handleOrderEvents(ctx context.Context, message *sarama.ConsumerMessage) error {
    log.Printf("Processing order event: Partition=%d, Offset=%d",
               message.Partition, message.Offset)

    // è§£æè®¢å•äº‹ä»¶
    var orderEvent map[string]interface{}
    if err := json.Unmarshal(message.Value, &orderEvent); err != nil {
        return fmt.Errorf("failed to unmarshal order event: %w", err)
    }

    // 1. æ›´æ–°é”€å”®ç»Ÿè®¡
    if err := s.updateSalesStats(ctx, orderEvent); err != nil {
        log.Printf("Failed to update sales stats: %v", err)
    }

    // 2. æ›´æ–°å•†å“çƒ­åº¦
    if err := s.updateProductPopularity(ctx, orderEvent); err != nil {
        log.Printf("Failed to update product popularity: %v", err)
    }

    // 3. ç”¨æˆ·ä»·å€¼åˆ†æ
    if err := s.analyzeUserValue(ctx, orderEvent); err != nil {
        log.Printf("Failed to analyze user value: %v", err)
    }

    return nil
}

// å¤„ç†å•†å“äº‹ä»¶
func (s *AnalyticsService) handleProductEvents(ctx context.Context, message *sarama.ConsumerMessage) error {
    log.Printf("Processing product event: Partition=%d, Offset=%d",
               message.Partition, message.Offset)

    // è§£æå•†å“äº‹ä»¶
    var productEvent map[string]interface{}
    if err := json.Unmarshal(message.Value, &productEvent); err != nil {
        return fmt.Errorf("failed to unmarshal product event: %w", err)
    }

    // 1. æ›´æ–°å•†å“ç»Ÿè®¡
    if err := s.updateProductStats(ctx, productEvent); err != nil {
        log.Printf("Failed to update product stats: %v", err)
    }

    // 2. åº“å­˜é¢„è­¦åˆ†æ
    if err := s.analyzeInventoryAlerts(ctx, productEvent); err != nil {
        log.Printf("Failed to analyze inventory alerts: %v", err)
    }

    return nil
}

// è¾…åŠ©æ–¹æ³•å®ç°
func (s *AnalyticsService) updateUserProfile(ctx context.Context, event *UserBehaviorEvent) error {
    // æ¨¡æ‹Ÿç”¨æˆ·ç”»åƒæ›´æ–°
    log.Printf("Updating user profile for user: %d", event.UserID)
    return nil
}

func (s *AnalyticsService) updateRecommendations(ctx context.Context, event *UserBehaviorEvent) error {
    // æ¨¡æ‹Ÿæ¨èæ›´æ–°
    log.Printf("Updating recommendations for user: %d", event.UserID)
    return nil
}

func (s *AnalyticsService) detectAnomalies(ctx context.Context, event *UserBehaviorEvent) error {
    // æ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹
    log.Printf("Detecting anomalies for user: %d", event.UserID)
    return nil
}

func (s *AnalyticsService) storeToWarehouse(ctx context.Context, event *UserBehaviorEvent) error {
    // æ¨¡æ‹Ÿæ•°æ®ä»“åº“å­˜å‚¨
    log.Printf("Storing event to warehouse: %s", event.EventType)
    return nil
}

func (s *AnalyticsService) updateSalesStats(ctx context.Context, orderEvent map[string]interface{}) error {
    // æ¨¡æ‹Ÿé”€å”®ç»Ÿè®¡æ›´æ–°
    log.Printf("Updating sales statistics")
    return nil
}

func (s *AnalyticsService) updateProductPopularity(ctx context.Context, orderEvent map[string]interface{}) error {
    // æ¨¡æ‹Ÿå•†å“çƒ­åº¦æ›´æ–°
    log.Printf("Updating product popularity")
    return nil
}

func (s *AnalyticsService) analyzeUserValue(ctx context.Context, orderEvent map[string]interface{}) error {
    // æ¨¡æ‹Ÿç”¨æˆ·ä»·å€¼åˆ†æ
    log.Printf("Analyzing user value")
    return nil
}

func (s *AnalyticsService) updateProductStats(ctx context.Context, productEvent map[string]interface{}) error {
    // æ¨¡æ‹Ÿå•†å“ç»Ÿè®¡æ›´æ–°
    log.Printf("Updating product statistics")
    return nil
}

func (s *AnalyticsService) analyzeInventoryAlerts(ctx context.Context, productEvent map[string]interface{}) error {
    // æ¨¡æ‹Ÿåº“å­˜é¢„è­¦åˆ†æ
    log.Printf("Analyzing inventory alerts")
    return nil
}

// å¯åŠ¨æœåŠ¡
func (s *AnalyticsService) Start() error {
    return s.consumer.Start()
}

// åœæ­¢æœåŠ¡
func (s *AnalyticsService) Stop() error {
    return s.consumer.Stop()
}
```

---

## ğŸš€ NSQé›†æˆå®è·µ

NSQæ˜¯Goè¯­è¨€åŸç”Ÿçš„åˆ†å¸ƒå¼æ¶ˆæ¯é˜Ÿåˆ—ï¼Œå…·æœ‰ç®€å•æ˜“ç”¨ã€é«˜æ€§èƒ½ã€å»ä¸­å¿ƒåŒ–ç­‰ç‰¹ç‚¹ã€‚

### NSQåŸºç¡€é…ç½®ä¸è¿æ¥

```go
// æ¥è‡ª mall-go/internal/mq/nsq/client.go
package nsq

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "sync"
    "time"

    "github.com/nsqio/go-nsq"
)

// NSQé…ç½®
type Config struct {
    NSQDAddrs    []string      `yaml:"nsqd_addrs"`
    LookupdAddrs []string      `yaml:"lookupd_addrs"`

    // ç”Ÿäº§è€…é…ç½®
    Producer ProducerConfig `yaml:"producer"`

    // æ¶ˆè´¹è€…é…ç½®
    Consumer ConsumerConfig `yaml:"consumer"`
}

// ç”Ÿäº§è€…é…ç½®
type ProducerConfig struct {
    MaxInFlight int           `yaml:"max_in_flight"`
    DialTimeout time.Duration `yaml:"dial_timeout"`
    ReadTimeout time.Duration `yaml:"read_timeout"`
    WriteTimeout time.Duration `yaml:"write_timeout"`
    LocalAddr   string        `yaml:"local_addr"`
    UserAgent   string        `yaml:"user_agent"`
}

// æ¶ˆè´¹è€…é…ç½®
type ConsumerConfig struct {
    MaxInFlight        int           `yaml:"max_in_flight"`
    MaxAttempts        uint16        `yaml:"max_attempts"`
    RequeueDelay       time.Duration `yaml:"requeue_delay"`
    DefaultRequeueDelay time.Duration `yaml:"default_requeue_delay"`
    BackoffStrategy    string        `yaml:"backoff_strategy"`
    MaxBackoffDuration time.Duration `yaml:"max_backoff_duration"`
    BackoffMultiplier  time.Duration `yaml:"backoff_multiplier"`
    LookupdPollInterval time.Duration `yaml:"lookupd_poll_interval"`
    LookupdPollJitter  float64       `yaml:"lookupd_poll_jitter"`
}

// NSQå®¢æˆ·ç«¯
type Client struct {
    config    *Config
    producers map[string]*nsq.Producer
    consumers map[string]*nsq.Consumer
    mutex     sync.RWMutex
}

// åˆ›å»ºNSQå®¢æˆ·ç«¯
func NewClient(config *Config) (*Client, error) {
    client := &Client{
        config:    config,
        producers: make(map[string]*nsq.Producer),
        consumers: make(map[string]*nsq.Consumer),
    }

    return client, nil
}

// è·å–ç”Ÿäº§è€…
func (c *Client) GetProducer(nsqdAddr string) (*nsq.Producer, error) {
    c.mutex.RLock()
    if producer, exists := c.producers[nsqdAddr]; exists {
        c.mutex.RUnlock()
        return producer, nil
    }
    c.mutex.RUnlock()

    c.mutex.Lock()
    defer c.mutex.Unlock()

    // åŒé‡æ£€æŸ¥
    if producer, exists := c.producers[nsqdAddr]; exists {
        return producer, nil
    }

    // åˆ›å»ºç”Ÿäº§è€…é…ç½®
    config := nsq.NewConfig()
    config.MaxInFlight = c.config.Producer.MaxInFlight
    config.DialTimeout = c.config.Producer.DialTimeout
    config.ReadTimeout = c.config.Producer.ReadTimeout
    config.WriteTimeout = c.config.Producer.WriteTimeout
    config.LocalAddr = c.config.Producer.LocalAddr
    config.UserAgent = c.config.Producer.UserAgent

    // åˆ›å»ºç”Ÿäº§è€…
    producer, err := nsq.NewProducer(nsqdAddr, config)
    if err != nil {
        return nil, fmt.Errorf("failed to create NSQ producer: %w", err)
    }

    c.producers[nsqdAddr] = producer
    log.Printf("NSQ producer created for: %s", nsqdAddr)

    return producer, nil
}

// åˆ›å»ºæ¶ˆè´¹è€…
func (c *Client) CreateConsumer(topic, channel string) (*nsq.Consumer, error) {
    // åˆ›å»ºæ¶ˆè´¹è€…é…ç½®
    config := nsq.NewConfig()
    config.MaxInFlight = c.config.Consumer.MaxInFlight
    config.MaxAttempts = c.config.Consumer.MaxAttempts
    config.RequeueDelay = c.config.Consumer.RequeueDelay
    config.DefaultRequeueDelay = c.config.Consumer.DefaultRequeueDelay
    config.MaxBackoffDuration = c.config.Consumer.MaxBackoffDuration
    config.BackoffMultiplier = c.config.Consumer.BackoffMultiplier
    config.LookupdPollInterval = c.config.Consumer.LookupdPollInterval
    config.LookupdPollJitter = c.config.Consumer.LookupdPollJitter

    // è®¾ç½®é€€é¿ç­–ç•¥
    switch c.config.Consumer.BackoffStrategy {
    case "exponential":
        config.BackoffStrategy = nsq.ExponentialStrategy{}
    case "full_jitter":
        config.BackoffStrategy = nsq.FullJitterStrategy{}
    default:
        config.BackoffStrategy = nsq.ExponentialStrategy{}
    }

    // åˆ›å»ºæ¶ˆè´¹è€…
    consumer, err := nsq.NewConsumer(topic, channel, config)
    if err != nil {
        return nil, fmt.Errorf("failed to create NSQ consumer: %w", err)
    }

    consumerKey := fmt.Sprintf("%s:%s", topic, channel)
    c.mutex.Lock()
    c.consumers[consumerKey] = consumer
    c.mutex.Unlock()

    log.Printf("NSQ consumer created for topic: %s, channel: %s", topic, channel)

    return consumer, nil
}

// å…³é—­å®¢æˆ·ç«¯
func (c *Client) Close() error {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    var errs []error

    // å…³é—­æ‰€æœ‰ç”Ÿäº§è€…
    for addr, producer := range c.producers {
        producer.Stop()
        if err := <-producer.StopChan; err != nil {
            errs = append(errs, fmt.Errorf("error stopping producer %s: %w", addr, err))
        }
    }

    // å…³é—­æ‰€æœ‰æ¶ˆè´¹è€…
    for key, consumer := range c.consumers {
        consumer.Stop()
        if err := <-consumer.StopChan; err != nil {
            errs = append(errs, fmt.Errorf("error stopping consumer %s: %w", key, err))
        }
    }

    if len(errs) > 0 {
        return fmt.Errorf("errors closing NSQ client: %v", errs)
    }

    return nil
}
```

### NSQç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…å®ç°

```go
// æ¥è‡ª mall-go/internal/mq/nsq/producer.go
package nsq

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/nsqio/go-nsq"
)

// NSQç”Ÿäº§è€…åŒ…è£…å™¨
type Producer struct {
    client   *Client
    nsqdAddr string
    producer *nsq.Producer
}

// åˆ›å»ºç”Ÿäº§è€…
func NewProducer(client *Client, nsqdAddr string) (*Producer, error) {
    producer, err := client.GetProducer(nsqdAddr)
    if err != nil {
        return nil, err
    }

    return &Producer{
        client:   client,
        nsqdAddr: nsqdAddr,
        producer: producer,
    }, nil
}

// NSQæ¶ˆæ¯ç»“æ„
type NSQMessage struct {
    ID        string                 `json:"id"`
    Type      string                 `json:"type"`
    Payload   map[string]interface{} `json:"payload"`
    Timestamp int64                  `json:"timestamp"`
    Retry     int                    `json:"retry"`
}

// å‘å¸ƒæ¶ˆæ¯
func (p *Producer) Publish(ctx context.Context, topic string, message *NSQMessage) error {
    messageBytes, err := json.Marshal(message)
    if err != nil {
        return fmt.Errorf("failed to marshal message: %w", err)
    }

    if err := p.producer.Publish(topic, messageBytes); err != nil {
        return fmt.Errorf("failed to publish message: %w", err)
    }

    fmt.Printf("Message published to NSQ: topic=%s, id=%s\n", topic, message.ID)
    return nil
}

// å»¶è¿Ÿå‘å¸ƒæ¶ˆæ¯
func (p *Producer) DeferredPublish(ctx context.Context, topic string, delay time.Duration, message *NSQMessage) error {
    messageBytes, err := json.Marshal(message)
    if err != nil {
        return fmt.Errorf("failed to marshal message: %w", err)
    }

    if err := p.producer.DeferredPublish(topic, delay, messageBytes); err != nil {
        return fmt.Errorf("failed to publish deferred message: %w", err)
    }

    fmt.Printf("Deferred message published to NSQ: topic=%s, delay=%v, id=%s\n",
               topic, delay, message.ID)
    return nil
}

// æ‰¹é‡å‘å¸ƒæ¶ˆæ¯
func (p *Producer) MultiPublish(ctx context.Context, topic string, messages []*NSQMessage) error {
    messageBytes := make([][]byte, len(messages))

    for i, msg := range messages {
        bytes, err := json.Marshal(msg)
        if err != nil {
            return fmt.Errorf("failed to marshal message %d: %w", i, err)
        }
        messageBytes[i] = bytes
    }

    if err := p.producer.MultiPublish(topic, messageBytes); err != nil {
        return fmt.Errorf("failed to multi-publish messages: %w", err)
    }

    fmt.Printf("Multi-published %d messages to NSQ: topic=%s\n", len(messages), topic)
    return nil
}

// NSQæ¶ˆè´¹è€…åŒ…è£…å™¨
type Consumer struct {
    client   *Client
    consumer *nsq.Consumer
    topic    string
    channel  string
    handlers map[string]NSQMessageHandler
    mutex    sync.RWMutex
}

// æ¶ˆæ¯å¤„ç†å™¨
type NSQMessageHandler func(ctx context.Context, message *NSQMessage) error

// åˆ›å»ºæ¶ˆè´¹è€…
func NewConsumer(client *Client, topic, channel string) (*Consumer, error) {
    consumer, err := client.CreateConsumer(topic, channel)
    if err != nil {
        return nil, err
    }

    c := &Consumer{
        client:   client,
        consumer: consumer,
        topic:    topic,
        channel:  channel,
        handlers: make(map[string]NSQMessageHandler),
    }

    // è®¾ç½®æ¶ˆæ¯å¤„ç†å™¨
    consumer.AddHandler(c)

    return c, nil
}

// å®ç°nsq.Handleræ¥å£
func (c *Consumer) HandleMessage(message *nsq.Message) error {
    var nsqMsg NSQMessage
    if err := json.Unmarshal(message.Body, &nsqMsg); err != nil {
        return fmt.Errorf("failed to unmarshal NSQ message: %w", err)
    }

    c.mutex.RLock()
    handler, exists := c.handlers[nsqMsg.Type]
    c.mutex.RUnlock()

    if !exists {
        return fmt.Errorf("no handler registered for message type: %s", nsqMsg.Type)
    }

    ctx := context.Background()
    if err := handler(ctx, &nsqMsg); err != nil {
        // å¢åŠ é‡è¯•æ¬¡æ•°
        nsqMsg.Retry++

        // å¦‚æœé‡è¯•æ¬¡æ•°è¶…è¿‡é™åˆ¶ï¼Œè®°å½•é”™è¯¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
        if nsqMsg.Retry >= 3 {
            log.Printf("Message processing failed after %d retries: %v", nsqMsg.Retry, err)
            return nil // è¿”å›nilé¿å…é‡æ–°å…¥é˜Ÿ
        }

        return err // è¿”å›é”™è¯¯ä¼šå¯¼è‡´æ¶ˆæ¯é‡æ–°å…¥é˜Ÿ
    }

    return nil
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (c *Consumer) RegisterHandler(messageType string, handler NSQMessageHandler) {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    c.handlers[messageType] = handler
}

// è¿æ¥åˆ°NSQ
func (c *Consumer) ConnectToNSQD(nsqdAddr string) error {
    return c.consumer.ConnectToNSQD(nsqdAddr)
}

// è¿æ¥åˆ°NSQLookupd
func (c *Consumer) ConnectToNSQLookupd(lookupdAddr string) error {
    return c.consumer.ConnectToNSQLookupd(lookupdAddr)
}

// åœæ­¢æ¶ˆè´¹è€…
func (c *Consumer) Stop() {
    c.consumer.Stop()
}
```

### NSQå®é™…åº”ç”¨ç¤ºä¾‹

```go
// æ¥è‡ª mall-go/internal/service/notification_service.go
package service

import (
    "context"
    "fmt"
    "log"
    "time"

    "mall-go/internal/mq/nsq"
)

// é€šçŸ¥æœåŠ¡
type NotificationService struct {
    producer *nsq.Producer
    consumer *nsq.Consumer
}

// é€šçŸ¥ç±»å‹
const (
    NotificationTypeEmail = "email"
    NotificationTypeSMS   = "sms"
    NotificationTypePush  = "push"
    NotificationTypeInApp = "in_app"
)

// é€šçŸ¥æ¶ˆæ¯
type NotificationMessage struct {
    UserID      uint                   `json:"user_id"`
    Type        string                 `json:"type"`
    Title       string                 `json:"title"`
    Content     string                 `json:"content"`
    Template    string                 `json:"template"`
    Variables   map[string]interface{} `json:"variables"`
    Priority    int                    `json:"priority"`
    ScheduledAt *time.Time             `json:"scheduled_at,omitempty"`
}

// åˆ›å»ºé€šçŸ¥æœåŠ¡
func NewNotificationService(client *nsq.Client) (*NotificationService, error) {
    // åˆ›å»ºç”Ÿäº§è€…
    producer, err := nsq.NewProducer(client, "127.0.0.1:4150")
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºæ¶ˆè´¹è€…
    consumer, err := nsq.NewConsumer(client, "notifications", "notification-processor")
    if err != nil {
        return nil, err
    }

    service := &NotificationService{
        producer: producer,
        consumer: consumer,
    }

    // æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    service.registerHandlers()

    return service, nil
}

// æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
func (s *NotificationService) registerHandlers() {
    s.consumer.RegisterHandler(NotificationTypeEmail, s.handleEmailNotification)
    s.consumer.RegisterHandler(NotificationTypeSMS, s.handleSMSNotification)
    s.consumer.RegisterHandler(NotificationTypePush, s.handlePushNotification)
    s.consumer.RegisterHandler(NotificationTypeInApp, s.handleInAppNotification)
}

// å‘é€é€šçŸ¥
func (s *NotificationService) SendNotification(ctx context.Context, notification *NotificationMessage) error {
    message := &nsq.NSQMessage{
        ID:   generateMessageID(),
        Type: notification.Type,
        Payload: map[string]interface{}{
            "user_id":      notification.UserID,
            "title":        notification.Title,
            "content":      notification.Content,
            "template":     notification.Template,
            "variables":    notification.Variables,
            "priority":     notification.Priority,
            "scheduled_at": notification.ScheduledAt,
        },
        Timestamp: time.Now().Unix(),
    }

    // å¦‚æœæ˜¯å®šæ—¶é€šçŸ¥ï¼Œä½¿ç”¨å»¶è¿Ÿå‘å¸ƒ
    if notification.ScheduledAt != nil && notification.ScheduledAt.After(time.Now()) {
        delay := notification.ScheduledAt.Sub(time.Now())
        return s.producer.DeferredPublish(ctx, "notifications", delay, message)
    }

    return s.producer.Publish(ctx, "notifications", message)
}

// æ‰¹é‡å‘é€é€šçŸ¥
func (s *NotificationService) SendBatchNotifications(ctx context.Context, notifications []*NotificationMessage) error {
    messages := make([]*nsq.NSQMessage, len(notifications))

    for i, notification := range notifications {
        messages[i] = &nsq.NSQMessage{
            ID:   generateMessageID(),
            Type: notification.Type,
            Payload: map[string]interface{}{
                "user_id":   notification.UserID,
                "title":     notification.Title,
                "content":   notification.Content,
                "template":  notification.Template,
                "variables": notification.Variables,
                "priority":  notification.Priority,
            },
            Timestamp: time.Now().Unix(),
        }
    }

    return s.producer.MultiPublish(ctx, "notifications", messages)
}

// å¤„ç†é‚®ä»¶é€šçŸ¥
func (s *NotificationService) handleEmailNotification(ctx context.Context, message *nsq.NSQMessage) error {
    userID := uint(message.Payload["user_id"].(float64))
    title := message.Payload["title"].(string)
    content := message.Payload["content"].(string)

    log.Printf("Sending email notification: UserID=%d, Title=%s", userID, title)

    // æ¨¡æ‹Ÿé‚®ä»¶å‘é€
    if err := s.sendEmail(ctx, userID, title, content); err != nil {
        return fmt.Errorf("failed to send email: %w", err)
    }

    log.Printf("Email notification sent successfully: UserID=%d", userID)
    return nil
}

// å¤„ç†çŸ­ä¿¡é€šçŸ¥
func (s *NotificationService) handleSMSNotification(ctx context.Context, message *nsq.NSQMessage) error {
    userID := uint(message.Payload["user_id"].(float64))
    content := message.Payload["content"].(string)

    log.Printf("Sending SMS notification: UserID=%d", userID)

    // æ¨¡æ‹ŸçŸ­ä¿¡å‘é€
    if err := s.sendSMS(ctx, userID, content); err != nil {
        return fmt.Errorf("failed to send SMS: %w", err)
    }

    log.Printf("SMS notification sent successfully: UserID=%d", userID)
    return nil
}

// å¤„ç†æ¨é€é€šçŸ¥
func (s *NotificationService) handlePushNotification(ctx context.Context, message *nsq.NSQMessage) error {
    userID := uint(message.Payload["user_id"].(float64))
    title := message.Payload["title"].(string)
    content := message.Payload["content"].(string)

    log.Printf("Sending push notification: UserID=%d, Title=%s", userID, title)

    // æ¨¡æ‹Ÿæ¨é€å‘é€
    if err := s.sendPush(ctx, userID, title, content); err != nil {
        return fmt.Errorf("failed to send push: %w", err)
    }

    log.Printf("Push notification sent successfully: UserID=%d", userID)
    return nil
}

// å¤„ç†åº”ç”¨å†…é€šçŸ¥
func (s *NotificationService) handleInAppNotification(ctx context.Context, message *nsq.NSQMessage) error {
    userID := uint(message.Payload["user_id"].(float64))
    title := message.Payload["title"].(string)
    content := message.Payload["content"].(string)

    log.Printf("Sending in-app notification: UserID=%d, Title=%s", userID, title)

    // æ¨¡æ‹Ÿåº”ç”¨å†…é€šçŸ¥
    if err := s.sendInAppNotification(ctx, userID, title, content); err != nil {
        return fmt.Errorf("failed to send in-app notification: %w", err)
    }

    log.Printf("In-app notification sent successfully: UserID=%d", userID)
    return nil
}

// è¾…åŠ©æ–¹æ³•
func (s *NotificationService) sendEmail(ctx context.Context, userID uint, title, content string) error {
    // æ¨¡æ‹Ÿé‚®ä»¶å‘é€é€»è¾‘
    time.Sleep(100 * time.Millisecond)
    return nil
}

func (s *NotificationService) sendSMS(ctx context.Context, userID uint, content string) error {
    // æ¨¡æ‹ŸçŸ­ä¿¡å‘é€é€»è¾‘
    time.Sleep(50 * time.Millisecond)
    return nil
}

func (s *NotificationService) sendPush(ctx context.Context, userID uint, title, content string) error {
    // æ¨¡æ‹Ÿæ¨é€å‘é€é€»è¾‘
    time.Sleep(30 * time.Millisecond)
    return nil
}

func (s *NotificationService) sendInAppNotification(ctx context.Context, userID uint, title, content string) error {
    // æ¨¡æ‹Ÿåº”ç”¨å†…é€šçŸ¥é€»è¾‘
    time.Sleep(10 * time.Millisecond)
    return nil
}

func generateMessageID() string {
    return fmt.Sprintf("msg_%d", time.Now().UnixNano())
}

// å¯åŠ¨æœåŠ¡
func (s *NotificationService) Start() error {
    // è¿æ¥åˆ°NSQLookupd
    if err := s.consumer.ConnectToNSQLookupd("127.0.0.1:4161"); err != nil {
        return err
    }

    log.Printf("Notification service started")
    return nil
}

// åœæ­¢æœåŠ¡
func (s *NotificationService) Stop() {
    s.consumer.Stop()
    log.Printf("Notification service stopped")
}
```

---

## ğŸª äº‹ä»¶é©±åŠ¨æ¶æ„è®¾è®¡

äº‹ä»¶é©±åŠ¨æ¶æ„ï¼ˆEvent-Driven Architectureï¼ŒEDAï¼‰æ˜¯ä¸€ç§åŸºäºäº‹ä»¶çš„è½¯ä»¶æ¶æ„æ¨¡å¼ï¼Œé€šè¿‡äº‹ä»¶çš„äº§ç”Ÿã€ä¼ æ’­å’Œæ¶ˆè´¹æ¥å®ç°ç³»ç»Ÿé—´çš„æ¾è€¦åˆé€šä¿¡ã€‚

### äº‹ä»¶é©±åŠ¨æ¶æ„æ ¸å¿ƒæ¦‚å¿µ

```go
// æ¥è‡ª mall-go/internal/event/event.go
package event

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
)

// äº‹ä»¶æ¥å£
type Event interface {
    GetEventID() string
    GetEventType() string
    GetAggregateID() string
    GetVersion() int
    GetTimestamp() time.Time
    GetPayload() interface{}
    GetMetadata() map[string]interface{}
}

// åŸºç¡€äº‹ä»¶ç»“æ„
type BaseEvent struct {
    EventID     string                 `json:"event_id"`
    EventType   string                 `json:"event_type"`
    AggregateID string                 `json:"aggregate_id"`
    Version     int                    `json:"version"`
    Timestamp   time.Time              `json:"timestamp"`
    Payload     interface{}            `json:"payload"`
    Metadata    map[string]interface{} `json:"metadata"`
}

// å®ç°Eventæ¥å£
func (e *BaseEvent) GetEventID() string                 { return e.EventID }
func (e *BaseEvent) GetEventType() string               { return e.EventType }
func (e *BaseEvent) GetAggregateID() string             { return e.AggregateID }
func (e *BaseEvent) GetVersion() int                    { return e.Version }
func (e *BaseEvent) GetTimestamp() time.Time            { return e.Timestamp }
func (e *BaseEvent) GetPayload() interface{}            { return e.Payload }
func (e *BaseEvent) GetMetadata() map[string]interface{} { return e.Metadata }

// äº‹ä»¶æ€»çº¿æ¥å£
type EventBus interface {
    Publish(ctx context.Context, event Event) error
    Subscribe(eventType string, handler EventHandler) error
    Unsubscribe(eventType string, handler EventHandler) error
    Start() error
    Stop() error
}

// äº‹ä»¶å¤„ç†å™¨
type EventHandler interface {
    Handle(ctx context.Context, event Event) error
    GetHandlerName() string
}

// äº‹ä»¶å­˜å‚¨æ¥å£
type EventStore interface {
    SaveEvent(ctx context.Context, event Event) error
    GetEvents(ctx context.Context, aggregateID string) ([]Event, error)
    GetEventsByType(ctx context.Context, eventType string, limit int) ([]Event, error)
}

// äº‹ä»¶å‘å¸ƒå™¨
type EventPublisher interface {
    PublishEvent(ctx context.Context, event Event) error
    PublishEvents(ctx context.Context, events []Event) error
}

// èšåˆæ ¹æ¥å£
type AggregateRoot interface {
    GetID() string
    GetVersion() int
    GetUncommittedEvents() []Event
    MarkEventsAsCommitted()
    LoadFromHistory(events []Event) error
}
```

### äº‹ä»¶æ€»çº¿å®ç°

```go
// æ¥è‡ª mall-go/internal/event/bus.go
package event

import (
    "context"
    "fmt"
    "log"
    "sync"

    "mall-go/internal/mq/rabbitmq"
)

// åŸºäºRabbitMQçš„äº‹ä»¶æ€»çº¿
type RabbitMQEventBus struct {
    producer  *rabbitmq.Producer
    consumer  *rabbitmq.Consumer
    handlers  map[string][]EventHandler
    mutex     sync.RWMutex
    started   bool
}

// åˆ›å»ºäº‹ä»¶æ€»çº¿
func NewRabbitMQEventBus(client *rabbitmq.Client) (*RabbitMQEventBus, error) {
    producer, err := rabbitmq.NewProducer(client, "events")
    if err != nil {
        return nil, err
    }

    consumerConfig := &rabbitmq.ConsumerConfig{
        QueueName:    "event-bus",
        RoutingKey:   "event.*",
        ConsumerTag:  "event-bus-consumer",
        AutoAck:      false,
        PrefetchCount: 10,
        MaxRetries:   3,
    }

    consumer, err := rabbitmq.NewConsumer(client, "events", consumerConfig)
    if err != nil {
        return nil, err
    }

    bus := &RabbitMQEventBus{
        producer: producer,
        consumer: consumer,
        handlers: make(map[string][]EventHandler),
    }

    return bus, nil
}

// å‘å¸ƒäº‹ä»¶
func (bus *RabbitMQEventBus) Publish(ctx context.Context, event Event) error {
    routingKey := fmt.Sprintf("event.%s", event.GetEventType())

    return bus.producer.Send(ctx, routingKey, event)
}

// è®¢é˜…äº‹ä»¶
func (bus *RabbitMQEventBus) Subscribe(eventType string, handler EventHandler) error {
    bus.mutex.Lock()
    defer bus.mutex.Unlock()

    if bus.handlers[eventType] == nil {
        bus.handlers[eventType] = make([]EventHandler, 0)
    }

    bus.handlers[eventType] = append(bus.handlers[eventType], handler)

    log.Printf("Event handler registered: %s -> %s", eventType, handler.GetHandlerName())
    return nil
}

// å–æ¶ˆè®¢é˜…
func (bus *RabbitMQEventBus) Unsubscribe(eventType string, handler EventHandler) error {
    bus.mutex.Lock()
    defer bus.mutex.Unlock()

    handlers := bus.handlers[eventType]
    for i, h := range handlers {
        if h.GetHandlerName() == handler.GetHandlerName() {
            bus.handlers[eventType] = append(handlers[:i], handlers[i+1:]...)
            break
        }
    }

    return nil
}

// å¯åŠ¨äº‹ä»¶æ€»çº¿
func (bus *RabbitMQEventBus) Start() error {
    if bus.started {
        return nil
    }

    // æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    bus.consumer.RegisterHandler("event.*", bus.handleEvent)

    // å¯åŠ¨æ¶ˆè´¹è€…
    if err := bus.consumer.Start(); err != nil {
        return err
    }

    bus.started = true
    log.Printf("Event bus started")
    return nil
}

// åœæ­¢äº‹ä»¶æ€»çº¿
func (bus *RabbitMQEventBus) Stop() error {
    if !bus.started {
        return nil
    }

    if err := bus.consumer.Stop(); err != nil {
        return err
    }

    bus.started = false
    log.Printf("Event bus stopped")
    return nil
}

// å¤„ç†äº‹ä»¶æ¶ˆæ¯
func (bus *RabbitMQEventBus) handleEvent(ctx context.Context, delivery amqp.Delivery) error {
    var baseEvent BaseEvent
    if err := json.Unmarshal(delivery.Body, &baseEvent); err != nil {
        return fmt.Errorf("failed to unmarshal event: %w", err)
    }

    bus.mutex.RLock()
    handlers := bus.handlers[baseEvent.EventType]
    bus.mutex.RUnlock()

    if len(handlers) == 0 {
        log.Printf("No handlers registered for event type: %s", baseEvent.EventType)
        return nil
    }

    // å¹¶å‘å¤„ç†äº‹ä»¶
    var wg sync.WaitGroup
    errChan := make(chan error, len(handlers))

    for _, handler := range handlers {
        wg.Add(1)
        go func(h EventHandler) {
            defer wg.Done()

            if err := h.Handle(ctx, &baseEvent); err != nil {
                errChan <- fmt.Errorf("handler %s failed: %w", h.GetHandlerName(), err)
            }
        }(handler)
    }

    wg.Wait()
    close(errChan)

    // æ”¶é›†é”™è¯¯
    var errors []error
    for err := range errChan {
        errors = append(errors, err)
    }

    if len(errors) > 0 {
        return fmt.Errorf("event handling errors: %v", errors)
    }

    return nil
}
```

### é¢†åŸŸäº‹ä»¶å®ç°

```go
// æ¥è‡ª mall-go/internal/domain/order/events.go
package order

import (
    "time"

    "mall-go/internal/event"
)

// è®¢å•äº‹ä»¶ç±»å‹
const (
    OrderCreatedEventType   = "order.created"
    OrderPaidEventType      = "order.paid"
    OrderShippedEventType   = "order.shipped"
    OrderDeliveredEventType = "order.delivered"
    OrderCancelledEventType = "order.cancelled"
)

// è®¢å•åˆ›å»ºäº‹ä»¶
type OrderCreatedEvent struct {
    *event.BaseEvent
    OrderData OrderCreatedData `json:"order_data"`
}

type OrderCreatedData struct {
    OrderID   uint                   `json:"order_id"`
    UserID    uint                   `json:"user_id"`
    Items     []OrderItem            `json:"items"`
    Amount    float64                `json:"amount"`
    Address   string                 `json:"address"`
    CreatedAt time.Time              `json:"created_at"`
}

// åˆ›å»ºè®¢å•åˆ›å»ºäº‹ä»¶
func NewOrderCreatedEvent(orderID uint, orderData OrderCreatedData) *OrderCreatedEvent {
    return &OrderCreatedEvent{
        BaseEvent: &event.BaseEvent{
            EventID:     generateEventID(),
            EventType:   OrderCreatedEventType,
            AggregateID: fmt.Sprintf("order_%d", orderID),
            Version:     1,
            Timestamp:   time.Now(),
            Metadata: map[string]interface{}{
                "source": "order-service",
                "user_id": orderData.UserID,
            },
        },
        OrderData: orderData,
    }
}

// è®¢å•æ”¯ä»˜äº‹ä»¶
type OrderPaidEvent struct {
    *event.BaseEvent
    PaymentData OrderPaidData `json:"payment_data"`
}

type OrderPaidData struct {
    OrderID       uint      `json:"order_id"`
    PaymentMethod string    `json:"payment_method"`
    Amount        float64   `json:"amount"`
    TransactionID string    `json:"transaction_id"`
    PaidAt        time.Time `json:"paid_at"`
}

// åˆ›å»ºè®¢å•æ”¯ä»˜äº‹ä»¶
func NewOrderPaidEvent(orderID uint, paymentData OrderPaidData) *OrderPaidEvent {
    return &OrderPaidEvent{
        BaseEvent: &event.BaseEvent{
            EventID:     generateEventID(),
            EventType:   OrderPaidEventType,
            AggregateID: fmt.Sprintf("order_%d", orderID),
            Version:     2,
            Timestamp:   time.Now(),
            Metadata: map[string]interface{}{
                "source": "payment-service",
                "transaction_id": paymentData.TransactionID,
            },
        },
        PaymentData: paymentData,
    }
}

// è®¢å•å‘è´§äº‹ä»¶
type OrderShippedEvent struct {
    *event.BaseEvent
    ShippingData OrderShippedData `json:"shipping_data"`
}

type OrderShippedData struct {
    OrderID        uint      `json:"order_id"`
    TrackingNumber string    `json:"tracking_number"`
    Carrier        string    `json:"carrier"`
    ShippedAt      time.Time `json:"shipped_at"`
    EstimatedDelivery time.Time `json:"estimated_delivery"`
}

// åˆ›å»ºè®¢å•å‘è´§äº‹ä»¶
func NewOrderShippedEvent(orderID uint, shippingData OrderShippedData) *OrderShippedEvent {
    return &OrderShippedEvent{
        BaseEvent: &event.BaseEvent{
            EventID:     generateEventID(),
            EventType:   OrderShippedEventType,
            AggregateID: fmt.Sprintf("order_%d", orderID),
            Version:     3,
            Timestamp:   time.Now(),
            Metadata: map[string]interface{}{
                "source": "shipping-service",
                "tracking_number": shippingData.TrackingNumber,
            },
        },
        ShippingData: shippingData,
    }
}

// è®¢å•å–æ¶ˆäº‹ä»¶
type OrderCancelledEvent struct {
    *event.BaseEvent
    CancellationData OrderCancelledData `json:"cancellation_data"`
}

type OrderCancelledData struct {
    OrderID     uint      `json:"order_id"`
    Reason      string    `json:"reason"`
    CancelledBy string    `json:"cancelled_by"`
    CancelledAt time.Time `json:"cancelled_at"`
}

// åˆ›å»ºè®¢å•å–æ¶ˆäº‹ä»¶
func NewOrderCancelledEvent(orderID uint, cancellationData OrderCancelledData) *OrderCancelledEvent {
    return &OrderCancelledEvent{
        BaseEvent: &event.BaseEvent{
            EventID:     generateEventID(),
            EventType:   OrderCancelledEventType,
            AggregateID: fmt.Sprintf("order_%d", orderID),
            Version:     4,
            Timestamp:   time.Now(),
            Metadata: map[string]interface{}{
                "source": "order-service",
                "cancelled_by": cancellationData.CancelledBy,
            },
        },
        CancellationData: cancellationData,
    }
}

func generateEventID() string {
    return fmt.Sprintf("evt_%d", time.Now().UnixNano())
}
```

### äº‹ä»¶å¤„ç†å™¨å®ç°

```go
// æ¥è‡ª mall-go/internal/handler/order_event_handler.go
package handler

import (
    "context"
    "encoding/json"
    "fmt"
    "log"

    "mall-go/internal/event"
    "mall-go/internal/domain/order"
    "mall-go/internal/service"
)

// è®¢å•äº‹ä»¶å¤„ç†å™¨
type OrderEventHandler struct {
    inventoryService    *service.InventoryService
    notificationService *service.NotificationService
    analyticsService    *service.AnalyticsService
    handlerName         string
}

// åˆ›å»ºè®¢å•äº‹ä»¶å¤„ç†å™¨
func NewOrderEventHandler(
    inventoryService *service.InventoryService,
    notificationService *service.NotificationService,
    analyticsService *service.AnalyticsService,
) *OrderEventHandler {
    return &OrderEventHandler{
        inventoryService:    inventoryService,
        notificationService: notificationService,
        analyticsService:    analyticsService,
        handlerName:         "OrderEventHandler",
    }
}

// è·å–å¤„ç†å™¨åç§°
func (h *OrderEventHandler) GetHandlerName() string {
    return h.handlerName
}

// å¤„ç†äº‹ä»¶
func (h *OrderEventHandler) Handle(ctx context.Context, event event.Event) error {
    switch event.GetEventType() {
    case order.OrderCreatedEventType:
        return h.handleOrderCreated(ctx, event)
    case order.OrderPaidEventType:
        return h.handleOrderPaid(ctx, event)
    case order.OrderShippedEventType:
        return h.handleOrderShipped(ctx, event)
    case order.OrderCancelledEventType:
        return h.handleOrderCancelled(ctx, event)
    default:
        return fmt.Errorf("unsupported event type: %s", event.GetEventType())
    }
}

// å¤„ç†è®¢å•åˆ›å»ºäº‹ä»¶
func (h *OrderEventHandler) handleOrderCreated(ctx context.Context, event event.Event) error {
    var orderCreatedEvent order.OrderCreatedEvent
    if err := h.unmarshalEvent(event, &orderCreatedEvent); err != nil {
        return err
    }

    log.Printf("Handling order created event: OrderID=%d", orderCreatedEvent.OrderData.OrderID)

    // 1. æ›´æ–°åº“å­˜
    if err := h.updateInventory(ctx, orderCreatedEvent.OrderData); err != nil {
        return fmt.Errorf("failed to update inventory: %w", err)
    }

    // 2. å‘é€é€šçŸ¥
    if err := h.sendOrderCreatedNotification(ctx, orderCreatedEvent.OrderData); err != nil {
        log.Printf("Failed to send notification: %v", err)
        // é€šçŸ¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    }

    // 3. è®°å½•åˆ†ææ•°æ®
    if err := h.recordOrderAnalytics(ctx, orderCreatedEvent.OrderData); err != nil {
        log.Printf("Failed to record analytics: %v", err)
        // åˆ†ææ•°æ®è®°å½•å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    }

    return nil
}

// å¤„ç†è®¢å•æ”¯ä»˜äº‹ä»¶
func (h *OrderEventHandler) handleOrderPaid(ctx context.Context, event event.Event) error {
    var orderPaidEvent order.OrderPaidEvent
    if err := h.unmarshalEvent(event, &orderPaidEvent); err != nil {
        return err
    }

    log.Printf("Handling order paid event: OrderID=%d", orderPaidEvent.PaymentData.OrderID)

    // 1. è§¦å‘å‘è´§æµç¨‹
    if err := h.triggerShipping(ctx, orderPaidEvent.PaymentData); err != nil {
        return fmt.Errorf("failed to trigger shipping: %w", err)
    }

    // 2. å‘é€æ”¯ä»˜æˆåŠŸé€šçŸ¥
    if err := h.sendPaymentSuccessNotification(ctx, orderPaidEvent.PaymentData); err != nil {
        log.Printf("Failed to send payment notification: %v", err)
    }

    // 3. æ›´æ–°ç”¨æˆ·ç§¯åˆ†
    if err := h.updateUserPoints(ctx, orderPaidEvent.PaymentData); err != nil {
        log.Printf("Failed to update user points: %v", err)
    }

    return nil
}

// å¤„ç†è®¢å•å‘è´§äº‹ä»¶
func (h *OrderEventHandler) handleOrderShipped(ctx context.Context, event event.Event) error {
    var orderShippedEvent order.OrderShippedEvent
    if err := h.unmarshalEvent(event, &orderShippedEvent); err != nil {
        return err
    }

    log.Printf("Handling order shipped event: OrderID=%d", orderShippedEvent.ShippingData.OrderID)

    // 1. å‘é€å‘è´§é€šçŸ¥
    if err := h.sendShippingNotification(ctx, orderShippedEvent.ShippingData); err != nil {
        log.Printf("Failed to send shipping notification: %v", err)
    }

    // 2. å¯åŠ¨ç‰©æµè·Ÿè¸ª
    if err := h.startLogisticsTracking(ctx, orderShippedEvent.ShippingData); err != nil {
        log.Printf("Failed to start logistics tracking: %v", err)
    }

    return nil
}

// å¤„ç†è®¢å•å–æ¶ˆäº‹ä»¶
func (h *OrderEventHandler) handleOrderCancelled(ctx context.Context, event event.Event) error {
    var orderCancelledEvent order.OrderCancelledEvent
    if err := h.unmarshalEvent(event, &orderCancelledEvent); err != nil {
        return err
    }

    log.Printf("Handling order cancelled event: OrderID=%d", orderCancelledEvent.CancellationData.OrderID)

    // 1. æ¢å¤åº“å­˜
    if err := h.restoreInventory(ctx, orderCancelledEvent.CancellationData); err != nil {
        return fmt.Errorf("failed to restore inventory: %w", err)
    }

    // 2. å¤„ç†é€€æ¬¾
    if err := h.processRefund(ctx, orderCancelledEvent.CancellationData); err != nil {
        return fmt.Errorf("failed to process refund: %w", err)
    }

    // 3. å‘é€å–æ¶ˆé€šçŸ¥
    if err := h.sendCancellationNotification(ctx, orderCancelledEvent.CancellationData); err != nil {
        log.Printf("Failed to send cancellation notification: %v", err)
    }

    return nil
}

// è¾…åŠ©æ–¹æ³•
func (h *OrderEventHandler) unmarshalEvent(event event.Event, target interface{}) error {
    eventBytes, err := json.Marshal(event)
    if err != nil {
        return fmt.Errorf("failed to marshal event: %w", err)
    }

    if err := json.Unmarshal(eventBytes, target); err != nil {
        return fmt.Errorf("failed to unmarshal event: %w", err)
    }

    return nil
}

func (h *OrderEventHandler) updateInventory(ctx context.Context, orderData order.OrderCreatedData) error {
    return h.inventoryService.UpdateStock(ctx, orderData.Items)
}

func (h *OrderEventHandler) sendOrderCreatedNotification(ctx context.Context, orderData order.OrderCreatedData) error {
    return h.notificationService.SendOrderCreatedNotification(ctx, orderData.UserID, orderData.OrderID)
}

func (h *OrderEventHandler) recordOrderAnalytics(ctx context.Context, orderData order.OrderCreatedData) error {
    return h.analyticsService.RecordOrderCreated(ctx, orderData)
}

func (h *OrderEventHandler) triggerShipping(ctx context.Context, paymentData order.OrderPaidData) error {
    // æ¨¡æ‹Ÿè§¦å‘å‘è´§
    log.Printf("Triggering shipping for order: %d", paymentData.OrderID)
    return nil
}

func (h *OrderEventHandler) sendPaymentSuccessNotification(ctx context.Context, paymentData order.OrderPaidData) error {
    // æ¨¡æ‹Ÿå‘é€æ”¯ä»˜æˆåŠŸé€šçŸ¥
    log.Printf("Sending payment success notification for order: %d", paymentData.OrderID)
    return nil
}

func (h *OrderEventHandler) updateUserPoints(ctx context.Context, paymentData order.OrderPaidData) error {
    // æ¨¡æ‹Ÿæ›´æ–°ç”¨æˆ·ç§¯åˆ†
    log.Printf("Updating user points for order: %d", paymentData.OrderID)
    return nil
}

func (h *OrderEventHandler) sendShippingNotification(ctx context.Context, shippingData order.OrderShippedData) error {
    // æ¨¡æ‹Ÿå‘é€å‘è´§é€šçŸ¥
    log.Printf("Sending shipping notification for order: %d", shippingData.OrderID)
    return nil
}

func (h *OrderEventHandler) startLogisticsTracking(ctx context.Context, shippingData order.OrderShippedData) error {
    // æ¨¡æ‹Ÿå¯åŠ¨ç‰©æµè·Ÿè¸ª
    log.Printf("Starting logistics tracking for order: %d", shippingData.OrderID)
    return nil
}

func (h *OrderEventHandler) restoreInventory(ctx context.Context, cancellationData order.OrderCancelledData) error {
    // æ¨¡æ‹Ÿæ¢å¤åº“å­˜
    log.Printf("Restoring inventory for order: %d", cancellationData.OrderID)
    return nil
}

func (h *OrderEventHandler) processRefund(ctx context.Context, cancellationData order.OrderCancelledData) error {
    // æ¨¡æ‹Ÿå¤„ç†é€€æ¬¾
    log.Printf("Processing refund for order: %d", cancellationData.OrderID)
    return nil
}

func (h *OrderEventHandler) sendCancellationNotification(ctx context.Context, cancellationData order.OrderCancelledData) error {
    // æ¨¡æ‹Ÿå‘é€å–æ¶ˆé€šçŸ¥
    log.Printf("Sending cancellation notification for order: %d", cancellationData.OrderID)
    return nil
}
```

---

## ğŸ¯ é¢è¯•å¸¸è€ƒç‚¹

### 1. æ¶ˆæ¯é˜Ÿåˆ—åŸºç¡€æ¦‚å¿µ

**é—®é¢˜ï¼š** ä»€ä¹ˆæ˜¯æ¶ˆæ¯é˜Ÿåˆ—ï¼Ÿæœ‰ä»€ä¹ˆä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Ÿ

**ç­”æ¡ˆï¼š**
```go
/*
æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆMessage Queueï¼‰æ˜¯ä¸€ç§åº”ç”¨ç¨‹åºé—´çš„é€šä¿¡æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¶ˆæ¯çš„ä¼ è¾“è¿‡ç¨‹ä¸­ä¿å­˜æ¶ˆæ¯æ¥å®ç°åº”ç”¨ç¨‹åºé—´çš„å¼‚æ­¥é€šä¿¡ã€‚

ä¼˜åŠ¿ï¼š
âœ… ç³»ç»Ÿè§£è€¦ï¼šç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ä¸éœ€è¦ç›´æ¥äº¤äº’
âœ… å¼‚æ­¥å¤„ç†ï¼šæé«˜ç³»ç»Ÿå“åº”é€Ÿåº¦å’Œååé‡
âœ… æµé‡å‰Šå³°ï¼šç¼“è§£ç³»ç»Ÿå‹åŠ›ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½
âœ… å¯é æ€§ï¼šæ¶ˆæ¯æŒä¹…åŒ–ï¼Œä¿è¯æ¶ˆæ¯ä¸ä¸¢å¤±
âœ… æ‰©å±•æ€§ï¼šæ˜“äºæ°´å¹³æ‰©å±•å’Œè´Ÿè½½å‡è¡¡

åŠ£åŠ¿ï¼š
âŒ ç³»ç»Ÿå¤æ‚æ€§ï¼šå¢åŠ äº†ç³»ç»Ÿçš„å¤æ‚åº¦
âŒ ä¸€è‡´æ€§é—®é¢˜ï¼šå¼‚æ­¥å¤„ç†å¯èƒ½å¯¼è‡´æ•°æ®ä¸€è‡´æ€§é—®é¢˜
âŒ æ¶ˆæ¯é‡å¤ï¼šç½‘ç»œé—®é¢˜å¯èƒ½å¯¼è‡´æ¶ˆæ¯é‡å¤æ¶ˆè´¹
âŒ æ¶ˆæ¯é¡ºåºï¼šåˆ†å¸ƒå¼ç¯å¢ƒä¸‹éš¾ä»¥ä¿è¯æ¶ˆæ¯é¡ºåº
âŒ è°ƒè¯•å›°éš¾ï¼šå¼‚æ­¥å¤„ç†å¢åŠ äº†è°ƒè¯•éš¾åº¦
*/

// æ¶ˆæ¯é˜Ÿåˆ—çš„æ ¸å¿ƒç»„ä»¶
type MessageQueueComponents struct {
    Producer  Producer  // ç”Ÿäº§è€…ï¼šå‘é€æ¶ˆæ¯
    Consumer  Consumer  // æ¶ˆè´¹è€…ï¼šæ¥æ”¶å’Œå¤„ç†æ¶ˆæ¯
    Broker    Broker    // ä»£ç†ï¼šå­˜å‚¨å’Œè½¬å‘æ¶ˆæ¯
    Topic     Topic     // ä¸»é¢˜ï¼šæ¶ˆæ¯åˆ†ç±»
    Queue     Queue     // é˜Ÿåˆ—ï¼šæ¶ˆæ¯å­˜å‚¨
    Exchange  Exchange  // äº¤æ¢æœºï¼šæ¶ˆæ¯è·¯ç”±ï¼ˆRabbitMQï¼‰
}

// æ¶ˆæ¯ä¼ é€’æ¨¡å¼
type MessagePatterns struct {
    PointToPoint    string // ç‚¹å¯¹ç‚¹ï¼šä¸€å¯¹ä¸€æ¶ˆæ¯ä¼ é€’
    PublishSubscribe string // å‘å¸ƒè®¢é˜…ï¼šä¸€å¯¹å¤šæ¶ˆæ¯ä¼ é€’
    RequestReply    string // è¯·æ±‚å“åº”ï¼šåŒæ­¥æ¶ˆæ¯ä¼ é€’
    MessageRouting  string // æ¶ˆæ¯è·¯ç”±ï¼šåŸºäºè§„åˆ™çš„æ¶ˆæ¯åˆ†å‘
}
```

### 2. æ¶ˆæ¯å¯é æ€§ä¿è¯

**é—®é¢˜ï¼š** å¦‚ä½•ä¿è¯æ¶ˆæ¯çš„å¯é æ€§ï¼Ÿæ¶ˆæ¯ä¸¢å¤±çš„åœºæ™¯æœ‰å“ªäº›ï¼Ÿ

**ç­”æ¡ˆï¼š**
```go
/*
æ¶ˆæ¯ä¸¢å¤±çš„ä¸‰ä¸ªé˜¶æ®µï¼š
1. ç”Ÿäº§è€…å‘é€æ¶ˆæ¯æ—¶ä¸¢å¤±
2. æ¶ˆæ¯é˜Ÿåˆ—å­˜å‚¨æ—¶ä¸¢å¤±
3. æ¶ˆè´¹è€…å¤„ç†æ¶ˆæ¯æ—¶ä¸¢å¤±

è§£å†³æ–¹æ¡ˆï¼š
*/

// 1. ç”Ÿäº§è€…ç¡®è®¤æœºåˆ¶
type ProducerConfirmation struct {
    // RabbitMQç¡®è®¤æœºåˆ¶
    ConfirmMode bool `json:"confirm_mode"` // å¼€å¯ç¡®è®¤æ¨¡å¼

    // Kafkaç¡®è®¤æœºåˆ¶
    RequiredAcks int `json:"required_acks"` // 0=ä¸ç­‰å¾…, 1=ç­‰å¾…leader, -1=ç­‰å¾…æ‰€æœ‰å‰¯æœ¬

    // é‡è¯•æœºåˆ¶
    RetryCount int           `json:"retry_count"`
    RetryDelay time.Duration `json:"retry_delay"`
}

// ç”Ÿäº§è€…ç¡®è®¤ç¤ºä¾‹
func (p *Producer) SendWithConfirmation(ctx context.Context, message *Message) error {
    // å¼€å¯ç¡®è®¤æ¨¡å¼
    if err := p.channel.Confirm(false); err != nil {
        return err
    }

    // ç›‘å¬ç¡®è®¤
    confirms := p.channel.NotifyPublish(make(chan amqp.Confirmation, 1))

    // å‘é€æ¶ˆæ¯
    if err := p.channel.Publish("exchange", "routing.key", false, false, amqp.Publishing{
        Body: message.Body,
        DeliveryMode: 2, // æŒä¹…åŒ–
    }); err != nil {
        return err
    }

    // ç­‰å¾…ç¡®è®¤
    select {
    case confirm := <-confirms:
        if !confirm.Ack {
            return fmt.Errorf("message not acknowledged")
        }
        return nil
    case <-time.After(5 * time.Second):
        return fmt.Errorf("confirmation timeout")
    }
}

// 2. æ¶ˆæ¯æŒä¹…åŒ–
type MessagePersistence struct {
    // RabbitMQæŒä¹…åŒ–
    DurableQueue    bool `json:"durable_queue"`    // é˜Ÿåˆ—æŒä¹…åŒ–
    DurableExchange bool `json:"durable_exchange"` // äº¤æ¢æœºæŒä¹…åŒ–
    PersistentMessage bool `json:"persistent_message"` // æ¶ˆæ¯æŒä¹…åŒ–

    // KafkaæŒä¹…åŒ–
    ReplicationFactor int `json:"replication_factor"` // å‰¯æœ¬å› å­
    MinInSyncReplicas int `json:"min_in_sync_replicas"` // æœ€å°åŒæ­¥å‰¯æœ¬æ•°
}

// 3. æ¶ˆè´¹è€…ç¡®è®¤æœºåˆ¶
type ConsumerAcknowledgment struct {
    AutoAck    bool `json:"auto_ack"`    // è‡ªåŠ¨ç¡®è®¤
    ManualAck  bool `json:"manual_ack"`  // æ‰‹åŠ¨ç¡®è®¤
    RejectRequeue bool `json:"reject_requeue"` // æ‹’ç»å¹¶é‡æ–°å…¥é˜Ÿ
}

// æ¶ˆè´¹è€…æ‰‹åŠ¨ç¡®è®¤ç¤ºä¾‹
func (c *Consumer) ProcessMessage(delivery amqp.Delivery) {
    defer func() {
        if r := recover(); r != nil {
            // å¤„ç†å¼‚å¸¸ï¼Œæ‹’ç»æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
            delivery.Nack(false, true)
        }
    }()

    // å¤„ç†æ¶ˆæ¯
    if err := c.handleMessage(delivery.Body); err != nil {
        // å¤„ç†å¤±è´¥ï¼Œæ‹’ç»æ¶ˆæ¯
        delivery.Nack(false, false) // ä¸é‡æ–°å…¥é˜Ÿï¼Œå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
        return
    }

    // å¤„ç†æˆåŠŸï¼Œç¡®è®¤æ¶ˆæ¯
    delivery.Ack(false)
}

// 4. æ­»ä¿¡é˜Ÿåˆ—å¤„ç†
type DeadLetterQueue struct {
    Exchange   string `json:"exchange"`
    RoutingKey string `json:"routing_key"`
    TTL        int    `json:"ttl"` // æ¶ˆæ¯å­˜æ´»æ—¶é—´
}

// æ­»ä¿¡é˜Ÿåˆ—é…ç½®
func ConfigureDeadLetterQueue(ch *amqp.Channel) error {
    // å£°æ˜æ­»ä¿¡äº¤æ¢æœº
    if err := ch.ExchangeDeclare("dlx", "direct", true, false, false, false, nil); err != nil {
        return err
    }

    // å£°æ˜ä¸»é˜Ÿåˆ—ï¼Œé…ç½®æ­»ä¿¡äº¤æ¢æœº
    _, err := ch.QueueDeclare("main.queue", true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "dlx",
        "x-dead-letter-routing-key": "dead.letter",
        "x-message-ttl":             300000, // 5åˆ†é’ŸTTL
    })

    return err
}
```

### 3. æ¶ˆæ¯é‡å¤å’Œå¹‚ç­‰æ€§

**é—®é¢˜ï¼š** å¦‚ä½•å¤„ç†æ¶ˆæ¯é‡å¤æ¶ˆè´¹ï¼Ÿå¦‚ä½•ä¿è¯æ¶ˆè´¹çš„å¹‚ç­‰æ€§ï¼Ÿ

**ç­”æ¡ˆï¼š**
```go
/*
æ¶ˆæ¯é‡å¤çš„åŸå› ï¼š
1. ç½‘ç»œé—®é¢˜å¯¼è‡´ç¡®è®¤ä¸¢å¤±
2. æ¶ˆè´¹è€…å¤„ç†è¶…æ—¶
3. ç³»ç»Ÿé‡å¯æˆ–æ•…éšœæ¢å¤
4. è´Ÿè½½å‡è¡¡å¯¼è‡´çš„é‡å¤æŠ•é€’

è§£å†³æ–¹æ¡ˆï¼š
*/

// 1. æ¶ˆæ¯å»é‡
type MessageDeduplication struct {
    MessageID string    `json:"message_id"` // å…¨å±€å”¯ä¸€æ¶ˆæ¯ID
    Timestamp int64     `json:"timestamp"`  // æ¶ˆæ¯æ—¶é—´æˆ³
    Hash      string    `json:"hash"`       // æ¶ˆæ¯å†…å®¹å“ˆå¸Œ
}

// åŸºäºRedisçš„æ¶ˆæ¯å»é‡
type RedisDeduplicator struct {
    rdb *redis.Client
    ttl time.Duration
}

func (d *RedisDeduplicator) IsDuplicate(ctx context.Context, messageID string) (bool, error) {
    key := fmt.Sprintf("msg:processed:%s", messageID)

    // ä½¿ç”¨SET NXå‘½ä»¤å®ç°åŸå­æ€§æ£€æŸ¥å’Œè®¾ç½®
    result, err := d.rdb.SetNX(ctx, key, "1", d.ttl).Result()
    if err != nil {
        return false, err
    }

    // å¦‚æœè®¾ç½®æˆåŠŸï¼Œè¯´æ˜æ˜¯ç¬¬ä¸€æ¬¡å¤„ç†
    return !result, nil
}

// æ¶ˆè´¹è€…å»é‡å¤„ç†
func (c *Consumer) ProcessMessageWithDeduplication(ctx context.Context, delivery amqp.Delivery) error {
    var message struct {
        ID      string      `json:"id"`
        Content interface{} `json:"content"`
    }

    if err := json.Unmarshal(delivery.Body, &message); err != nil {
        return err
    }

    // æ£€æŸ¥æ˜¯å¦é‡å¤
    isDuplicate, err := c.deduplicator.IsDuplicate(ctx, message.ID)
    if err != nil {
        return err
    }

    if isDuplicate {
        log.Printf("Duplicate message detected: %s", message.ID)
        delivery.Ack(false) // ç¡®è®¤æ¶ˆæ¯ï¼Œé¿å…é‡å¤å¤„ç†
        return nil
    }

    // å¤„ç†æ¶ˆæ¯
    if err := c.handleMessage(ctx, message.Content); err != nil {
        return err
    }

    delivery.Ack(false)
    return nil
}

// 2. å¹‚ç­‰æ€§è®¾è®¡
type IdempotentOperation struct {
    OperationID string `json:"operation_id"` // æ“ä½œå”¯ä¸€æ ‡è¯†
    Version     int    `json:"version"`      // ç‰ˆæœ¬å·
    Status      string `json:"status"`       // æ“ä½œçŠ¶æ€
}

// å¹‚ç­‰æ€§å¤„ç†ç¤ºä¾‹
func (s *OrderService) ProcessPayment(ctx context.Context, orderID uint, amount float64, operationID string) error {
    // æ£€æŸ¥æ“ä½œæ˜¯å¦å·²æ‰§è¡Œ
    operation, err := s.getOperation(ctx, operationID)
    if err != nil && err != ErrOperationNotFound {
        return err
    }

    if operation != nil {
        switch operation.Status {
        case "completed":
            return nil // å·²å®Œæˆï¼Œç›´æ¥è¿”å›
        case "processing":
            return ErrOperationInProgress
        case "failed":
            // å¯ä»¥é‡è¯•
            break
        }
    }

    // è®°å½•æ“ä½œå¼€å§‹
    if err := s.recordOperation(ctx, operationID, "processing"); err != nil {
        return err
    }

    // æ‰§è¡Œæ”¯ä»˜
    if err := s.doPayment(ctx, orderID, amount); err != nil {
        s.recordOperation(ctx, operationID, "failed")
        return err
    }

    // è®°å½•æ“ä½œå®Œæˆ
    return s.recordOperation(ctx, operationID, "completed")
}

// 3. åŸºäºæ•°æ®åº“çº¦æŸçš„å¹‚ç­‰æ€§
type PaymentRecord struct {
    ID          uint      `gorm:"primaryKey"`
    OrderID     uint      `gorm:"not null"`
    Amount      float64   `gorm:"not null"`
    OperationID string    `gorm:"uniqueIndex;not null"` // å”¯ä¸€çº¦æŸ
    Status      string    `gorm:"not null"`
    CreatedAt   time.Time
}

// åˆ©ç”¨æ•°æ®åº“å”¯ä¸€çº¦æŸä¿è¯å¹‚ç­‰æ€§
func (s *PaymentService) ProcessPaymentIdempotent(ctx context.Context, orderID uint, amount float64, operationID string) error {
    payment := &PaymentRecord{
        OrderID:     orderID,
        Amount:      amount,
        OperationID: operationID,
        Status:      "processing",
        CreatedAt:   time.Now(),
    }

    // æ’å…¥è®°å½•ï¼Œå¦‚æœoperationIDé‡å¤ä¼šå¤±è´¥
    if err := s.db.Create(payment).Error; err != nil {
        if isUniqueConstraintError(err) {
            // æ£€æŸ¥å·²å­˜åœ¨è®°å½•çš„çŠ¶æ€
            var existing PaymentRecord
            if err := s.db.Where("operation_id = ?", operationID).First(&existing).Error; err != nil {
                return err
            }

            if existing.Status == "completed" {
                return nil // å·²å®Œæˆ
            }

            return ErrOperationInProgress
        }
        return err
    }

    // æ‰§è¡Œæ”¯ä»˜é€»è¾‘
    if err := s.doPayment(ctx, orderID, amount); err != nil {
        // æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        s.db.Model(payment).Update("status", "failed")
        return err
    }

    // æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
    return s.db.Model(payment).Update("status", "completed").Error
}
```

### 4. æ¶ˆæ¯é¡ºåºæ€§ä¿è¯

**é—®é¢˜ï¼š** å¦‚ä½•ä¿è¯æ¶ˆæ¯çš„é¡ºåºæ€§ï¼Ÿ

**ç­”æ¡ˆï¼š**
```go
/*
æ¶ˆæ¯é¡ºåºæ€§çš„æŒ‘æˆ˜ï¼š
1. åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„å¹¶å‘å¤„ç†
2. å¤šä¸ªç”Ÿäº§è€…åŒæ—¶å‘é€æ¶ˆæ¯
3. æ¶ˆæ¯é‡è¯•å¯èƒ½æ‰“ä¹±é¡ºåº
4. è´Ÿè½½å‡è¡¡å¯¼è‡´çš„ä¹±åº

è§£å†³æ–¹æ¡ˆï¼š
*/

// 1. å•åˆ†åŒº/å•é˜Ÿåˆ—ä¿è¯é¡ºåº
type OrderedMessageProducer struct {
    producer *kafka.Producer
}

// åŸºäºåˆ†åŒºé”®ä¿è¯é¡ºåº
func (p *OrderedMessageProducer) SendOrderedMessage(ctx context.Context, topic string, key string, message interface{}) error {
    // ä½¿ç”¨ç›¸åŒçš„keyç¡®ä¿æ¶ˆæ¯å‘é€åˆ°åŒä¸€åˆ†åŒº
    kafkaMsg := &kafka.KafkaMessage{
        Key:   key, // ç›¸åŒä¸šåŠ¡çš„æ¶ˆæ¯ä½¿ç”¨ç›¸åŒkey
        Value: message,
        Timestamp: time.Now(),
    }

    return p.producer.Send(ctx, topic, kafkaMsg)
}

// 2. æ¶ˆæ¯åºåˆ—å·
type SequencedMessage struct {
    SequenceID int64       `json:"sequence_id"`
    BusinessID string      `json:"business_id"` // ä¸šåŠ¡æ ‡è¯†
    Content    interface{} `json:"content"`
    Timestamp  int64       `json:"timestamp"`
}

// é¡ºåºæ¶ˆè´¹è€…
type OrderedConsumer struct {
    consumer        *kafka.Consumer
    sequenceTracker map[string]int64 // è·Ÿè¸ªæ¯ä¸ªä¸šåŠ¡çš„åºåˆ—å·
    mutex           sync.RWMutex
}

func (c *OrderedConsumer) ProcessOrderedMessage(ctx context.Context, message *sarama.ConsumerMessage) error {
    var seqMsg SequencedMessage
    if err := json.Unmarshal(message.Value, &seqMsg); err != nil {
        return err
    }

    c.mutex.Lock()
    defer c.mutex.Unlock()

    expectedSeq := c.sequenceTracker[seqMsg.BusinessID] + 1

    if seqMsg.SequenceID < expectedSeq {
        // é‡å¤æ¶ˆæ¯ï¼Œå¿½ç•¥
        log.Printf("Duplicate message: expected=%d, got=%d", expectedSeq, seqMsg.SequenceID)
        return nil
    }

    if seqMsg.SequenceID > expectedSeq {
        // æ¶ˆæ¯ä¹±åºï¼Œéœ€è¦ç­‰å¾…æˆ–é‡æ–°æ’åº
        log.Printf("Out of order message: expected=%d, got=%d", expectedSeq, seqMsg.SequenceID)
        return c.handleOutOfOrderMessage(ctx, &seqMsg)
    }

    // æ­£ç¡®é¡ºåºï¼Œå¤„ç†æ¶ˆæ¯
    if err := c.handleMessage(ctx, seqMsg.Content); err != nil {
        return err
    }

    // æ›´æ–°åºåˆ—å·
    c.sequenceTracker[seqMsg.BusinessID] = seqMsg.SequenceID
    return nil
}

// 3. åŸºäºæ—¶é—´æˆ³çš„æ’åº
type TimestampOrderedConsumer struct {
    consumer    *kafka.Consumer
    buffer      map[string][]*TimestampedMessage // ç¼“å†²åŒº
    bufferSize  int
    waitTimeout time.Duration
}

type TimestampedMessage struct {
    BusinessID string      `json:"business_id"`
    Timestamp  int64       `json:"timestamp"`
    Content    interface{} `json:"content"`
}

func (c *TimestampOrderedConsumer) ProcessTimestampedMessage(ctx context.Context, message *sarama.ConsumerMessage) error {
    var tsMsg TimestampedMessage
    if err := json.Unmarshal(message.Value, &tsMsg); err != nil {
        return err
    }

    // æ·»åŠ åˆ°ç¼“å†²åŒº
    c.addToBuffer(&tsMsg)

    // æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†ç¼“å†²åŒºä¸­çš„æ¶ˆæ¯
    return c.processBufferedMessages(ctx, tsMsg.BusinessID)
}

func (c *TimestampOrderedConsumer) addToBuffer(msg *TimestampedMessage) {
    if c.buffer[msg.BusinessID] == nil {
        c.buffer[msg.BusinessID] = make([]*TimestampedMessage, 0)
    }

    // æŒ‰æ—¶é—´æˆ³æ’åºæ’å…¥
    buffer := c.buffer[msg.BusinessID]
    insertIndex := len(buffer)

    for i, bufferedMsg := range buffer {
        if msg.Timestamp < bufferedMsg.Timestamp {
            insertIndex = i
            break
        }
    }

    // æ’å…¥æ¶ˆæ¯
    buffer = append(buffer, nil)
    copy(buffer[insertIndex+1:], buffer[insertIndex:])
    buffer[insertIndex] = msg

    c.buffer[msg.BusinessID] = buffer
}

func (c *TimestampOrderedConsumer) processBufferedMessages(ctx context.Context, businessID string) error {
    buffer := c.buffer[businessID]
    if len(buffer) == 0 {
        return nil
    }

    now := time.Now().UnixMilli()
    processedCount := 0

    // å¤„ç†è¶…è¿‡ç­‰å¾…æ—¶é—´çš„æ¶ˆæ¯
    for i, msg := range buffer {
        if now-msg.Timestamp > c.waitTimeout.Milliseconds() || len(buffer) > c.bufferSize {
            if err := c.handleMessage(ctx, msg.Content); err != nil {
                return err
            }
            processedCount = i + 1
        } else {
            break
        }
    }

    // ç§»é™¤å·²å¤„ç†çš„æ¶ˆæ¯
    if processedCount > 0 {
        c.buffer[businessID] = buffer[processedCount:]
    }

    return nil
}
```

---

## âš ï¸ è¸©å‘æé†’

### 1. è¿æ¥ç®¡ç†é™·é˜±

```go
// âŒ é”™è¯¯ï¼šæ¯æ¬¡å‘é€æ¶ˆæ¯éƒ½åˆ›å»ºæ–°è¿æ¥
func BadConnectionManagement() {
    for i := 0; i < 1000; i++ {
        // æ¯æ¬¡éƒ½åˆ›å»ºæ–°è¿æ¥ï¼Œèµ„æºæµªè´¹ä¸¥é‡
        conn, _ := amqp.Dial("amqp://localhost")
        ch, _ := conn.Channel()

        ch.Publish("exchange", "key", false, false, amqp.Publishing{
            Body: []byte("message"),
        })

        ch.Close()
        conn.Close()
    }
}

// âœ… æ­£ç¡®ï¼šä½¿ç”¨è¿æ¥æ± ç®¡ç†è¿æ¥
type ConnectionPool struct {
    connections chan *amqp.Connection
    maxSize     int
    url         string
}

func NewConnectionPool(url string, maxSize int) *ConnectionPool {
    pool := &ConnectionPool{
        connections: make(chan *amqp.Connection, maxSize),
        maxSize:     maxSize,
        url:         url,
    }

    // é¢„åˆ›å»ºè¿æ¥
    for i := 0; i < maxSize; i++ {
        conn, _ := amqp.Dial(url)
        pool.connections <- conn
    }

    return pool
}

func (p *ConnectionPool) GetConnection() *amqp.Connection {
    return <-p.connections
}

func (p *ConnectionPool) ReturnConnection(conn *amqp.Connection) {
    if !conn.IsClosed() {
        p.connections <- conn
    } else {
        // è¿æ¥å·²å…³é—­ï¼Œåˆ›å»ºæ–°è¿æ¥
        newConn, _ := amqp.Dial(p.url)
        p.connections <- newConn
    }
}
```

### 2. æ¶ˆæ¯åºåˆ—åŒ–é™·é˜±

```go
// âŒ é”™è¯¯ï¼šç›´æ¥åºåˆ—åŒ–å¤æ‚å¯¹è±¡
type ComplexMessage struct {
    Data     map[string]interface{} `json:"data"`
    Callback func()                 `json:"-"` // å‡½æ•°æ— æ³•åºåˆ—åŒ–
    Channel  chan string            `json:"-"` // é€šé“æ— æ³•åºåˆ—åŒ–
    Mutex    sync.Mutex             `json:"-"` // äº’æ–¥é”æ— æ³•åºåˆ—åŒ–
}

func BadSerialization(msg *ComplexMessage) error {
    // è¿™ä¼šå¯¼è‡´åºåˆ—åŒ–å¤±è´¥æˆ–æ•°æ®ä¸¢å¤±
    data, err := json.Marshal(msg)
    if err != nil {
        return err
    }

    // å‘é€æ¶ˆæ¯...
    return nil
}

// âœ… æ­£ç¡®ï¼šè®¾è®¡ä¸“é—¨çš„æ¶ˆæ¯ç»“æ„
type MessagePayload struct {
    ID        string                 `json:"id"`
    Type      string                 `json:"type"`
    Data      map[string]interface{} `json:"data"`
    Timestamp int64                  `json:"timestamp"`
    Version   string                 `json:"version"`
}

func GoodSerialization(businessData interface{}) error {
    // è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
    payload := &MessagePayload{
        ID:        generateID(),
        Type:      "business.event",
        Data:      convertToMap(businessData),
        Timestamp: time.Now().Unix(),
        Version:   "1.0",
    }

    data, err := json.Marshal(payload)
    if err != nil {
        return err
    }

    // å‘é€æ¶ˆæ¯...
    return nil
}

func convertToMap(data interface{}) map[string]interface{} {
    result := make(map[string]interface{})

    // ä½¿ç”¨åå°„æˆ–æ‰‹åŠ¨è½¬æ¢
    bytes, _ := json.Marshal(data)
    json.Unmarshal(bytes, &result)

    return result
}
```

### 3. é”™è¯¯å¤„ç†é™·é˜±

```go
// âŒ é”™è¯¯ï¼šå¿½ç•¥é”™è¯¯æˆ–ç®€å•é‡è¯•
func BadErrorHandling(consumer *Consumer) {
    consumer.RegisterHandler("topic", func(ctx context.Context, msg *Message) error {
        if err := processMessage(msg); err != nil {
            // ç®€å•å¿½ç•¥é”™è¯¯
            log.Printf("Error: %v", err)
            return nil // è¿™ä¼šå¯¼è‡´æ¶ˆæ¯ä¸¢å¤±
        }
        return nil
    })
}

// âœ… æ­£ç¡®ï¼šåˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
type ErrorHandler struct {
    retryableErrors map[string]bool
    maxRetries      int
    deadLetterQueue string
}

func (h *ErrorHandler) HandleError(ctx context.Context, msg *Message, err error) error {
    // åˆ†æé”™è¯¯ç±»å‹
    errorType := classifyError(err)

    switch errorType {
    case "temporary":
        // ä¸´æ—¶é”™è¯¯ï¼Œå¯ä»¥é‡è¯•
        return h.handleRetryableError(ctx, msg, err)
    case "permanent":
        // æ°¸ä¹…é”™è¯¯ï¼Œå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
        return h.sendToDeadLetterQueue(ctx, msg, err)
    case "poison":
        // æ¯’æ¶ˆæ¯ï¼Œè®°å½•å¹¶ä¸¢å¼ƒ
        return h.handlePoisonMessage(ctx, msg, err)
    default:
        // æœªçŸ¥é”™è¯¯ï¼Œä¿å®ˆå¤„ç†
        return h.handleUnknownError(ctx, msg, err)
    }
}

func (h *ErrorHandler) handleRetryableError(ctx context.Context, msg *Message, err error) error {
    if msg.RetryCount >= h.maxRetries {
        // è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
        return h.sendToDeadLetterQueue(ctx, msg, err)
    }

    // å¢åŠ é‡è¯•æ¬¡æ•°
    msg.RetryCount++

    // è®¡ç®—é€€é¿æ—¶é—´
    backoffTime := time.Duration(msg.RetryCount*msg.RetryCount) * time.Second

    // å»¶è¿Ÿé‡è¯•
    time.Sleep(backoffTime)

    return err // è¿”å›é”™è¯¯ï¼Œè§¦å‘é‡è¯•
}

func classifyError(err error) string {
    switch {
    case isNetworkError(err):
        return "temporary"
    case isValidationError(err):
        return "permanent"
    case isSerializationError(err):
        return "poison"
    default:
        return "unknown"
    }
}
```

### 4. å†…å­˜æ³„æ¼é™·é˜±

```go
// âŒ é”™è¯¯ï¼šä¸æ­£ç¡®çš„èµ„æºç®¡ç†
func BadResourceManagement() {
    consumers := make([]*Consumer, 0)

    for i := 0; i < 100; i++ {
        consumer := createConsumer()
        consumers = append(consumers, consumer)

        // å¯åŠ¨æ¶ˆè´¹è€…ä½†æ²¡æœ‰æ­£ç¡®å…³é—­
        consumer.Start()
    }

    // ç¨‹åºç»“æŸæ—¶æ²¡æœ‰æ¸…ç†èµ„æº
}

// âœ… æ­£ç¡®ï¼šä½¿ç”¨èµ„æºç®¡ç†å™¨
type ResourceManager struct {
    consumers []io.Closer
    producers []io.Closer
    mutex     sync.Mutex
}

func NewResourceManager() *ResourceManager {
    return &ResourceManager{
        consumers: make([]io.Closer, 0),
        producers: make([]io.Closer, 0),
    }
}

func (rm *ResourceManager) AddConsumer(consumer io.Closer) {
    rm.mutex.Lock()
    defer rm.mutex.Unlock()

    rm.consumers = append(rm.consumers, consumer)
}

func (rm *ResourceManager) AddProducer(producer io.Closer) {
    rm.mutex.Lock()
    defer rm.mutex.Unlock()

    rm.producers = append(rm.producers, producer)
}

func (rm *ResourceManager) Close() error {
    rm.mutex.Lock()
    defer rm.mutex.Unlock()

    var errors []error

    // å…³é—­æ‰€æœ‰æ¶ˆè´¹è€…
    for _, consumer := range rm.consumers {
        if err := consumer.Close(); err != nil {
            errors = append(errors, err)
        }
    }

    // å…³é—­æ‰€æœ‰ç”Ÿäº§è€…
    for _, producer := range rm.producers {
        if err := producer.Close(); err != nil {
            errors = append(errors, err)
        }
    }

    if len(errors) > 0 {
        return fmt.Errorf("errors closing resources: %v", errors)
    }

    return nil
}

// ä½¿ç”¨deferç¡®ä¿èµ„æºæ¸…ç†
func GoodResourceManagement() {
    rm := NewResourceManager()
    defer rm.Close() // ç¡®ä¿èµ„æºè¢«æ¸…ç†

    for i := 0; i < 100; i++ {
        consumer := createConsumer()
        rm.AddConsumer(consumer)
        consumer.Start()
    }
}
```

### 5. æ€§èƒ½ä¼˜åŒ–é™·é˜±

```go
// âŒ é”™è¯¯ï¼šåŒæ­¥å¤„ç†æ‰€æœ‰æ¶ˆæ¯
func BadPerformance(messages []*Message) {
    for _, msg := range messages {
        // åŒæ­¥å¤„ç†ï¼Œæ€§èƒ½å·®
        processMessage(msg)
    }
}

// âœ… æ­£ç¡®ï¼šæ‰¹é‡å’Œå¹¶å‘å¤„ç†
type BatchProcessor struct {
    batchSize   int
    workerCount int
    timeout     time.Duration
}

func (bp *BatchProcessor) ProcessMessages(messages []*Message) error {
    // åˆ†æ‰¹å¤„ç†
    batches := bp.createBatches(messages)

    // å¹¶å‘å¤„ç†æ‰¹æ¬¡
    var wg sync.WaitGroup
    errChan := make(chan error, len(batches))

    // é™åˆ¶å¹¶å‘æ•°
    semaphore := make(chan struct{}, bp.workerCount)

    for _, batch := range batches {
        wg.Add(1)
        go func(b []*Message) {
            defer wg.Done()

            // è·å–ä¿¡å·é‡
            semaphore <- struct{}{}
            defer func() { <-semaphore }()

            if err := bp.processBatch(b); err != nil {
                errChan <- err
            }
        }(batch)
    }

    wg.Wait()
    close(errChan)

    // æ”¶é›†é”™è¯¯
    var errors []error
    for err := range errChan {
        errors = append(errors, err)
    }

    if len(errors) > 0 {
        return fmt.Errorf("batch processing errors: %v", errors)
    }

    return nil
}

func (bp *BatchProcessor) createBatches(messages []*Message) [][]*Message {
    var batches [][]*Message

    for i := 0; i < len(messages); i += bp.batchSize {
        end := i + bp.batchSize
        if end > len(messages) {
            end = len(messages)
        }
        batches = append(batches, messages[i:end])
    }

    return batches
}

func (bp *BatchProcessor) processBatch(batch []*Message) error {
    ctx, cancel := context.WithTimeout(context.Background(), bp.timeout)
    defer cancel()

    // æ‰¹é‡å¤„ç†æ¶ˆæ¯
    for _, msg := range batch {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            if err := processMessage(msg); err != nil {
                return err
            }
        }
    }

    return nil
}
```

---

## ğŸ“ ç»ƒä¹ é¢˜

### ç»ƒä¹ é¢˜1ï¼šåˆ†å¸ƒå¼äº‹åŠ¡æ¶ˆæ¯å®ç°ï¼ˆâ­â­â­ï¼‰

**é¢˜ç›®æè¿°ï¼š**
å®ç°ä¸€ä¸ªåŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„åˆ†å¸ƒå¼äº‹åŠ¡è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒä¸¤é˜¶æ®µæäº¤åè®®ï¼Œç¡®ä¿æ¶ˆæ¯å‘é€å’Œæœ¬åœ°äº‹åŠ¡çš„ä¸€è‡´æ€§ã€‚

```go
// ç»ƒä¹ é¢˜1ï¼šåˆ†å¸ƒå¼äº‹åŠ¡æ¶ˆæ¯å®ç°
package main

import (
    "context"
    "database/sql"
    "encoding/json"
    "fmt"
    "time"

    "github.com/streadway/amqp"
    "gorm.io/gorm"
)

// è§£ç­”ï¼š
// äº‹åŠ¡æ¶ˆæ¯çŠ¶æ€
type TransactionMessageStatus string

const (
    StatusPrepared  TransactionMessageStatus = "prepared"
    StatusCommitted TransactionMessageStatus = "committed"
    StatusRollback  TransactionMessageStatus = "rollback"
)

// äº‹åŠ¡æ¶ˆæ¯è®°å½•
type TransactionMessage struct {
    ID          string                    `gorm:"primaryKey"`
    Topic       string                    `gorm:"not null"`
    RoutingKey  string                    `gorm:"not null"`
    Payload     string                    `gorm:"type:text;not null"`
    Status      TransactionMessageStatus `gorm:"not null"`
    CreatedAt   time.Time
    UpdatedAt   time.Time
    ExpiredAt   time.Time `gorm:"index"`
}

// åˆ†å¸ƒå¼äº‹åŠ¡æ¶ˆæ¯ç®¡ç†å™¨
type TransactionMessageManager struct {
    db       *gorm.DB
    producer *amqp.Channel
    consumer *amqp.Channel
}

func NewTransactionMessageManager(db *gorm.DB, conn *amqp.Connection) (*TransactionMessageManager, error) {
    producer, err := conn.Channel()
    if err != nil {
        return nil, err
    }

    consumer, err := conn.Channel()
    if err != nil {
        return nil, err
    }

    manager := &TransactionMessageManager{
        db:       db,
        producer: producer,
        consumer: consumer,
    }

    // å¯åŠ¨å®šæ—¶ä»»åŠ¡
    go manager.startCleanupTask()
    go manager.startRetryTask()

    return manager, nil
}

// ç¬¬ä¸€é˜¶æ®µï¼šå‡†å¤‡äº‹åŠ¡æ¶ˆæ¯
func (tm *TransactionMessageManager) PrepareMessage(ctx context.Context, topic, routingKey string, payload interface{}) (string, error) {
    payloadBytes, err := json.Marshal(payload)
    if err != nil {
        return "", fmt.Errorf("failed to marshal payload: %w", err)
    }

    messageID := generateMessageID()
    transactionMsg := &TransactionMessage{
        ID:         messageID,
        Topic:      topic,
        RoutingKey: routingKey,
        Payload:    string(payloadBytes),
        Status:     StatusPrepared,
        CreatedAt:  time.Now(),
        ExpiredAt:  time.Now().Add(5 * time.Minute), // 5åˆ†é’Ÿè¶…æ—¶
    }

    if err := tm.db.Create(transactionMsg).Error; err != nil {
        return "", fmt.Errorf("failed to prepare transaction message: %w", err)
    }

    return messageID, nil
}

// ç¬¬äºŒé˜¶æ®µï¼šæäº¤äº‹åŠ¡æ¶ˆæ¯
func (tm *TransactionMessageManager) CommitMessage(ctx context.Context, messageID string) error {
    return tm.db.Transaction(func(tx *gorm.DB) error {
        var transactionMsg TransactionMessage
        if err := tx.Where("id = ? AND status = ?", messageID, StatusPrepared).First(&transactionMsg).Error; err != nil {
            return fmt.Errorf("transaction message not found or already processed: %w", err)
        }

        // æ›´æ–°çŠ¶æ€ä¸ºå·²æäº¤
        if err := tx.Model(&transactionMsg).Update("status", StatusCommitted).Error; err != nil {
            return fmt.Errorf("failed to commit transaction message: %w", err)
        }

        // å‘é€æ¶ˆæ¯åˆ°MQ
        if err := tm.publishMessage(&transactionMsg); err != nil {
            return fmt.Errorf("failed to publish message: %w", err)
        }

        return nil
    })
}

// ç¬¬äºŒé˜¶æ®µï¼šå›æ»šäº‹åŠ¡æ¶ˆæ¯
func (tm *TransactionMessageManager) RollbackMessage(ctx context.Context, messageID string) error {
    return tm.db.Model(&TransactionMessage{}).
        Where("id = ? AND status = ?", messageID, StatusPrepared).
        Update("status", StatusRollback).Error
}

// å‘å¸ƒæ¶ˆæ¯åˆ°MQ
func (tm *TransactionMessageManager) publishMessage(transactionMsg *TransactionMessage) error {
    return tm.producer.Publish(
        transactionMsg.Topic,
        transactionMsg.RoutingKey,
        false,
        false,
        amqp.Publishing{
            ContentType:  "application/json",
            Body:         []byte(transactionMsg.Payload),
            DeliveryMode: 2, // æŒä¹…åŒ–
            Headers: amqp.Table{
                "transaction_id": transactionMsg.ID,
                "timestamp":      time.Now().Unix(),
            },
        },
    )
}

// ä¸šåŠ¡æœåŠ¡ç¤ºä¾‹
type OrderService struct {
    db  *gorm.DB
    txm *TransactionMessageManager
}

// åˆ›å»ºè®¢å•ï¼ˆæœ¬åœ°äº‹åŠ¡ + äº‹åŠ¡æ¶ˆæ¯ï¼‰
func (s *OrderService) CreateOrder(ctx context.Context, order *Order) error {
    return s.db.Transaction(func(tx *gorm.DB) error {
        // 1. å‡†å¤‡äº‹åŠ¡æ¶ˆæ¯
        messageID, err := s.txm.PrepareMessage(ctx, "order.events", "order.created", map[string]interface{}{
            "order_id": order.ID,
            "user_id":  order.UserID,
            "amount":   order.Amount,
        })
        if err != nil {
            return err
        }

        // 2. æ‰§è¡Œæœ¬åœ°äº‹åŠ¡
        if err := tx.Create(order).Error; err != nil {
            // æœ¬åœ°äº‹åŠ¡å¤±è´¥ï¼Œå›æ»šäº‹åŠ¡æ¶ˆæ¯
            s.txm.RollbackMessage(ctx, messageID)
            return err
        }

        // 3. æœ¬åœ°äº‹åŠ¡æˆåŠŸï¼Œæäº¤äº‹åŠ¡æ¶ˆæ¯
        if err := s.txm.CommitMessage(ctx, messageID); err != nil {
            return err
        }

        return nil
    })
}

// å®šæ—¶æ¸…ç†è¿‡æœŸçš„äº‹åŠ¡æ¶ˆæ¯
func (tm *TransactionMessageManager) startCleanupTask() {
    ticker := time.NewTicker(time.Minute)
    defer ticker.Stop()

    for range ticker.C {
        // æ¸…ç†è¿‡æœŸçš„å‡†å¤‡çŠ¶æ€æ¶ˆæ¯
        tm.db.Where("status = ? AND expired_at < ?", StatusPrepared, time.Now()).
            Update("status", StatusRollback)

        // åˆ é™¤è¿‡æœŸçš„å·²å¤„ç†æ¶ˆæ¯
        tm.db.Where("status IN ? AND created_at < ?",
                   []TransactionMessageStatus{StatusCommitted, StatusRollback},
                   time.Now().Add(-24*time.Hour)).
            Delete(&TransactionMessage{})
    }
}

// å®šæ—¶é‡è¯•å¤±è´¥çš„æ¶ˆæ¯
func (tm *TransactionMessageManager) startRetryTask() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        var messages []TransactionMessage
        tm.db.Where("status = ? AND updated_at < ?", StatusCommitted, time.Now().Add(-time.Minute)).
            Find(&messages)

        for _, msg := range messages {
            if err := tm.publishMessage(&msg); err != nil {
                log.Printf("Failed to retry message %s: %v", msg.ID, err)
            } else {
                log.Printf("Successfully retried message %s", msg.ID)
            }
        }
    }
}

/*
è§£æè¯´æ˜ï¼š
1. ä¸¤é˜¶æ®µæäº¤ï¼šå…ˆå‡†å¤‡äº‹åŠ¡æ¶ˆæ¯ï¼Œå†æ ¹æ®æœ¬åœ°äº‹åŠ¡ç»“æœå†³å®šæäº¤æˆ–å›æ»š
2. æ¶ˆæ¯è¡¨ï¼šä½¿ç”¨æ•°æ®åº“è¡¨è®°å½•äº‹åŠ¡æ¶ˆæ¯çŠ¶æ€ï¼Œç¡®ä¿ä¸€è‡´æ€§
3. å®šæ—¶ä»»åŠ¡ï¼šæ¸…ç†è¿‡æœŸæ¶ˆæ¯å’Œé‡è¯•å¤±è´¥æ¶ˆæ¯
4. äº‹åŠ¡è¾¹ç•Œï¼šæœ¬åœ°äº‹åŠ¡å’Œæ¶ˆæ¯å‘é€åœ¨åŒä¸€ä¸ªäº‹åŠ¡ä¸­

æ‰©å±•æ€è€ƒï¼š
- å¦‚ä½•å¤„ç†æ¶ˆæ¯å‘é€å¤±è´¥çš„æƒ…å†µï¼Ÿ
- å¦‚ä½•ä¼˜åŒ–å¤§é‡äº‹åŠ¡æ¶ˆæ¯çš„æ€§èƒ½ï¼Ÿ
- å¦‚ä½•å®ç°æ¶ˆæ¯çš„å¹‚ç­‰æ€§æ¶ˆè´¹ï¼Ÿ
- å¦‚ä½•ç›‘æ§äº‹åŠ¡æ¶ˆæ¯çš„å¥åº·çŠ¶æ€ï¼Ÿ
*/
```

### ç»ƒä¹ é¢˜2ï¼šæ¶ˆæ¯é˜Ÿåˆ—ç›‘æ§ç³»ç»Ÿï¼ˆâ­â­ï¼‰

**é¢˜ç›®æè¿°ï¼š**
è®¾è®¡å¹¶å®ç°ä¸€ä¸ªæ¶ˆæ¯é˜Ÿåˆ—ç›‘æ§ç³»ç»Ÿï¼Œèƒ½å¤Ÿå®æ—¶ç›‘æ§æ¶ˆæ¯é˜Ÿåˆ—çš„å¥åº·çŠ¶æ€ã€æ€§èƒ½æŒ‡æ ‡å’Œå¼‚å¸¸æƒ…å†µã€‚

```go
// ç»ƒä¹ é¢˜2ï¼šæ¶ˆæ¯é˜Ÿåˆ—ç›‘æ§ç³»ç»Ÿ
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "sync"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// è§£ç­”ï¼š
// ç›‘æ§æŒ‡æ ‡å®šä¹‰
var (
    // æ¶ˆæ¯è®¡æ•°å™¨
    messagesProduced = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "mq_messages_produced_total",
            Help: "Total number of messages produced",
        },
        []string{"topic", "status"},
    )

    messagesConsumed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "mq_messages_consumed_total",
            Help: "Total number of messages consumed",
        },
        []string{"topic", "consumer_group", "status"},
    )

    // æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ
    messageProcessingDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "mq_message_processing_duration_seconds",
            Help:    "Message processing duration in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"topic", "consumer_group"},
    )

    // é˜Ÿåˆ—æ·±åº¦
    queueDepth = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "mq_queue_depth",
            Help: "Current queue depth",
        },
        []string{"queue"},
    )

    // è¿æ¥çŠ¶æ€
    connectionStatus = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "mq_connection_status",
            Help: "Connection status (1=connected, 0=disconnected)",
        },
        []string{"broker", "type"},
    )
)

// ç›‘æ§æ•°æ®ç»“æ„
type MonitoringData struct {
    Timestamp         time.Time              `json:"timestamp"`
    Topic             string                 `json:"topic"`
    ConsumerGroup     string                 `json:"consumer_group,omitempty"`
    MessageCount      int64                  `json:"message_count"`
    ProcessingTime    time.Duration          `json:"processing_time"`
    ErrorCount        int64                  `json:"error_count"`
    QueueDepth        int64                  `json:"queue_depth"`
    ConnectionStatus  bool                   `json:"connection_status"`
    CustomMetrics     map[string]interface{} `json:"custom_metrics,omitempty"`
}

// ç›‘æ§ç³»ç»Ÿ
type MonitoringSystem struct {
    metrics     map[string]*MonitoringData
    mutex       sync.RWMutex
    alertRules  []AlertRule
    collectors  []MetricCollector
    reporters   []MetricReporter
}

// å‘Šè­¦è§„åˆ™
type AlertRule struct {
    Name        string                 `json:"name"`
    Condition   string                 `json:"condition"`
    Threshold   float64                `json:"threshold"`
    Duration    time.Duration          `json:"duration"`
    Severity    string                 `json:"severity"`
    Actions     []AlertAction          `json:"actions"`
    LastTriggered time.Time            `json:"last_triggered"`
}

type AlertAction struct {
    Type   string                 `json:"type"`   // email, webhook, slack
    Config map[string]interface{} `json:"config"`
}

// æŒ‡æ ‡æ”¶é›†å™¨æ¥å£
type MetricCollector interface {
    Collect(ctx context.Context) (*MonitoringData, error)
    GetName() string
}

// æŒ‡æ ‡æŠ¥å‘Šå™¨æ¥å£
type MetricReporter interface {
    Report(ctx context.Context, data *MonitoringData) error
    GetName() string
}

// åˆ›å»ºç›‘æ§ç³»ç»Ÿ
func NewMonitoringSystem() *MonitoringSystem {
    return &MonitoringSystem{
        metrics:    make(map[string]*MonitoringData),
        alertRules: make([]AlertRule, 0),
        collectors: make([]MetricCollector, 0),
        reporters:  make([]MetricReporter, 0),
    }
}

// æ³¨å†ŒæŒ‡æ ‡æ”¶é›†å™¨
func (ms *MonitoringSystem) RegisterCollector(collector MetricCollector) {
    ms.collectors = append(ms.collectors, collector)
}

// æ³¨å†ŒæŒ‡æ ‡æŠ¥å‘Šå™¨
func (ms *MonitoringSystem) RegisterReporter(reporter MetricReporter) {
    ms.reporters = append(ms.reporters, reporter)
}

// æ·»åŠ å‘Šè­¦è§„åˆ™
func (ms *MonitoringSystem) AddAlertRule(rule AlertRule) {
    ms.alertRules = append(ms.alertRules, rule)
}

// å¯åŠ¨ç›‘æ§
func (ms *MonitoringSystem) Start(ctx context.Context) error {
    // å¯åŠ¨æŒ‡æ ‡æ”¶é›†
    go ms.startMetricCollection(ctx)

    // å¯åŠ¨å‘Šè­¦æ£€æŸ¥
    go ms.startAlertChecking(ctx)

    // å¯åŠ¨æŒ‡æ ‡æŠ¥å‘Š
    go ms.startMetricReporting(ctx)

    return nil
}

// æŒ‡æ ‡æ”¶é›†å¾ªç¯
func (ms *MonitoringSystem) startMetricCollection(ctx context.Context) {
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            ms.collectMetrics(ctx)
        }
    }
}

// æ”¶é›†æŒ‡æ ‡
func (ms *MonitoringSystem) collectMetrics(ctx context.Context) {
    var wg sync.WaitGroup

    for _, collector := range ms.collectors {
        wg.Add(1)
        go func(c MetricCollector) {
            defer wg.Done()

            data, err := c.Collect(ctx)
            if err != nil {
                log.Printf("Failed to collect metrics from %s: %v", c.GetName(), err)
                return
            }

            ms.updateMetrics(c.GetName(), data)
        }(collector)
    }

    wg.Wait()
}

// æ›´æ–°æŒ‡æ ‡
func (ms *MonitoringSystem) updateMetrics(collectorName string, data *MonitoringData) {
    ms.mutex.Lock()
    defer ms.mutex.Unlock()

    key := fmt.Sprintf("%s:%s", collectorName, data.Topic)
    ms.metrics[key] = data

    // æ›´æ–°PrometheusæŒ‡æ ‡
    ms.updatePrometheusMetrics(data)
}

// æ›´æ–°PrometheusæŒ‡æ ‡
func (ms *MonitoringSystem) updatePrometheusMetrics(data *MonitoringData) {
    // æ›´æ–°æ¶ˆæ¯è®¡æ•°
    messagesConsumed.WithLabelValues(data.Topic, data.ConsumerGroup, "success").
        Add(float64(data.MessageCount))

    // æ›´æ–°å¤„ç†æ—¶é—´
    messageProcessingDuration.WithLabelValues(data.Topic, data.ConsumerGroup).
        Observe(data.ProcessingTime.Seconds())

    // æ›´æ–°é˜Ÿåˆ—æ·±åº¦
    queueDepth.WithLabelValues(data.Topic).Set(float64(data.QueueDepth))

    // æ›´æ–°è¿æ¥çŠ¶æ€
    connectionValue := 0.0
    if data.ConnectionStatus {
        connectionValue = 1.0
    }
    connectionStatus.WithLabelValues("broker", "consumer").Set(connectionValue)
}

// å‘Šè­¦æ£€æŸ¥å¾ªç¯
func (ms *MonitoringSystem) startAlertChecking(ctx context.Context) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            ms.checkAlerts(ctx)
        }
    }
}

// æ£€æŸ¥å‘Šè­¦
func (ms *MonitoringSystem) checkAlerts(ctx context.Context) {
    ms.mutex.RLock()
    metrics := make(map[string]*MonitoringData)
    for k, v := range ms.metrics {
        metrics[k] = v
    }
    ms.mutex.RUnlock()

    for _, rule := range ms.alertRules {
        if ms.evaluateAlertRule(rule, metrics) {
            ms.triggerAlert(ctx, rule, metrics)
        }
    }
}

// è¯„ä¼°å‘Šè­¦è§„åˆ™
func (ms *MonitoringSystem) evaluateAlertRule(rule AlertRule, metrics map[string]*MonitoringData) bool {
    switch rule.Condition {
    case "queue_depth_high":
        for _, data := range metrics {
            if float64(data.QueueDepth) > rule.Threshold {
                return true
            }
        }
    case "error_rate_high":
        for _, data := range metrics {
            if data.MessageCount > 0 {
                errorRate := float64(data.ErrorCount) / float64(data.MessageCount)
                if errorRate > rule.Threshold {
                    return true
                }
            }
        }
    case "processing_time_high":
        for _, data := range metrics {
            if data.ProcessingTime.Seconds() > rule.Threshold {
                return true
            }
        }
    case "connection_down":
        for _, data := range metrics {
            if !data.ConnectionStatus {
                return true
            }
        }
    }

    return false
}

// è§¦å‘å‘Šè­¦
func (ms *MonitoringSystem) triggerAlert(ctx context.Context, rule AlertRule, metrics map[string]*MonitoringData) {
    // æ£€æŸ¥å‘Šè­¦å†·å´æ—¶é—´
    if time.Since(rule.LastTriggered) < rule.Duration {
        return
    }

    // æ›´æ–°æœ€åè§¦å‘æ—¶é—´
    rule.LastTriggered = time.Now()

    // æ‰§è¡Œå‘Šè­¦åŠ¨ä½œ
    for _, action := range rule.Actions {
        go ms.executeAlertAction(ctx, action, rule, metrics)
    }

    log.Printf("Alert triggered: %s", rule.Name)
}

// æ‰§è¡Œå‘Šè­¦åŠ¨ä½œ
func (ms *MonitoringSystem) executeAlertAction(ctx context.Context, action AlertAction, rule AlertRule, metrics map[string]*MonitoringData) {
    switch action.Type {
    case "email":
        ms.sendEmailAlert(ctx, action.Config, rule, metrics)
    case "webhook":
        ms.sendWebhookAlert(ctx, action.Config, rule, metrics)
    case "slack":
        ms.sendSlackAlert(ctx, action.Config, rule, metrics)
    }
}

// æŒ‡æ ‡æŠ¥å‘Šå¾ªç¯
func (ms *MonitoringSystem) startMetricReporting(ctx context.Context) {
    ticker := time.NewTicker(time.Minute)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            ms.reportMetrics(ctx)
        }
    }
}

// æŠ¥å‘ŠæŒ‡æ ‡
func (ms *MonitoringSystem) reportMetrics(ctx context.Context) {
    ms.mutex.RLock()
    metrics := make(map[string]*MonitoringData)
    for k, v := range ms.metrics {
        metrics[k] = v
    }
    ms.mutex.RUnlock()

    for _, reporter := range ms.reporters {
        for _, data := range metrics {
            go func(r MetricReporter, d *MonitoringData) {
                if err := r.Report(ctx, d); err != nil {
                    log.Printf("Failed to report metrics to %s: %v", r.GetName(), err)
                }
            }(reporter, data)
        }
    }
}

// RabbitMQæŒ‡æ ‡æ”¶é›†å™¨
type RabbitMQCollector struct {
    client *rabbitmq.Client
    queues []string
}

func NewRabbitMQCollector(client *rabbitmq.Client, queues []string) *RabbitMQCollector {
    return &RabbitMQCollector{
        client: client,
        queues: queues,
    }
}

func (c *RabbitMQCollector) GetName() string {
    return "rabbitmq"
}

func (c *RabbitMQCollector) Collect(ctx context.Context) (*MonitoringData, error) {
    // æ¨¡æ‹Ÿæ”¶é›†RabbitMQæŒ‡æ ‡
    data := &MonitoringData{
        Timestamp:        time.Now(),
        Topic:            "orders",
        MessageCount:     1000,
        ProcessingTime:   50 * time.Millisecond,
        ErrorCount:       5,
        QueueDepth:       100,
        ConnectionStatus: true,
        CustomMetrics: map[string]interface{}{
            "memory_usage": "256MB",
            "disk_usage":   "1GB",
        },
    }

    return data, nil
}

// InfluxDBæŠ¥å‘Šå™¨
type InfluxDBReporter struct {
    client   *influxdb.Client
    database string
}

func NewInfluxDBReporter(client *influxdb.Client, database string) *InfluxDBReporter {
    return &InfluxDBReporter{
        client:   client,
        database: database,
    }
}

func (r *InfluxDBReporter) GetName() string {
    return "influxdb"
}

func (r *InfluxDBReporter) Report(ctx context.Context, data *MonitoringData) error {
    // æ¨¡æ‹Ÿå†™å…¥InfluxDB
    log.Printf("Reporting metrics to InfluxDB: %s", data.Topic)
    return nil
}

// è¾…åŠ©æ–¹æ³•
func (ms *MonitoringSystem) sendEmailAlert(ctx context.Context, config map[string]interface{}, rule AlertRule, metrics map[string]*MonitoringData) {
    // æ¨¡æ‹Ÿå‘é€é‚®ä»¶å‘Šè­¦
    log.Printf("Sending email alert: %s", rule.Name)
}

func (ms *MonitoringSystem) sendWebhookAlert(ctx context.Context, config map[string]interface{}, rule AlertRule, metrics map[string]*MonitoringData) {
    // æ¨¡æ‹Ÿå‘é€Webhookå‘Šè­¦
    log.Printf("Sending webhook alert: %s", rule.Name)
}

func (ms *MonitoringSystem) sendSlackAlert(ctx context.Context, config map[string]interface{}, rule AlertRule, metrics map[string]*MonitoringData) {
    // æ¨¡æ‹Ÿå‘é€Slackå‘Šè­¦
    log.Printf("Sending slack alert: %s", rule.Name)
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleMonitoringSystem() {
    // åˆ›å»ºç›‘æ§ç³»ç»Ÿ
    ms := NewMonitoringSystem()

    // æ³¨å†Œæ”¶é›†å™¨
    rabbitmqClient := &rabbitmq.Client{} // å‡è®¾å·²åˆå§‹åŒ–
    collector := NewRabbitMQCollector(rabbitmqClient, []string{"orders", "payments"})
    ms.RegisterCollector(collector)

    // æ³¨å†ŒæŠ¥å‘Šå™¨
    influxClient := &influxdb.Client{} // å‡è®¾å·²åˆå§‹åŒ–
    reporter := NewInfluxDBReporter(influxClient, "monitoring")
    ms.RegisterReporter(reporter)

    // æ·»åŠ å‘Šè­¦è§„åˆ™
    ms.AddAlertRule(AlertRule{
        Name:      "High Queue Depth",
        Condition: "queue_depth_high",
        Threshold: 1000,
        Duration:  5 * time.Minute,
        Severity:  "warning",
        Actions: []AlertAction{
            {
                Type: "email",
                Config: map[string]interface{}{
                    "to": "admin@example.com",
                },
            },
        },
    })

    // å¯åŠ¨ç›‘æ§
    ctx := context.Background()
    ms.Start(ctx)
}

/*
è§£æè¯´æ˜ï¼š
1. å¤šç»´åº¦ç›‘æ§ï¼šæ¶ˆæ¯è®¡æ•°ã€å¤„ç†å»¶è¿Ÿã€é˜Ÿåˆ—æ·±åº¦ã€è¿æ¥çŠ¶æ€ç­‰
2. å¯æ‰©å±•æ¶æ„ï¼šæ”¯æŒå¤šç§æ”¶é›†å™¨å’ŒæŠ¥å‘Šå™¨
3. å‘Šè­¦ç³»ç»Ÿï¼šæ”¯æŒå¤šç§å‘Šè­¦æ¡ä»¶å’ŒåŠ¨ä½œ
4. Prometheusé›†æˆï¼šæ ‡å‡†çš„ç›‘æ§æŒ‡æ ‡æ ¼å¼
5. å®æ—¶ç›‘æ§ï¼šå®šæ—¶æ”¶é›†å’ŒæŠ¥å‘ŠæŒ‡æ ‡

æ‰©å±•æ€è€ƒï¼š
- å¦‚ä½•å®ç°æ›´å¤æ‚çš„å‘Šè­¦è§„åˆ™ï¼Ÿ
- å¦‚ä½•ä¼˜åŒ–å¤§é‡æŒ‡æ ‡çš„å­˜å‚¨å’ŒæŸ¥è¯¢ï¼Ÿ
- å¦‚ä½•å®ç°ç›‘æ§æ•°æ®çš„å¯è§†åŒ–ï¼Ÿ
- å¦‚ä½•å¤„ç†ç›‘æ§ç³»ç»Ÿæœ¬èº«çš„é«˜å¯ç”¨ï¼Ÿ
*/
```

---

## ğŸ“š ç« èŠ‚æ€»ç»“

### ğŸ¯ æœ¬ç« å­¦ä¹ æˆæœ

é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š

#### ğŸ“– ç†è®ºçŸ¥è¯†
- **æ¶ˆæ¯é˜Ÿåˆ—æ ¸å¿ƒæ¦‚å¿µ**ï¼šç”Ÿäº§è€…ã€æ¶ˆè´¹è€…ã€ä»£ç†ã€ä¸»é¢˜ã€é˜Ÿåˆ—ç­‰åŸºç¡€æ¦‚å¿µ
- **æ¶ˆæ¯ä¼ é€’æ¨¡å¼**ï¼šç‚¹å¯¹ç‚¹ã€å‘å¸ƒè®¢é˜…ã€è¯·æ±‚å“åº”ç­‰é€šä¿¡æ¨¡å¼
- **å¯é æ€§ä¿è¯æœºåˆ¶**ï¼šæ¶ˆæ¯ç¡®è®¤ã€æŒä¹…åŒ–ã€æ­»ä¿¡é˜Ÿåˆ—ã€é‡è¯•æœºåˆ¶
- **äº‹ä»¶é©±åŠ¨æ¶æ„**ï¼šäº‹ä»¶æº¯æºã€CQRSã€é¢†åŸŸäº‹ä»¶ç­‰é«˜çº§æ¶æ„æ¨¡å¼

#### ğŸ› ï¸ å®è·µæŠ€èƒ½
- **å¤šç§MQé›†æˆ**ï¼šRabbitMQã€Kafkaã€NSQã€Redis Streamçš„å®Œæ•´é›†æˆæ–¹æ¡ˆ
- **æ¶ˆæ¯å¯é æ€§**ï¼šç”Ÿäº§è€…ç¡®è®¤ã€æ¶ˆè´¹è€…ç¡®è®¤ã€äº‹åŠ¡æ¶ˆæ¯ç­‰å¯é æ€§ä¿è¯
- **æ€§èƒ½ä¼˜åŒ–**ï¼šè¿æ¥æ± ç®¡ç†ã€æ‰¹é‡å¤„ç†ã€å¹¶å‘æ¶ˆè´¹ç­‰æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- **é”™è¯¯å¤„ç†**ï¼šåˆ†ç±»é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶ã€æ­»ä¿¡é˜Ÿåˆ—ç­‰å®¹é”™è®¾è®¡
- **ç›‘æ§å‘Šè­¦**ï¼šæŒ‡æ ‡æ”¶é›†ã€å®æ—¶ç›‘æ§ã€å‘Šè­¦è§„åˆ™ç­‰è¿ç»´èƒ½åŠ›

#### ğŸ—ï¸ æ¶æ„èƒ½åŠ›
- **äº‹ä»¶é©±åŠ¨è®¾è®¡**ï¼šåŸºäºäº‹ä»¶çš„å¾®æœåŠ¡æ¶æ„è®¾è®¡å’Œå®ç°
- **åˆ†å¸ƒå¼äº‹åŠ¡**ï¼šåŸºäºæ¶ˆæ¯çš„åˆ†å¸ƒå¼äº‹åŠ¡è§£å†³æ–¹æ¡ˆ
- **ç³»ç»Ÿè§£è€¦**ï¼šé€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å®ç°ç³»ç»Ÿé—´çš„æ¾è€¦åˆ
- **æµé‡æ§åˆ¶**ï¼šæ¶ˆæ¯é˜Ÿåˆ—åœ¨æµé‡å‰Šå³°å’Œè´Ÿè½½å‡è¡¡ä¸­çš„åº”ç”¨

### ğŸ†š æ¶ˆæ¯é˜Ÿåˆ—æŠ€æœ¯é€‰å‹æ€»ç»“

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|----------|------|
| **ä¼ä¸šçº§åº”ç”¨** | RabbitMQ | åŠŸèƒ½ä¸°å¯Œã€å¯é æ€§é«˜ã€ç”Ÿæ€æˆç†Ÿ |
| **å¤§æ•°æ®æµå¤„ç†** | Apache Kafka | é«˜ååé‡ã€æ°´å¹³æ‰©å±•ã€æµå¤„ç†æ”¯æŒ |
| **Goå¾®æœåŠ¡** | NSQ | åŸç”ŸGoã€ç®€å•æ˜“ç”¨ã€å»ä¸­å¿ƒåŒ– |
| **è½»é‡çº§é˜Ÿåˆ—** | Redis Stream | éƒ¨ç½²ç®€å•ã€æ€§èƒ½ä¼˜ç§€ã€å­¦ä¹ æˆæœ¬ä½ |
| **å®æ—¶é€šä¿¡** | WebSocket + Redis | ä½å»¶è¿Ÿã€å®æ—¶æ€§å¥½ |
| **æ‰¹å¤„ç†ä»»åŠ¡** | RabbitMQ + å»¶è¿Ÿé˜Ÿåˆ— | æ”¯æŒå»¶è¿Ÿæ¶ˆæ¯ã€ä»»åŠ¡è°ƒåº¦ |

### ğŸ¯ é¢è¯•å‡†å¤‡è¦ç‚¹

#### æ ¸å¿ƒæ¦‚å¿µæŒæ¡
- æ¶ˆæ¯é˜Ÿåˆ—çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œé€‚ç”¨åœºæ™¯åˆ†æ
- ä¸åŒæ¶ˆæ¯é˜Ÿåˆ—çš„ç‰¹ç‚¹å¯¹æ¯”å’Œé€‰å‹ä¾æ®
- æ¶ˆæ¯å¯é æ€§ä¿è¯çš„å®Œæ•´æ–¹æ¡ˆ
- äº‹ä»¶é©±åŠ¨æ¶æ„çš„è®¾è®¡åŸåˆ™å’Œå®ç°æ–¹å¼

#### å®è·µç»éªŒå±•ç¤º
- å¤§å‹é¡¹ç›®ä¸­çš„æ¶ˆæ¯é˜Ÿåˆ—æ¶æ„è®¾è®¡ç»éªŒ
- æ¶ˆæ¯ä¸¢å¤±ã€é‡å¤ã€ä¹±åºç­‰é—®é¢˜çš„è§£å†³å®è·µ
- é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹
- åˆ†å¸ƒå¼äº‹åŠ¡çš„å®ç°æ–¹æ¡ˆå’Œè¸©å‘ç»éªŒ

#### é—®é¢˜è§£å†³èƒ½åŠ›
- å¸¸è§æ¶ˆæ¯é˜Ÿåˆ—é—®é¢˜çš„æ’æŸ¥æ€è·¯
- æ¶ˆæ¯ç§¯å‹å’Œæ€§èƒ½ç“¶é¢ˆçš„è¯Šæ–­æ–¹æ³•
- ç³»ç»Ÿæ•…éšœæ—¶çš„åº”æ€¥å¤„ç†èƒ½åŠ›
- ç›‘æ§ä½“ç³»çš„å»ºè®¾å’Œç»´æŠ¤ç»éªŒ

### ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®

#### æ·±å…¥å­¦ä¹ æ–¹å‘
1. **æ¶ˆæ¯é˜Ÿåˆ—æºç åˆ†æ**
   - RabbitMQçš„Erlangå®ç°åŸç†
   - Kafkaçš„åˆ†å¸ƒå¼æ—¥å¿—è®¾è®¡
   - NSQçš„Goè¯­è¨€å®ç°ç»†èŠ‚
   - æ¶ˆæ¯è·¯ç”±å’Œå­˜å‚¨æœºåˆ¶

2. **é«˜çº§ç‰¹æ€§æ¢ç´¢**
   - æ¶ˆæ¯é˜Ÿåˆ—é›†ç¾¤éƒ¨ç½²å’Œè¿ç»´
   - è·¨æ•°æ®ä¸­å¿ƒçš„æ¶ˆæ¯å¤åˆ¶
   - æ¶ˆæ¯é˜Ÿåˆ—çš„å®‰å…¨æœºåˆ¶
   - æµå¤„ç†å’Œå¤æ‚äº‹ä»¶å¤„ç†

3. **ä¼ä¸šçº§å®è·µ**
   - å¤§è§„æ¨¡æ¶ˆæ¯é˜Ÿåˆ—çš„å®¹é‡è§„åˆ’
   - æ¶ˆæ¯é˜Ÿåˆ—çš„ç¾å¤‡å’Œæ¢å¤
   - å¤šç§Ÿæˆ·æ¶ˆæ¯é˜Ÿåˆ—è®¾è®¡
   - æ¶ˆæ¯é˜Ÿåˆ—çš„æˆæœ¬ä¼˜åŒ–

#### å®è·µé¡¹ç›®å»ºè®®
1. **ä¸ªäººé¡¹ç›®**ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„äº‹ä»¶é©±åŠ¨ç”µå•†ç³»ç»Ÿ
2. **å¼€æºè´¡çŒ®**ï¼šå‚ä¸æ¶ˆæ¯é˜Ÿåˆ—ç›¸å…³å¼€æºé¡¹ç›®
3. **ä¼ä¸šå®è·µ**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”ç”¨æ¶ˆæ¯é˜Ÿåˆ—è§£å†³å®é™…é—®é¢˜

### ğŸ’¡ å­¦ä¹ å¿ƒå¾—

æ¶ˆæ¯é˜Ÿåˆ—ä½œä¸ºç°ä»£åˆ†å¸ƒå¼ç³»ç»Ÿçš„é‡è¦ç»„ä»¶ï¼Œä¸ä»…ä»…æ˜¯ç®€å•çš„æ¶ˆæ¯ä¼ é€’å·¥å…·ï¼Œæ›´æ˜¯å®ç°ç³»ç»Ÿè§£è€¦ã€æé«˜å¯æ‰©å±•æ€§çš„å…³é”®æŠ€æœ¯ã€‚é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæˆ‘ä»¬ä¸ä»…æŒæ¡äº†å„ç§æ¶ˆæ¯é˜Ÿåˆ—çš„ä½¿ç”¨æ–¹æ³•ï¼Œæ›´é‡è¦çš„æ˜¯åŸ¹å…»äº†äº‹ä»¶é©±åŠ¨çš„æ¶æ„æ€ç»´ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¦å§‹ç»ˆè®°ä½ï¼š
- **é€‰å‹ä¼˜äºä¼˜åŒ–**ï¼šé€‰æ‹©æœ€é€‚åˆä¸šåŠ¡åœºæ™¯çš„æ¶ˆæ¯é˜Ÿåˆ—
- **å¯é æ€§ä¼˜äºæ€§èƒ½**ï¼šåœ¨ä¿è¯å¯é æ€§çš„å‰æä¸‹è¿½æ±‚æ€§èƒ½
- **ç›‘æ§ä¼˜äºè°ƒè¯•**ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»é¢„é˜²é—®é¢˜
- **ç®€å•ä¼˜äºå¤æ‚**ï¼šé¿å…è¿‡åº¦è®¾è®¡å’Œä¸å¿…è¦çš„å¤æ‚æ€§

### ğŸ”— ä¸å…¶ä»–ç« èŠ‚çš„è”ç³»

æœ¬ç« å†…å®¹ä¸å…¶ä»–ç« èŠ‚ç´§å¯†ç›¸å…³ï¼š
- **Redisç¼“å­˜ç« èŠ‚**ï¼šæ¶ˆæ¯é˜Ÿåˆ—å¯ä»¥è§¦å‘ç¼“å­˜æ›´æ–°å’Œå¤±æ•ˆ
- **æ•°æ®åº“ç« èŠ‚**ï¼šæ¶ˆæ¯é˜Ÿåˆ—å®ç°æ•°æ®åº“çš„å¼‚æ­¥åŒæ­¥å’Œå¤‡ä»½
- **å¾®æœåŠ¡ç« èŠ‚**ï¼šæ¶ˆæ¯é˜Ÿåˆ—æ˜¯å¾®æœåŠ¡é—´é€šä¿¡çš„é‡è¦æ–¹å¼
- **ç›‘æ§ç« èŠ‚**ï¼šæ¶ˆæ¯é˜Ÿåˆ—éœ€è¦å®Œå–„çš„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶

### ğŸ‰ æ­å–œå®Œæˆ

æ­å–œä½ å®Œæˆäº†æ¶ˆæ¯é˜Ÿåˆ—é›†æˆä¸å®è·µçš„å­¦ä¹ ï¼ä½ ç°åœ¨å·²ç»å…·å¤‡äº†ï¼š

âœ… **æ‰å®çš„ç†è®ºåŸºç¡€** - æ·±å…¥ç†è§£æ¶ˆæ¯é˜Ÿåˆ—åŸç†å’Œäº‹ä»¶é©±åŠ¨æ¶æ„
âœ… **ä¸°å¯Œçš„å®è·µç»éªŒ** - æŒæ¡å¤šç§æ¶ˆæ¯é˜Ÿåˆ—çš„é›†æˆå’Œä½¿ç”¨æ–¹æ³•
âœ… **ä¼˜ç§€çš„æ¶æ„èƒ½åŠ›** - èƒ½å¤Ÿè®¾è®¡é«˜å¯ç”¨ã€é«˜æ€§èƒ½çš„æ¶ˆæ¯ç³»ç»Ÿ
âœ… **å®Œå–„çš„é¢è¯•å‡†å¤‡** - å…·å¤‡å›ç­”å„ç§æ¶ˆæ¯é˜Ÿåˆ—ç›¸å…³é—®é¢˜çš„èƒ½åŠ›

ç»§ç»­ä¿æŒå­¦ä¹ çš„çƒ­æƒ…ï¼Œåœ¨Goè¯­è¨€çš„é“è·¯ä¸Šä¸æ–­å‰è¿›ï¼ä¸‹ä¸€ç« æˆ‘ä»¬å°†å­¦ä¹ å¾®æœåŠ¡æ¶æ„è®¾è®¡ï¼Œè¿›ä¸€æ­¥æå‡ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

---

*"æ¶ˆæ¯é˜Ÿåˆ—æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„ç¥ç»ç½‘ç»œï¼Œäº‹ä»¶é©±åŠ¨æ˜¯ç°ä»£æ¶æ„çš„æ ¸å¿ƒæ€æƒ³ã€‚æŒæ¡äº†æ¶ˆæ¯é˜Ÿåˆ—ï¼Œä½ å°±æŒæ¡äº†æ„å»ºå¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿçš„å…³é”®æŠ€èƒ½ï¼"* ğŸš€âœ¨
